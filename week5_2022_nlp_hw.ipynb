{"cells":[{"cell_type":"markdown","metadata":{"id":"QhUHfXkPAORh"},"source":["ğŸ“Œ week5 ë‚´ìš© ì£¼ì°¨ì— í•´ë‹¹ë˜ëŠ” ê³¼ì œëŠ” Glove ëª¨ë¸ ì‹¤ìŠµ, NER task ì‹¤ìŠµ, Dependency Parsing task ì‹¤ìŠµìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (**ì°¸ê³ ** : **ì œì¶œì€ week6 branch ë³µìŠµê³¼ì œë¡œ!**)\n","\n","ğŸ“Œ ìœ„í‚¤ë…ìŠ¤ì˜ ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ êµì¬ ì‹¤ìŠµ, ìºê¸€ ë…¸íŠ¸ë¶ ë“±ì˜ ìë£Œë¡œ êµ¬ì„±ë˜ì–´ìˆëŠ” ê³¼ì œì…ë‹ˆë‹¤. \n","\n","ğŸ“Œ ì•ˆë‚´ëœ ë§í¬ì— ë§ì¶”ì–´ **ì§ì ‘ ì½”ë“œë¥¼ ë”°ë¼ ì¹˜ë©´ì„œ (í•„ì‚¬)** í•´ë‹¹ nlp task ì˜ ê¸°ë³¸ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë©”ì„œë“œë¥¼ ìˆ™ì§€í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ğŸ˜Š í•„ìˆ˜ë¼ê³  ì²´í¬í•œ ë¶€ë¶„ì€ ê³¼ì œì— ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì£¼ì‹œê³ , ì„ íƒìœ¼ë¡œ ì²´í¬í•œ ë¶€ë¶„ì€ ììœ¨ì ìœ¼ë¡œ ìŠ¤í„°ë”” í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n","\n","ğŸ“Œ ê¶ê¸ˆí•œ ì‚¬í•­ì€ ê¹ƒí—ˆë¸Œ ì´ìŠˆë‚˜, ì¹´í†¡ë°©, ì„¸ì…˜ ë°œí‘œ ì‹œì‘ ì´ì „ ì‹œê°„ ë“±ì„ í™œìš©í•˜ì—¬ ììœ ë¡­ê²Œ ê³µìœ í•´ì£¼ì„¸ìš”!"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665412546728,"user":{"displayName":"Â­ê¹€ê²½ë¯¼(ì—˜í…ê³µê³¼ëŒ€í•™ ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€)","userId":"06637781437683440716"},"user_tz":-540},"id":"3XjTSbcxBB6o","outputId":"31b2f024-725d-42fb-a0fb-39b044f0b645"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["import nltk\n","# nltk colab í™˜ê²½ì—ì„œ ì‹¤í–‰ì‹œ í•„ìš”í•œ ì½”ë“œì…ë‹ˆë‹¤. \n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')"]},{"cell_type":"markdown","metadata":{"id":"-vPZn15zBHIv"},"source":["### 1ï¸âƒ£ **Glove**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P11biHcUuBaH"},"source":["ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n","* ìŠ¤íƒ í¬ë“œ ëŒ€í•™ì—ì„œ ê°œë°œí•œ ì¹´ìš´íŠ¸ ê¸°ë°˜ê³¼ ì˜ˆì¸¡ ê¸°ë°˜ì„ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ ì„ë² ë”© ë°©ë²•ë¡  \n","* word2vec ì˜ ë‹¨ì ì„ ë³´ì™„í•´ì„œ ë‚˜ì˜¨ ëª¨ë¸ \n","* glove model ì˜ **input ì€ ë°˜ë“œì‹œ ë™ì‹œë“±ì¥í–‰ë ¬ í˜•íƒœ**ì—¬ì•¼ í•œë‹¤ â­\n","\n","![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n","\n","\n","\n","\n","ğŸ¤” í•œêµ­ì–´ ì˜ˆì œëŠ” ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” k-Glove ë¡œ ì†Œê°œë˜ëŠ” ì—°êµ¬ê°€ ìˆê¸´ í•œë°, ì¢€ ë” ì•Œì•„ë´ì•¼ í•  ê²ƒ ê°™ì•„ìš”!\n","\n","â• [ë…¼ë¬¸1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n","\n","\n","â•[ë…¼ë¬¸2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"]},{"cell_type":"markdown","metadata":{"id":"asGcGy6fBM1E"},"source":["ğŸ”¹ **1-(1)** glove python\n","\n","* [ì‹¤ìŠµ : basic code](https://wikidocs.net/22885) ğŸ‘‰ í•„ìˆ˜"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V31NoJdu5t3p","outputId":"f124123d-9e9f-406f-ae91-82c40259076f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: glove_python_binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.7.3)\n"]}],"source":["!pip install glove_python_binary\n","\n","import re\n","import urllib.request\n","import zipfile\n","from lxml import etree\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","\n","# ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")\n","\n","targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","target_text = etree.parse(targetXML)\n","\n","# xml íŒŒì¼ë¡œë¶€í„° <content>ì™€ </content> ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ê°€ì ¸ì˜¨ë‹¤.\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# ì •ê·œ í‘œí˜„ì‹ì˜ sub ëª¨ë“ˆì„ í†µí•´ content ì¤‘ê°„ì— ë“±ì¥í•˜ëŠ” (Audio), (Laughter) ë“±ì˜ ë°°ê²½ìŒ ë¶€ë¶„ì„ ì œê±°.\n","# í•´ë‹¹ ì½”ë“œëŠ” ê´„í˜¸ë¡œ êµ¬ì„±ëœ ë‚´ìš©ì„ ì œê±°.\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","\n","# ì…ë ¥ ì½”í¼ìŠ¤ì— ëŒ€í•´ì„œ NLTKë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì¥ í† í°í™”ë¥¼ ìˆ˜í–‰.\n","sent_text = sent_tokenize(content_text)\n","\n","# ê° ë¬¸ì¥ì— ëŒ€í•´ì„œ êµ¬ë‘ì ì„ ì œê±°í•˜ê³ , ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜.\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","\n","# ê° ë¬¸ì¥ì— ëŒ€í•´ì„œ NLTKë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ì–´ í† í°í™”ë¥¼ ìˆ˜í–‰.\n","result = [word_tokenize(sentence) for sentence in normalized_text]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ta6QgoKO5uXJ"},"outputs":[],"source":["from glove import Corpus, Glove\n","\n","corpus = Corpus() \n","\n","# í›ˆë ¨ ë°ì´í„°ë¡œë¶€í„° GloVeì—ì„œ ì‚¬ìš©í•  ë™ì‹œ ë“±ì¥ í–‰ë ¬ ìƒì„±\n","corpus.fit(result, window=5)\n","glove = Glove(no_components=100, learning_rate=0.05)\n","\n","# í•™ìŠµì— ì´ìš©í•  ì“°ë ˆë“œì˜ ê°œìˆ˜ëŠ” 4ë¡œ ì„¤ì •, ì—í¬í¬ëŠ” 20.\n","glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n","glove.add_dictionary(corpus.dictionary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlngY35O53sk"},"outputs":[],"source":["print(glove.most_similar(\"man\"))"]},{"cell_type":"markdown","metadata":{"id":"3ADfVM9lO9NE"},"source":["ğŸ”¹ **1-(2)** pre-trained glove \n","\n","* **ì‚¬ì „í•™ìŠµëª¨ë¸** : ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë“¤ì„ ë‹¤ë¥¸ ë¬¸ì œì— í•™ìŠµì‹œí‚¨ ê°€ì¤‘ì¹˜ë“¤ë¡œ ì´ˆê¸°í™”í•˜ëŠ” ë°©ë²•ì´ë‹¤.ì‚¬ì „ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•´ í•™ìŠµí•˜ê³ ì í•˜ëŠ” ë³¸ë˜ ë¬¸ì œë¥¼ í•˜ìœ„ë¬¸ì œë¼ê³  í•œë‹¤. \n","\n","* [ì‹¤ìŠµ : ë¬¸ì¥ì˜ ê¸ë¶€ì •ì„ íŒë‹¨í•˜ëŠ” ê°ì„± ë¶„ë¥˜ ëª¨ë¸ ë§Œë“¤ê¸°](https://wikidocs.net/33793) ğŸ‘‰ í•„ìˆ˜\n","  * [ì„¤ëª…ì°¸ê³ ](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n","* pre-trained data ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¼\n","* kaggle ëŒ€íšŒì—ì„œ ì£¼ë¡œ ì´ ë°©ì‹ì„ ë§ì´ ì‚¬ìš©í•¨\n","  * [ì°¸ê³ ](https://lsjsj92.tistory.com/455)"]},{"cell_type":"code","source":[],"metadata":{"id":"CVw2vvTIW54w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_wcrE5PtLMI"},"source":["ğŸ”¹ **1-(3)** fine tuning glove\n","* ë¯¸ì„¸ì¡°ì • : ì‚¬ì „ í•™ìŠµí•œ ëª¨ë“  ê°€ì¤‘ì¹˜ì™€ ë”ë¶ˆì–´ í•˜ìœ„ ë¬¸ì œë¥¼ ìœ„í•œ ìµœì†Œí•œì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¶”ê°€í•´ ëª¨ë¸ì„ ì¶”ê°€ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ë‹¤. \n","\n","* fine tuning ì´ í•„ìš”í•œ ê²½ìš° \n","  * pretrained model ì— ë°ì´í„°ì…‹ì— ìˆëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš° \n","  * ë°ì´í„° ì§‘í•©ì´ ë„ˆë¬´ ì‘ì•„ì„œ ì „ì²´ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ì–´ë ¤ìš´ ê²½ìš° \n","\n","* [Mittens ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) ğŸ‘‰ í•„ìˆ˜\n","  *  GloVe ì„ë² ë”©ì„ fine-tuning í•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","  * [github](https://github.com/roamanalytics/mittens)\n","\n","* [í•œêµ­ì–´ ì†Œì„¤ í…ìŠ¤íŠ¸ ë°ì´í„° ë¯¸ì„¸ì¡°ì • ëª¨ë¸ í•™ìŠµ - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) ğŸ‘‰ ì„ íƒ (glove ëª¨ë¸ ì˜ˆì œëŠ” ì•„ë‹™ë‹ˆë‹¤. fine-tuning ì— ì´ˆì ì„ ë‘ì–´ì„œ ì°¸ê³ í•´ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHiR5mN4577l"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"I_-OB9Siga3G"},"source":["* (ì°¸ê³ ) word2vec pretrained example\n","\n","â• [word2vec ì‚¬ì „í•™ìŠµ ëª¨ë¸ -í•œêµ­ì–´1](http://doc.mindscale.kr/km/unstructured/11.html)\n","\n","â• [word2vec ì‚¬ì „í•™ìŠµ - í•œêµ­ì–´2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"]},{"cell_type":"markdown","metadata":{"id":"xUWWDwdiPLS9"},"source":["### **2ï¸âƒ£ NER**"]},{"cell_type":"markdown","metadata":{"id":"9N0B4VknPkTk"},"source":["ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n","* ê°œì²´ëª… ì¸ì‹ì„ ì‚¬ìš©í•˜ë©´ ì½”í¼ìŠ¤ë¡œë¶€í„° ì–´ë–¤ ë‹¨ì–´ê°€ ì‚¬ëŒ, ì¥ì†Œ, ì¡°ì§ ë“±ì„ ì˜ë¯¸í•˜ëŠ” ë‹¨ì–´ì¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤. "]},{"cell_type":"markdown","metadata":{"id":"QWgla1BuPRqJ"},"source":["\n","\n","\n","ğŸ”¹ **2-(1)** NER task by nltk library\n","\n","\n","* nltk ì—ì„œëŠ” ê°œì²´ëª… ì¸ì‹ê¸° (NER chunker) ë¥¼ ì§€ì›í•˜ê³  ìˆë‹¤. \n","* ne_chunk ëŠ” ê°œì²´ëª…ì„ íƒœê¹…í•˜ê¸° ìœ„í•´ì„œ ì•ì„œ í’ˆì‚¬ íƒœê¹… pos_tag ê°€ ìˆ˜í–‰ë˜ì–´ì•¼ í•œë‹¤. \n","\n","\n","ğŸ“Œ [basic code](https://wikidocs.net/30682) ğŸ‘‰ í•„ìˆ˜ \n","\n","ğŸ“Œ [BIO í‘œí˜„, LSTMì„ í™œìš©í•œ NER ì‹¤ìŠµ](https://wikidocs.net/24682) ğŸ‘‰ ì„ íƒ\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"diaZweMyAxJz"},"outputs":[],"source":["from nltk import word_tokenize, pos_tag, ne_chunk\n","\n","sentence = \"James is working at Disney in London\"\n","# í† í°í™” í›„ í’ˆì‚¬ íƒœê¹…\n","tokenized_sentence = pos_tag(word_tokenize(sentence))\n","print(tokenized_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1k09tKha3Lgi"},"outputs":[],"source":["# ê°œì²´ëª… ì¸ì‹\n","ner_sentence = ne_chunk(tokenized_sentence)\n","print(ner_sentence)"]},{"cell_type":"markdown","metadata":{"id":"TPX-WtSvPmm6"},"source":["ğŸ”¹ **2-(2)** NER task by spacy library\n","\n","\n","* spaCy ëŠ” ìì—°ì–´ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ ê¸°ë°˜ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. \n","  * Tokenization \n","  * POS tagging \n","  * Lemmatization \n","  * Sentence Boundary Detection (SBD)\n","  * Named Entity Recognition (NER)\n","  * Similarity\n","  * Text Classification\n","  * Rule-based Matching\n","  * Training\n","  * Serialization\n","\n","* spaCy ì™€ NER\n","  * .ents â†’ .label_\n","\n","\n","ğŸ“Œ [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) ğŸ‘‰ í•„ìˆ˜ (NER ë¶€ë¶„ë§Œ)\n","\n","ğŸ“Œ [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) ğŸ‘‰ ì„ íƒ\n","\n","  * í›ˆë ¨ë˜ì§€ ì•Šì€ ë°ì´í„° ì„¸íŠ¸ì— ëª…ëª…ëœ ì—”í‹°í‹°ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²• : ì´ë ¥ì„œ pdf ë°ì´í„° í™œìš© \n","  * manually labelled \n","\n","ğŸ“Œ [í•œêµ­ì–´ NER](https://github.com/monologg/KoBERT-NER) ğŸ‘‰ ì°¸ê³ í•˜ë©´ ì¢‹ì„ ìë£Œ\n","\n","â• [ì°¸ê³ ](http://aispiration.com/nlp2/nlp-ner-python.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WXjRfz-qP0Xx"},"outputs":[],"source":["import spacy \n","nlp = spacy.load('en_core_web_sm')\n","doc = nlp('Apple is looking at buyin at U.K startup for $1 billion.')\n","print(type(doc))\n","print(doc)\n","print(list(doc))\n","print(type(doc[0]))\n","\n","\n","## part of speech tagging \n","\n","temp_str = \"\"\"\n","Text: The original word text.\n","Lemma: The base form of the word.(ì¶•ì•½í•œ ìƒíƒœ)\n","POS: The simple part-of-speech tag.\n","Tag: The detailed part-of-speech tag.\n","Dep: Syntactic dependency, i.e. the relation between tokens.\n","Shape: The word shape â€“ capitalisation, punctuation, digits.\n","is alpha: Is the token an alpha character?\n","is stop: Is the token part of a stop list, i.e. the most common words of the language?\n","\"\"\".strip()\n","print(temp_str)\n","print(\"==\"*40)\n","\n","str_format = \"{:>10}\"*8\n","print(str_format.format(*temp_dict.keys()))\n","print(\"==\"*40)\n","\n","doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n","for token in doc:\n","    print(str_format.format(token.text, token.lemma_, token.pos_, token.tag_, \n","                            token.dep_, token.shape_, str(token.is_alpha), str(token.is_stop)))"]},{"cell_type":"markdown","metadata":{"id":"008-V5QsQG25"},"source":["###**3ï¸âƒ£ Dependency Parsing**"]},{"cell_type":"markdown","metadata":{"id":"oQfcodHQQPlt"},"source":["ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n","* ë¬¸ì¥ì˜ ì „ì²´ì ì¸ êµ¬ì„±/êµ¬ì¡° ë³´ë‹¤ëŠ” ê° ê°œë³„ë‹¨ì–´ ê°„ì˜ 'ì˜ì¡´ê´€ê³„' ë˜ëŠ” 'ìˆ˜ì‹ê´€ê³„' ì™€ ê°™ì€ ë‹¨ì–´ê°„ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì´ ëª©ì ì¸ NLP Task\n","* ë¬¸ì¥ í•´ì„ì˜ ëª¨í˜¸ì„±ì„ ì—†ì• ê¸° ìœ„í•´ Parsing ì„ í•œë‹¤."]},{"cell_type":"markdown","metadata":{"id":"mJLAzZnbRNlL"},"source":["\n","\n","\n","ğŸ”¹ **3-(1)** Dependency Parsing by spacy library\n","\n","\n","* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) ğŸ‘‰ dependecy parsing ë¶€ë¶„ë§Œ í•„ìˆ˜\n","* .dep_ ë©”ì„œë“œ\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbQEYt76bJXz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9QAEsrLAxHP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XQD5oiGgRfHe"},"source":["ğŸ”¹ **3-(2)** Spacy (kaggle) \n","\n","* ìºê¸€ ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ì‹¤ìŠµí•´ë³´ëŠ” ê²ƒì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤!\n","\n","* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) ğŸ‘‰ í•„ìˆ˜\n","  * ë„ë‚ ë“œ íŠ¸ëŸ¼í”„ íŠ¸ìœ„í„° íŠ¸ìœ— ë‚´ìš© ë°ì´í„° ë¶„ì„\n","\n","\n","ğŸ‘€ **ë…¸íŠ¸ë¶ í‚¤í¬ì¸íŠ¸** \n","  1. spacy.display ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œ NER ì‹œê°í™” \n","  2. Tagging ì„ í†µí•œ íŠ¸ëŸ¼í”„ íŠ¸ìœ— ë¶„ì„ : noun_chunks ëŠ” dependency graphë¥¼ ê³ ë ¤í•˜ì—¬, noun phraseë¥¼ ë½‘ì•„ì¤€ë‹¤. \n","  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : ì§ì ‘ ë¬¸ì¥/ë‹¨ì–´ íŒ¨í„´ì„ ë“±ë¡í•˜ì—¬ parsing\n","  4. Question and answering task using Dependency Parsing\n","    * spacy display :  ``style = 'dep'``\n","    * .dep_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuHGKITRbKYq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMArOUrxAJ8K"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1vb1qpw7zMmpoLHTDuCSbWbwRQGXjIA-E","timestamp":1665413924772},{"file_id":"1RyTVvavR5yzGtoim73Sw_LLFKhhbdDd-","timestamp":1664432950955}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}