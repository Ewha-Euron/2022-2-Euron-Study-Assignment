{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fae343",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "988db60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array1 type: <class 'numpy.ndarray'>\n",
      "array1 array 형태: (3,)\n",
      "array2 type: <class 'numpy.ndarray'>\n",
      "array2 array 형태: (2, 3)\n",
      "array3 type: <class 'numpy.ndarray'>\n",
      "array3 array 형태: (1, 3)\n",
      "array1: 1차원, array2: 2차원, array3:  2차원\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "[1 2 3] int32\n",
      "['1' '2' 'test'] <U11\n",
      "[1. 2. 3.] float64\n",
      "array1: [1 2 3 4 5 6 7 8 9]\n",
      "value: 3\n",
      "<class 'numpy.int32'>\n",
      "array1: [9 2 3 4 5 6 7 8 0]\n",
      "[9 2 3]\n",
      "<class 'numpy.ndarray'>\n",
      "array2d:\n",
      " [[1 2]\n",
      " [4 5]]\n",
      "[1 2 3]\n",
      "[4 5 6]\n",
      "array2d[0] shape: (3,) array2d[1] shape: (3,)\n",
      "원본 행렬: [3 1 9 5]\n",
      "np.sort() 호출 후 반환된 정렬행렬: [1 3 5 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array1=np.array([1,2,3])\n",
    "print('array1 type:',type(array1))\n",
    "print('array1 array 형태:', array1. shape)\n",
    "\n",
    "array2=np.array([[1,2,3],\n",
    "                [2,3,4]])\n",
    "print('array2 type:',type(array2))\n",
    "print('array2 array 형태:', array2. shape)\n",
    "\n",
    "array3=np.array([[1,2,3]])\n",
    "print('array3 type:',type(array3))\n",
    "print('array3 array 형태:', array3. shape)\n",
    "\n",
    "print('array1: {:0}차원, array2: {:1}차원, array3: {:2}차원'.format(array1.ndim,\n",
    "                                                         array2.ndim,array3.ndim))\n",
    "\n",
    "list1=[1,2,3]\n",
    "print(type(list1))\n",
    "array1=np.array(list1)\n",
    "print(type(array1))\n",
    "print(array1,array1.dtype)\n",
    "\n",
    "list2=[1,2,'test']\n",
    "array2=np.array(list2)\n",
    "print(array2,array2.dtype)\n",
    "\n",
    "list3=[1,2,3.0]\n",
    "array3=np.array(list3)\n",
    "print(array3,array3.dtype)\n",
    "\n",
    "array1=np.arange(start=1, stop=10)\n",
    "print('array1:',array1)\n",
    "\n",
    "value=array1[2]\n",
    "print('value:', value)\n",
    "print(type(value))\n",
    "\n",
    "array1[0]=9\n",
    "array1[8]=0\n",
    "print('array1:',array1)\n",
    "\n",
    "array3=array1[0:3]\n",
    "print(array3)\n",
    "print(type(array3))\n",
    "array4=array1[:3]\n",
    "array1d=np.arange(start=1,stop=10)\n",
    "array2d=array1d.reshape(3,3)\n",
    "print('array2d:\\n',array2d[0:2,0:2])\n",
    "print(array2d[0])\n",
    "print(array2d[1])\n",
    "print('array2d[0] shape:', array2d[0].shape, \n",
    "      'array2d[1] shape:', array2d[1].shape)\n",
    "\n",
    "org_array=np.array([3,1,9,5])\n",
    "print('원본 행렬:', org_array)\n",
    "sort_array1=np.sort(org_array)\n",
    "print('np.sort() 호출 후 반환된 정렬행렬:', sort_array1)\n",
    "\n",
    "titanic_df=pd.read_csv('titanic_train.csv')\n",
    "titanic_df.head(3)\n",
    "titanic_df.describe()\n",
    "titanic_df[0:2]\n",
    "titanic_df[titanic_df['Age']>60][['Name','Age']].head(3)\n",
    "titanic_df[(titanic_df['Age']>60)&(titanic_df['Pclass']==1)&(titanic_df['Sex']=='female')]\n",
    "titanic_sorted=titanic_df.sort_values(by=['Name'])\n",
    "titanic_sorted.head(3)\n",
    "titanic_groupby=titanic_df.groupby(by='Pclass')\n",
    "titanic_groupby=titanic_df.groupby(by='Pclass').count()\n",
    "titanic_df.groupby=titanic_df.groupby('Pclass')['Age'].agg([max,min])\n",
    "titanic_df.isna().head(3)\n",
    "titanic_df.isna().sum()\n",
    "titanic_df['Age']=titanic_df['Age'].fillna(titanic_df['Age'].mean())\n",
    "titanic_df['Embarked']=titanic_df['Embarked'].fillna('S')\n",
    "titanic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3382d3",
   "metadata": {},
   "source": [
    "## chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd2941",
   "metadata": {},
   "source": [
    "### 붓꽃 품종 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c28c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "iris=load_iris()\n",
    "iris_data=iris.data\n",
    "iris_label=iris.target\n",
    "iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df.head(3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data,iris_label,\n",
    "                                                   test_size=0.2, random_state=11)\n",
    "dt_clf=DecisionTreeClassifier(random_state=11)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred=dt_clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6df90c",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9b20f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2 2]\n",
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(9, 6)\n",
      "feature 들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n",
      "feature 들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n",
      "feature 들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서','믹서']\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels=encoder.transform(items)\n",
    "print('인코딩 변환값:', labels)\n",
    "\n",
    "#원-핫 인코딩\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서','믹서']\n",
    "items=np.array(items).reshape(-1,1)\n",
    "oh_encoder=OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels=oh_encoder.transform(items)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)\n",
    "df=pd.DataFrame({'item':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서','믹서']})\n",
    "pd.get_dummies(df)\n",
    "\n",
    "#StandardScaler\n",
    "iris=load_iris()\n",
    "iris_data=iris.data\n",
    "iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df.var())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled=scaler.transform(iris_df)\n",
    "iris_df_scaled=pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df_scaled.var())\n",
    "\n",
    "#MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled=scaler.transform(iris_df)\n",
    "iris_df_scaled=pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature 들의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b5a5c",
   "metadata": {},
   "source": [
    "## Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5dfa11",
   "metadata": {},
   "source": [
    "### 피마 인디언 당뇨병 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "diabetes_data=pd.read_csv('diabetes.csv')\n",
    "print(diabetes_data['Outcome'].value_counts())\n",
    "diabetes_data.head(3)\n",
    "\n",
    "diabetes_data.info()\n",
    "\n",
    "X=diabetes_data.iloc[:,:-1]\n",
    "y=diabetes_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=156,stratify=y)\n",
    "lr_clf=LogisticRegression(solver='linear')\n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred=lr_clf.predict(X_test)\n",
    "pred_proba=lr_clf.predict_proba(X_test)[:,1]\n",
    "get_clf_eval(y_test,pred,pred_proba)\n",
    "\n",
    "pred_proba_c1=lr_clf.predict_proba(X_test)[:,1]\n",
    "precision_recall_curve_plot(y_test,pred_proba_c1)\n",
    "\n",
    "diabetes_data.describe()\n",
    "plt.hist(diabetes_data['Glucos'],bins=100)\n",
    "plt.show()\n",
    "\n",
    "zero_features=['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n",
    "total_count=diabetes_data['Glucose'].count()\n",
    "for feature in zero_features:\n",
    "    zero_count=diabetes_data[diabetes_data[feature]==0][feature].count()\n",
    "    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f}%'.format(feature,zero_count,100*zero_count/total_count))\n",
    "    \n",
    "mean_zero_features=diabetes_data[zero_features].mean()\n",
    "diabetes_data[zero_features]=diabetes_data[zero_features].replace(0,mean_zero_features)\n",
    "\n",
    "X=diabetes_data.iloc[:,:-1]\n",
    "y=diabetes_data.iloc[:,-1]\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2,random_state=156,stratify=y)\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred=lr_clf.predict(X_test)\n",
    "pred_proba=lr_clf.predict_proba(X_test)[:,1]\n",
    "get_clf_eval(y_test,pred,pred_proba)\n",
    "\n",
    "thresholds=[0.3,0.33,0.36,0.39,0.42,0.45,0.48,0.50]\n",
    "pred_proba=lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test,pred_proba[:,1].reshape(-1,1),thresholds)\n",
    "\n",
    "binarizer=Binarizer(threshold=0.48)\n",
    "\n",
    "pred_th_0488=binarizer.fit_transform(pred_proba[:,1].reshape(-1,1))\n",
    "get_clf_eval(y_test,pred_th_048,pred_proba[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
