{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUHfXkPAORh"
      },
      "source": [
        "ğŸ“Œ week5 ë‚´ìš© ì£¼ì°¨ì— í•´ë‹¹ë˜ëŠ” ê³¼ì œëŠ” Glove ëª¨ë¸ ì‹¤ìŠµ, NER task ì‹¤ìŠµ, Dependency Parsing task ì‹¤ìŠµìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (**ì°¸ê³ ** : **ì œì¶œì€ week6 branch ë³µìŠµê³¼ì œë¡œ!**)\n",
        "\n",
        "ğŸ“Œ ìœ„í‚¤ë…ìŠ¤ì˜ ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ êµì¬ ì‹¤ìŠµ, ìºê¸€ ë…¸íŠ¸ë¶ ë“±ì˜ ìë£Œë¡œ êµ¬ì„±ë˜ì–´ìˆëŠ” ê³¼ì œì…ë‹ˆë‹¤. \n",
        "\n",
        "ğŸ“Œ ì•ˆë‚´ëœ ë§í¬ì— ë§ì¶”ì–´ **ì§ì ‘ ì½”ë“œë¥¼ ë”°ë¼ ì¹˜ë©´ì„œ (í•„ì‚¬)** í•´ë‹¹ nlp task ì˜ ê¸°ë³¸ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë©”ì„œë“œë¥¼ ìˆ™ì§€í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ğŸ˜Š í•„ìˆ˜ë¼ê³  ì²´í¬í•œ ë¶€ë¶„ì€ ê³¼ì œì— ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì£¼ì‹œê³ , ì„ íƒìœ¼ë¡œ ì²´í¬í•œ ë¶€ë¶„ì€ ììœ¨ì ìœ¼ë¡œ ìŠ¤í„°ë”” í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Œ ê¶ê¸ˆí•œ ì‚¬í•­ì€ ê¹ƒí—ˆë¸Œ ì´ìŠˆë‚˜, ì¹´í†¡ë°©, ì„¸ì…˜ ë°œí‘œ ì‹œì‘ ì´ì „ ì‹œê°„ ë“±ì„ í™œìš©í•˜ì—¬ ììœ ë¡­ê²Œ ê³µìœ í•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjTSbcxBB6o",
        "outputId": "3b224ca8-b18f-49de-a1b8-ec221ca85538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk colab í™˜ê²½ì—ì„œ ì‹¤í–‰ì‹œ í•„ìš”í•œ ì½”ë“œì…ë‹ˆë‹¤. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPZn15zBHIv"
      },
      "source": [
        "### 1ï¸âƒ£ **Glove**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11biHcUuBaH"
      },
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n",
        "* ìŠ¤íƒ í¬ë“œ ëŒ€í•™ì—ì„œ ê°œë°œí•œ ì¹´ìš´íŠ¸ ê¸°ë°˜ê³¼ ì˜ˆì¸¡ ê¸°ë°˜ì„ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ ì„ë² ë”© ë°©ë²•ë¡  \n",
        "* word2vec ì˜ ë‹¨ì ì„ ë³´ì™„í•´ì„œ ë‚˜ì˜¨ ëª¨ë¸ \n",
        "* glove model ì˜ **input ì€ ë°˜ë“œì‹œ ë™ì‹œë“±ì¥í–‰ë ¬ í˜•íƒœ**ì—¬ì•¼ í•œë‹¤ â­\n",
        "\n",
        "![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ğŸ¤” í•œêµ­ì–´ ì˜ˆì œëŠ” ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” k-Glove ë¡œ ì†Œê°œë˜ëŠ” ì—°êµ¬ê°€ ìˆê¸´ í•œë°, ì¢€ ë” ì•Œì•„ë´ì•¼ í•  ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "â• [ë…¼ë¬¸1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n",
        "\n",
        "\n",
        "â•[ë…¼ë¬¸2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asGcGy6fBM1E"
      },
      "source": [
        "ğŸ”¹ **1-(1)** glove python\n",
        "\n",
        "* [ì‹¤ìŠµ : basic code](https://wikidocs.net/22885) ğŸ‘‰ í•„ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31NoJdu5t3p",
        "outputId": "4ca1868c-a793-4433-9c45-8a818b08eb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: glove_python_binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "pip install glove_python_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta6QgoKO5uXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e010ea-d368-4280-9864-c24f33d6ca56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 20 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n"
          ]
        }
      ],
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "result = []\n",
        "\n",
        "corpus = Corpus()\n",
        "\n",
        "# í›ˆë ¨ ë°ì´í„°ë¡œë¶€í„° GloVeì—ì„œ ì‚¬ìš©í•  ë™ì‹œ ë“±ì¥ í–‰ë ¬ì„ ìƒì„±\n",
        "corpus.fit(result, window=5)\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "\n",
        "#í•™ìŠµì— ì´ìš©í•  ì“°ë ˆë“œì˜ ê°œìˆ˜ëŠ” 4ë¡œ ì„¤ì •, ì—í¬í¬ëŠ” 20\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ADfVM9lO9NE"
      },
      "source": [
        "ğŸ”¹ **1-(2)** pre-trained glove \n",
        "\n",
        "* **ì‚¬ì „í•™ìŠµëª¨ë¸** : ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë“¤ì„ ë‹¤ë¥¸ ë¬¸ì œì— í•™ìŠµì‹œí‚¨ ê°€ì¤‘ì¹˜ë“¤ë¡œ ì´ˆê¸°í™”í•˜ëŠ” ë°©ë²•ì´ë‹¤.ì‚¬ì „ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•´ í•™ìŠµí•˜ê³ ì í•˜ëŠ” ë³¸ë˜ ë¬¸ì œë¥¼ í•˜ìœ„ë¬¸ì œë¼ê³  í•œë‹¤. \n",
        "\n",
        "* [ì‹¤ìŠµ : ë¬¸ì¥ì˜ ê¸ë¶€ì •ì„ íŒë‹¨í•˜ëŠ” ê°ì„± ë¶„ë¥˜ ëª¨ë¸ ë§Œë“¤ê¸°](https://wikidocs.net/33793) ğŸ‘‰ í•„ìˆ˜\n",
        "  * [ì„¤ëª…ì°¸ê³ ](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n",
        "* pre-trained data ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¼\n",
        "* kaggle ëŒ€íšŒì—ì„œ ì£¼ë¡œ ì´ ë°©ì‹ì„ ë§ì´ ì‚¬ìš©í•¨\n",
        "  * [ì°¸ê³ ](https://lsjsj92.tistory.com/455)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "output_dim = 128\n",
        "input_length = 500\n",
        "\n",
        "v = Embedding(vocab_size, output_dim, input_length=input_length)"
      ],
      "metadata": {
        "id": "o7nmboPKbBid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "q74XmiQOeTvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # íŒ¨ë”©ì„ ê³ ë ¤í•˜ì—¬ +1\n",
        "print('ë‹¨ì–´ ì§‘í•© :',vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvIDqPw3ehDv",
        "outputId": "050bd619-5f5a-40bb-f594-c2f105a551a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‹¨ì–´ ì§‘í•© : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print('ì •ìˆ˜ ì¸ì½”ë”© ê²°ê³¼ :',X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHK3vDZ8ekC5",
        "outputId": "afcbbe96-5194-4ab4-96a9-87e1e1ef42c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì •ìˆ˜ ì¸ì½”ë”© ê²°ê³¼ : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('ìµœëŒ€ ê¸¸ì´ :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TVWjLjqenIx",
        "outputId": "c7f76158-cbc7-432c-f752-4df3f573acf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìµœëŒ€ ê¸¸ì´ : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_train = np.array(y_train)\n",
        "print('íŒ¨ë”© ê²°ê³¼ :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoWPn8kXeovw",
        "outputId": "f9bf0ddd-6815-40bf-fac6-e79811db475c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "íŒ¨ë”© ê²°ê³¼ :\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "embedding_dim = 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9zDkt3qeqL3",
        "outputId": "e94394a5-66eb-41f5-e177-1443ffacdb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 7 samples\n",
            "Epoch 1/100\n",
            "7/7 - 0s - loss: 0.6916 - acc: 0.4286 - 53ms/epoch - 8ms/sample\n",
            "Epoch 2/100\n",
            "7/7 - 0s - loss: 0.6903 - acc: 0.4286 - 10ms/epoch - 1ms/sample\n",
            "Epoch 3/100\n",
            "7/7 - 0s - loss: 0.6889 - acc: 0.5714 - 5ms/epoch - 752us/sample\n",
            "Epoch 4/100\n",
            "7/7 - 0s - loss: 0.6876 - acc: 0.7143 - 6ms/epoch - 911us/sample\n",
            "Epoch 5/100\n",
            "7/7 - 0s - loss: 0.6862 - acc: 0.7143 - 5ms/epoch - 774us/sample\n",
            "Epoch 6/100\n",
            "7/7 - 0s - loss: 0.6849 - acc: 0.7143 - 4ms/epoch - 597us/sample\n",
            "Epoch 7/100\n",
            "7/7 - 0s - loss: 0.6835 - acc: 0.7143 - 4ms/epoch - 641us/sample\n",
            "Epoch 8/100\n",
            "7/7 - 0s - loss: 0.6821 - acc: 0.7143 - 3ms/epoch - 460us/sample\n",
            "Epoch 9/100\n",
            "7/7 - 0s - loss: 0.6808 - acc: 0.7143 - 4ms/epoch - 566us/sample\n",
            "Epoch 10/100\n",
            "7/7 - 0s - loss: 0.6794 - acc: 0.7143 - 5ms/epoch - 768us/sample\n",
            "Epoch 11/100\n",
            "7/7 - 0s - loss: 0.6780 - acc: 0.7143 - 4ms/epoch - 605us/sample\n",
            "Epoch 12/100\n",
            "7/7 - 0s - loss: 0.6767 - acc: 0.7143 - 4ms/epoch - 558us/sample\n",
            "Epoch 13/100\n",
            "7/7 - 0s - loss: 0.6753 - acc: 0.7143 - 3ms/epoch - 487us/sample\n",
            "Epoch 14/100\n",
            "7/7 - 0s - loss: 0.6739 - acc: 0.7143 - 3ms/epoch - 483us/sample\n",
            "Epoch 15/100\n",
            "7/7 - 0s - loss: 0.6725 - acc: 0.7143 - 4ms/epoch - 614us/sample\n",
            "Epoch 16/100\n",
            "7/7 - 0s - loss: 0.6711 - acc: 0.7143 - 8ms/epoch - 1ms/sample\n",
            "Epoch 17/100\n",
            "7/7 - 0s - loss: 0.6697 - acc: 0.7143 - 4ms/epoch - 510us/sample\n",
            "Epoch 18/100\n",
            "7/7 - 0s - loss: 0.6683 - acc: 0.7143 - 3ms/epoch - 478us/sample\n",
            "Epoch 19/100\n",
            "7/7 - 0s - loss: 0.6669 - acc: 0.7143 - 3ms/epoch - 488us/sample\n",
            "Epoch 20/100\n",
            "7/7 - 0s - loss: 0.6654 - acc: 0.7143 - 4ms/epoch - 596us/sample\n",
            "Epoch 21/100\n",
            "7/7 - 0s - loss: 0.6640 - acc: 0.7143 - 3ms/epoch - 485us/sample\n",
            "Epoch 22/100\n",
            "7/7 - 0s - loss: 0.6626 - acc: 0.7143 - 3ms/epoch - 486us/sample\n",
            "Epoch 23/100\n",
            "7/7 - 0s - loss: 0.6611 - acc: 0.7143 - 5ms/epoch - 683us/sample\n",
            "Epoch 24/100\n",
            "7/7 - 0s - loss: 0.6597 - acc: 0.7143 - 3ms/epoch - 496us/sample\n",
            "Epoch 25/100\n",
            "7/7 - 0s - loss: 0.6582 - acc: 0.7143 - 4ms/epoch - 642us/sample\n",
            "Epoch 26/100\n",
            "7/7 - 0s - loss: 0.6568 - acc: 0.7143 - 4ms/epoch - 512us/sample\n",
            "Epoch 27/100\n",
            "7/7 - 0s - loss: 0.6553 - acc: 0.7143 - 4ms/epoch - 535us/sample\n",
            "Epoch 28/100\n",
            "7/7 - 0s - loss: 0.6538 - acc: 0.7143 - 4ms/epoch - 617us/sample\n",
            "Epoch 29/100\n",
            "7/7 - 0s - loss: 0.6523 - acc: 0.7143 - 4ms/epoch - 536us/sample\n",
            "Epoch 30/100\n",
            "7/7 - 0s - loss: 0.6508 - acc: 0.7143 - 4ms/epoch - 625us/sample\n",
            "Epoch 31/100\n",
            "7/7 - 0s - loss: 0.6493 - acc: 0.7143 - 5ms/epoch - 655us/sample\n",
            "Epoch 32/100\n",
            "7/7 - 0s - loss: 0.6478 - acc: 0.7143 - 3ms/epoch - 482us/sample\n",
            "Epoch 33/100\n",
            "7/7 - 0s - loss: 0.6463 - acc: 0.7143 - 3ms/epoch - 473us/sample\n",
            "Epoch 34/100\n",
            "7/7 - 0s - loss: 0.6448 - acc: 0.7143 - 4ms/epoch - 542us/sample\n",
            "Epoch 35/100\n",
            "7/7 - 0s - loss: 0.6432 - acc: 0.7143 - 6ms/epoch - 847us/sample\n",
            "Epoch 36/100\n",
            "7/7 - 0s - loss: 0.6417 - acc: 0.7143 - 3ms/epoch - 495us/sample\n",
            "Epoch 37/100\n",
            "7/7 - 0s - loss: 0.6401 - acc: 0.7143 - 4ms/epoch - 501us/sample\n",
            "Epoch 38/100\n",
            "7/7 - 0s - loss: 0.6386 - acc: 0.7143 - 4ms/epoch - 504us/sample\n",
            "Epoch 39/100\n",
            "7/7 - 0s - loss: 0.6370 - acc: 0.7143 - 4ms/epoch - 638us/sample\n",
            "Epoch 40/100\n",
            "7/7 - 0s - loss: 0.6354 - acc: 0.7143 - 4ms/epoch - 621us/sample\n",
            "Epoch 41/100\n",
            "7/7 - 0s - loss: 0.6338 - acc: 0.7143 - 3ms/epoch - 498us/sample\n",
            "Epoch 42/100\n",
            "7/7 - 0s - loss: 0.6322 - acc: 0.7143 - 3ms/epoch - 474us/sample\n",
            "Epoch 43/100\n",
            "7/7 - 0s - loss: 0.6306 - acc: 0.7143 - 4ms/epoch - 572us/sample\n",
            "Epoch 44/100\n",
            "7/7 - 0s - loss: 0.6290 - acc: 0.7143 - 5ms/epoch - 676us/sample\n",
            "Epoch 45/100\n",
            "7/7 - 0s - loss: 0.6274 - acc: 0.7143 - 3ms/epoch - 451us/sample\n",
            "Epoch 46/100\n",
            "7/7 - 0s - loss: 0.6258 - acc: 0.7143 - 5ms/epoch - 677us/sample\n",
            "Epoch 47/100\n",
            "7/7 - 0s - loss: 0.6242 - acc: 0.7143 - 3ms/epoch - 450us/sample\n",
            "Epoch 48/100\n",
            "7/7 - 0s - loss: 0.6225 - acc: 0.7143 - 3ms/epoch - 466us/sample\n",
            "Epoch 49/100\n",
            "7/7 - 0s - loss: 0.6209 - acc: 0.7143 - 3ms/epoch - 476us/sample\n",
            "Epoch 50/100\n",
            "7/7 - 0s - loss: 0.6192 - acc: 0.7143 - 4ms/epoch - 566us/sample\n",
            "Epoch 51/100\n",
            "7/7 - 0s - loss: 0.6175 - acc: 0.7143 - 4ms/epoch - 514us/sample\n",
            "Epoch 52/100\n",
            "7/7 - 0s - loss: 0.6159 - acc: 0.7143 - 4ms/epoch - 533us/sample\n",
            "Epoch 53/100\n",
            "7/7 - 0s - loss: 0.6142 - acc: 0.7143 - 6ms/epoch - 855us/sample\n",
            "Epoch 54/100\n",
            "7/7 - 0s - loss: 0.6125 - acc: 0.8571 - 3ms/epoch - 456us/sample\n",
            "Epoch 55/100\n",
            "7/7 - 0s - loss: 0.6108 - acc: 0.8571 - 3ms/epoch - 491us/sample\n",
            "Epoch 56/100\n",
            "7/7 - 0s - loss: 0.6091 - acc: 0.8571 - 5ms/epoch - 643us/sample\n",
            "Epoch 57/100\n",
            "7/7 - 0s - loss: 0.6074 - acc: 0.8571 - 3ms/epoch - 468us/sample\n",
            "Epoch 58/100\n",
            "7/7 - 0s - loss: 0.6057 - acc: 0.8571 - 6ms/epoch - 869us/sample\n",
            "Epoch 59/100\n",
            "7/7 - 0s - loss: 0.6039 - acc: 0.8571 - 3ms/epoch - 480us/sample\n",
            "Epoch 60/100\n",
            "7/7 - 0s - loss: 0.6022 - acc: 0.8571 - 3ms/epoch - 481us/sample\n",
            "Epoch 61/100\n",
            "7/7 - 0s - loss: 0.6004 - acc: 0.8571 - 3ms/epoch - 489us/sample\n",
            "Epoch 62/100\n",
            "7/7 - 0s - loss: 0.5987 - acc: 0.8571 - 7ms/epoch - 1ms/sample\n",
            "Epoch 63/100\n",
            "7/7 - 0s - loss: 0.5969 - acc: 0.8571 - 3ms/epoch - 488us/sample\n",
            "Epoch 64/100\n",
            "7/7 - 0s - loss: 0.5952 - acc: 0.8571 - 3ms/epoch - 448us/sample\n",
            "Epoch 65/100\n",
            "7/7 - 0s - loss: 0.5934 - acc: 1.0000 - 3ms/epoch - 471us/sample\n",
            "Epoch 66/100\n",
            "7/7 - 0s - loss: 0.5916 - acc: 1.0000 - 3ms/epoch - 487us/sample\n",
            "Epoch 67/100\n",
            "7/7 - 0s - loss: 0.5898 - acc: 1.0000 - 4ms/epoch - 552us/sample\n",
            "Epoch 68/100\n",
            "7/7 - 0s - loss: 0.5880 - acc: 1.0000 - 6ms/epoch - 912us/sample\n",
            "Epoch 69/100\n",
            "7/7 - 0s - loss: 0.5862 - acc: 1.0000 - 4ms/epoch - 510us/sample\n",
            "Epoch 70/100\n",
            "7/7 - 0s - loss: 0.5844 - acc: 1.0000 - 5ms/epoch - 657us/sample\n",
            "Epoch 71/100\n",
            "7/7 - 0s - loss: 0.5826 - acc: 1.0000 - 4ms/epoch - 508us/sample\n",
            "Epoch 72/100\n",
            "7/7 - 0s - loss: 0.5807 - acc: 1.0000 - 5ms/epoch - 686us/sample\n",
            "Epoch 73/100\n",
            "7/7 - 0s - loss: 0.5789 - acc: 1.0000 - 3ms/epoch - 489us/sample\n",
            "Epoch 74/100\n",
            "7/7 - 0s - loss: 0.5770 - acc: 1.0000 - 4ms/epoch - 606us/sample\n",
            "Epoch 75/100\n",
            "7/7 - 0s - loss: 0.5752 - acc: 1.0000 - 6ms/epoch - 893us/sample\n",
            "Epoch 76/100\n",
            "7/7 - 0s - loss: 0.5733 - acc: 1.0000 - 3ms/epoch - 477us/sample\n",
            "Epoch 77/100\n",
            "7/7 - 0s - loss: 0.5715 - acc: 1.0000 - 3ms/epoch - 497us/sample\n",
            "Epoch 78/100\n",
            "7/7 - 0s - loss: 0.5696 - acc: 1.0000 - 4ms/epoch - 502us/sample\n",
            "Epoch 79/100\n",
            "7/7 - 0s - loss: 0.5677 - acc: 1.0000 - 4ms/epoch - 546us/sample\n",
            "Epoch 80/100\n",
            "7/7 - 0s - loss: 0.5658 - acc: 1.0000 - 3ms/epoch - 447us/sample\n",
            "Epoch 81/100\n",
            "7/7 - 0s - loss: 0.5639 - acc: 1.0000 - 3ms/epoch - 440us/sample\n",
            "Epoch 82/100\n",
            "7/7 - 0s - loss: 0.5621 - acc: 1.0000 - 4ms/epoch - 520us/sample\n",
            "Epoch 83/100\n",
            "7/7 - 0s - loss: 0.5601 - acc: 1.0000 - 5ms/epoch - 653us/sample\n",
            "Epoch 84/100\n",
            "7/7 - 0s - loss: 0.5582 - acc: 1.0000 - 6ms/epoch - 797us/sample\n",
            "Epoch 85/100\n",
            "7/7 - 0s - loss: 0.5563 - acc: 1.0000 - 3ms/epoch - 492us/sample\n",
            "Epoch 86/100\n",
            "7/7 - 0s - loss: 0.5544 - acc: 1.0000 - 4ms/epoch - 630us/sample\n",
            "Epoch 87/100\n",
            "7/7 - 0s - loss: 0.5525 - acc: 1.0000 - 3ms/epoch - 479us/sample\n",
            "Epoch 88/100\n",
            "7/7 - 0s - loss: 0.5505 - acc: 1.0000 - 4ms/epoch - 565us/sample\n",
            "Epoch 89/100\n",
            "7/7 - 0s - loss: 0.5486 - acc: 1.0000 - 3ms/epoch - 481us/sample\n",
            "Epoch 90/100\n",
            "7/7 - 0s - loss: 0.5466 - acc: 1.0000 - 3ms/epoch - 471us/sample\n",
            "Epoch 91/100\n",
            "7/7 - 0s - loss: 0.5447 - acc: 1.0000 - 3ms/epoch - 471us/sample\n",
            "Epoch 92/100\n",
            "7/7 - 0s - loss: 0.5427 - acc: 1.0000 - 3ms/epoch - 500us/sample\n",
            "Epoch 93/100\n",
            "7/7 - 0s - loss: 0.5408 - acc: 1.0000 - 3ms/epoch - 437us/sample\n",
            "Epoch 94/100\n",
            "7/7 - 0s - loss: 0.5388 - acc: 1.0000 - 3ms/epoch - 486us/sample\n",
            "Epoch 95/100\n",
            "7/7 - 0s - loss: 0.5368 - acc: 1.0000 - 4ms/epoch - 634us/sample\n",
            "Epoch 96/100\n",
            "7/7 - 0s - loss: 0.5349 - acc: 1.0000 - 3ms/epoch - 489us/sample\n",
            "Epoch 97/100\n",
            "7/7 - 0s - loss: 0.5329 - acc: 1.0000 - 5ms/epoch - 682us/sample\n",
            "Epoch 98/100\n",
            "7/7 - 0s - loss: 0.5309 - acc: 1.0000 - 5ms/epoch - 673us/sample\n",
            "Epoch 99/100\n",
            "7/7 - 0s - loss: 0.5289 - acc: 1.0000 - 3ms/epoch - 497us/sample\n",
            "Epoch 100/100\n",
            "7/7 - 0s - loss: 0.5269 - acc: 1.0000 - 5ms/epoch - 665us/sample\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb87e3a2150>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktGZyzrVevaj",
        "outputId": "9f418b23-30f2-4ea0-9d29-984a7327d7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_3Dsd0mexQ3",
        "outputId": "dbec013b-90c9-4448-d7a2-b7f372451e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve, urlopen\n",
        "import gzip\n",
        "import zipfile\n",
        "\n",
        "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
        "zf = zipfile.ZipFile('glove.6B.zip')\n",
        "zf.extractall() \n",
        "zf.close()"
      ],
      "metadata": {
        "id": "HJ6Yp5bTezn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dict = dict()\n",
        "\n",
        "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "\n",
        "    # 100ê°œì˜ ê°’ì„ ê°€ì§€ëŠ” arrayë¡œ ë³€í™˜\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%sê°œì˜ Embedding vectorê°€ ìˆìŠµë‹ˆë‹¤.' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNnwrdzie0if",
        "outputId": "dfce0adf-9032-47c2-a02b-618fac1c9b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000ê°œì˜ Embedding vectorê°€ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print('ë²¡í„°ì˜ ì°¨ì› ìˆ˜ :',len(embedding_dict['respectable']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR4DhJioe2we",
        "outputId": "abd75671-27b8-4e28-ef95-ad7e597ffc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "ë²¡í„°ì˜ ì°¨ì› ìˆ˜ : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('ì„ë² ë”© í–‰ë ¬ì˜ í¬ê¸°(shape) :',np.shape(embedding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKiXXqj2e5mR",
        "outputId": "5bce9e1c-a599-45f1-9e2d-30602ab02dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì„ë² ë”© í–‰ë ¬ì˜ í¬ê¸°(shape) : (16, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBqszD2ze7A0",
        "outputId": "fa8d2761-1165-4ce5-d5da-ea1e8bc6e311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('ë‹¨ì–´ greatì˜ ë§µí•‘ëœ ì •ìˆ˜ :',tokenizer.word_index['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXlLy47fe9n_",
        "outputId": "d09211db-8a0f-4736-9ae2-21e06cee051c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‹¨ì–´ greatì˜ ë§µí•‘ëœ ì •ìˆ˜ : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozUcIcsXe_LK",
        "outputId": "e9bf477d-3f50-484f-df39-881106db9b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.013786   0.38216    0.53236    0.15261   -0.29694   -0.20558\n",
            " -0.41846   -0.58437   -0.77355   -0.87866   -0.37858   -0.18516\n",
            " -0.128     -0.20584   -0.22925   -0.42599    0.3725     0.26077\n",
            " -1.0702     0.62916   -0.091469   0.70348   -0.4973    -0.77691\n",
            "  0.66045    0.09465   -0.44893    0.018917   0.33146   -0.35022\n",
            " -0.35789    0.030313   0.22253   -0.23236   -0.19719   -0.0053125\n",
            " -0.25848    0.58081   -0.10705   -0.17845   -0.16206    0.087086\n",
            "  0.63029   -0.76649    0.51619    0.14073    1.019     -0.43136\n",
            "  0.46138   -0.43585   -0.47568    0.19226    0.36065    0.78987\n",
            "  0.088945  -2.7814    -0.15366    0.01015    1.1798     0.15168\n",
            " -0.050112   1.2626    -0.77527    0.36031    0.95761   -0.11385\n",
            "  0.28035   -0.02591    0.31246   -0.15424    0.3778    -0.13599\n",
            "  0.2946    -0.31579    0.42943    0.086969   0.019169  -0.27242\n",
            " -0.31696    0.37327    0.61997    0.13889    0.17188    0.30363\n",
            " -1.2776     0.044423  -0.52736   -0.88536   -0.19428   -0.61947\n",
            " -0.10146   -0.26301   -0.061707   0.36627   -0.95223   -0.39346\n",
            " -0.69183   -1.0426     0.28855    0.63056  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # ë‹¨ì–´ì™€ ë§µí•‘ë˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ì„ë² ë”© ë²¡í„°ê°’\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ],
      "metadata": {
        "id": "RysjIzg0fA9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJhD8cfYfCBs",
        "outputId": "9fdb0af2-70ba-4742-94e3-3ba68b42d831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.013786  ,  0.38216001,  0.53236002,  0.15261   , -0.29694   ,\n",
              "       -0.20558   , -0.41846001, -0.58437002, -0.77354997, -0.87866002,\n",
              "       -0.37858   , -0.18516   , -0.12800001, -0.20584001, -0.22925   ,\n",
              "       -0.42598999,  0.3725    ,  0.26076999, -1.07019997,  0.62915999,\n",
              "       -0.091469  ,  0.70348001, -0.4973    , -0.77691001,  0.66044998,\n",
              "        0.09465   , -0.44893   ,  0.018917  ,  0.33146   , -0.35021999,\n",
              "       -0.35789001,  0.030313  ,  0.22253001, -0.23236001, -0.19719   ,\n",
              "       -0.0053125 , -0.25848001,  0.58081001, -0.10705   , -0.17845   ,\n",
              "       -0.16205999,  0.087086  ,  0.63028997, -0.76648998,  0.51618999,\n",
              "        0.14072999,  1.01900005, -0.43136001,  0.46138   , -0.43584999,\n",
              "       -0.47567999,  0.19226   ,  0.36065   ,  0.78987002,  0.088945  ,\n",
              "       -2.78139997, -0.15366   ,  0.01015   ,  1.17980003,  0.15167999,\n",
              "       -0.050112  ,  1.26259995, -0.77526999,  0.36030999,  0.95761001,\n",
              "       -0.11385   ,  0.28035   , -0.02591   ,  0.31246001, -0.15424   ,\n",
              "        0.37779999, -0.13598999,  0.29460001, -0.31579   ,  0.42943001,\n",
              "        0.086969  ,  0.019169  , -0.27241999, -0.31696001,  0.37327   ,\n",
              "        0.61997002,  0.13889   ,  0.17188001,  0.30362999, -1.27760005,\n",
              "        0.044423  , -0.52736002, -0.88536   , -0.19428   , -0.61947   ,\n",
              "       -0.10146   , -0.26301   , -0.061707  ,  0.36627001, -0.95222998,\n",
              "       -0.39346001, -0.69182998, -1.04260004,  0.28854999,  0.63055998])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "output_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIvV1_r0fKSQ",
        "outputId": "eada9319-003d-4d4d-bc03-204ae8643dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 1s - loss: 0.7756 - acc: 0.4286 - 563ms/epoch - 563ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 0.7528 - acc: 0.4286 - 6ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 0.7309 - acc: 0.4286 - 9ms/epoch - 9ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 0.7097 - acc: 0.4286 - 8ms/epoch - 8ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 0.6893 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.6696 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.6508 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.6326 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.6152 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.5984 - acc: 0.7143 - 7ms/epoch - 7ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.5823 - acc: 0.7143 - 6ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.5669 - acc: 0.7143 - 7ms/epoch - 7ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.5520 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.5377 - acc: 0.7143 - 8ms/epoch - 8ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.5239 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.5107 - acc: 0.7143 - 4ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.4979 - acc: 0.7143 - 9ms/epoch - 9ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.4856 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.4737 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.4623 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.4512 - acc: 0.8571 - 7ms/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.4405 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.4302 - acc: 0.8571 - 8ms/epoch - 8ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.4202 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.4106 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.4012 - acc: 0.8571 - 12ms/epoch - 12ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.3921 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.3834 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.3748 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.3666 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.3585 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.3507 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.3432 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.3358 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.3286 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.3217 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.3149 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.3084 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.3020 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.2957 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.2897 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.2838 - acc: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.2781 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.2725 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.2671 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.2619 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.2567 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.2517 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.2469 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.2422 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.2376 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.2331 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.2288 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.2245 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.2204 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.2164 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.2125 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.2087 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.2050 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.2014 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.1979 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.1944 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.1911 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.1879 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.1847 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.1816 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.1786 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.1757 - acc: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.1728 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.1701 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.1674 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.1647 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.1621 - acc: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.1596 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.1571 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.1547 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.1524 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.1501 - acc: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.1479 - acc: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.1457 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.1436 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.1415 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.1394 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.1375 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.1355 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.1336 - acc: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.1318 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.1299 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.1282 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.1264 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.1247 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.1230 - acc: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.1214 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.1198 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.1183 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.1167 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.1152 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.1138 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.1123 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.1109 - acc: 1.0000 - 5ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8e8b78710>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_wcrE5PtLMI"
      },
      "source": [
        "ğŸ”¹ **1-(3)** fine tuning glove\n",
        "* ë¯¸ì„¸ì¡°ì • : ì‚¬ì „ í•™ìŠµí•œ ëª¨ë“  ê°€ì¤‘ì¹˜ì™€ ë”ë¶ˆì–´ í•˜ìœ„ ë¬¸ì œë¥¼ ìœ„í•œ ìµœì†Œí•œì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¶”ê°€í•´ ëª¨ë¸ì„ ì¶”ê°€ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ë‹¤. \n",
        "\n",
        "* fine tuning ì´ í•„ìš”í•œ ê²½ìš° \n",
        "  * pretrained model ì— ë°ì´í„°ì…‹ì— ìˆëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš° \n",
        "  * ë°ì´í„° ì§‘í•©ì´ ë„ˆë¬´ ì‘ì•„ì„œ ì „ì²´ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ì–´ë ¤ìš´ ê²½ìš° \n",
        "\n",
        "* [Mittens ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) ğŸ‘‰ í•„ìˆ˜\n",
        "  *  GloVe ì„ë² ë”©ì„ fine-tuning í•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "  * [github](https://github.com/roamanalytics/mittens)\n",
        "\n",
        "* [í•œêµ­ì–´ ì†Œì„¤ í…ìŠ¤íŠ¸ ë°ì´í„° ë¯¸ì„¸ì¡°ì • ëª¨ë¸ í•™ìŠµ - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) ğŸ‘‰ ì„ íƒ (glove ëª¨ë¸ ì˜ˆì œëŠ” ì•„ë‹™ë‹ˆë‹¤. fine-tuning ì— ì´ˆì ì„ ë‘ì–´ì„œ ì°¸ê³ í•´ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U mittens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ9wrD9HhBks",
        "outputId": "c79164e8-8427-43f9-be1a-20b43982f51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mittens\n",
            "  Downloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mittens) (1.21.6)\n",
            "Installing collected packages: mittens\n",
            "Successfully installed mittens-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown\n",
        "from mittens import GloVe, Mittens\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "Hsc6oP8XikDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def glove2dict(glove_filename):\n",
        "    with open(glove_filename, encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
        "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
        "                for line in reader}\n",
        "    return embed"
      ],
      "metadata": {
        "id": "3DqRk2vWjdvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-OB9Siga3G"
      },
      "source": [
        "* (ì°¸ê³ ) word2vec pretrained example\n",
        "\n",
        "â• [word2vec ì‚¬ì „í•™ìŠµ ëª¨ë¸ -í•œêµ­ì–´1](http://doc.mindscale.kr/km/unstructured/11.html)\n",
        "\n",
        "â• [word2vec ì‚¬ì „í•™ìŠµ - í•œêµ­ì–´2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUWWDwdiPLS9"
      },
      "source": [
        "### **2ï¸âƒ£ NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N0B4VknPkTk"
      },
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n",
        "* ê°œì²´ëª… ì¸ì‹ì„ ì‚¬ìš©í•˜ë©´ ì½”í¼ìŠ¤ë¡œë¶€í„° ì–´ë–¤ ë‹¨ì–´ê°€ ì‚¬ëŒ, ì¥ì†Œ, ì¡°ì§ ë“±ì„ ì˜ë¯¸í•˜ëŠ” ë‹¨ì–´ì¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgla1BuPRqJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "ğŸ”¹ **2-(1)** NER task by nltk library\n",
        "\n",
        "\n",
        "* nltk ì—ì„œëŠ” ê°œì²´ëª… ì¸ì‹ê¸° (NER chunker) ë¥¼ ì§€ì›í•˜ê³  ìˆë‹¤. \n",
        "* ne_chunk ëŠ” ê°œì²´ëª…ì„ íƒœê¹…í•˜ê¸° ìœ„í•´ì„œ ì•ì„œ í’ˆì‚¬ íƒœê¹… pos_tag ê°€ ìˆ˜í–‰ë˜ì–´ì•¼ í•œë‹¤. \n",
        "\n",
        "\n",
        "ğŸ“Œ [basic code](https://wikidocs.net/30682) ğŸ‘‰ í•„ìˆ˜ \n",
        "\n",
        "ğŸ“Œ [BIO í‘œí˜„, LSTMì„ í™œìš©í•œ NER ì‹¤ìŠµ](https://wikidocs.net/24682) ğŸ‘‰ ì„ íƒ\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap4vHDQ1NwC7",
        "outputId": "e232e1d4-0b32-4d53-c78e-58e7983a6d92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "diaZweMyAxJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8b69bc-43c6-486d-89c8-901c63bad79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"James is working at Disney in London\"\n",
        "\n",
        "#í† í°í™” í›„ í’ˆì‚¬ íƒœê¹…\n",
        "\n",
        "tokenized_sentence = pos_tag(word_tokenize(sentence))\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1k09tKha3Lgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e789097-e1ee-4221-b424-5d336cfd854a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ],
      "source": [
        "#ê°œì²´ëª… ì¸ì‹\n",
        "\n",
        "ner_sentence = ne_chunk(tokenized_sentence)\n",
        "print(ner_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX-WtSvPmm6"
      },
      "source": [
        "ğŸ”¹ **2-(2)** NER task by spacy library\n",
        "\n",
        "\n",
        "* spaCy ëŠ” ìì—°ì–´ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ ê¸°ë°˜ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. \n",
        "  * Tokenization \n",
        "  * POS tagging \n",
        "  * Lemmatization \n",
        "  * Sentence Boundary Detection (SBD)\n",
        "  * Named Entity Recognition (NER)\n",
        "  * Similarity\n",
        "  * Text Classification\n",
        "  * Rule-based Matching\n",
        "  * Training\n",
        "  * Serialization\n",
        "\n",
        "* spaCy ì™€ NER\n",
        "  * .ents â†’ .label_\n",
        "\n",
        "\n",
        "ğŸ“Œ [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) ğŸ‘‰ í•„ìˆ˜ (NER ë¶€ë¶„ë§Œ)\n",
        "\n",
        "ğŸ“Œ [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) ğŸ‘‰ ì„ íƒ\n",
        "\n",
        "  * í›ˆë ¨ë˜ì§€ ì•Šì€ ë°ì´í„° ì„¸íŠ¸ì— ëª…ëª…ëœ ì—”í‹°í‹°ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²• : ì´ë ¥ì„œ pdf ë°ì´í„° í™œìš© \n",
        "  * manually labelled \n",
        "\n",
        "ğŸ“Œ [í•œêµ­ì–´ NER](https://github.com/monologg/KoBERT-NER) ğŸ‘‰ ì°¸ê³ í•˜ë©´ ì¢‹ì„ ìë£Œ\n",
        "\n",
        "â• [ì°¸ê³ ](http://aispiration.com/nlp2/nlp-ner-python.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXjRfz-qP0Xx",
        "outputId": "9760e83a-3d65-48e7-dbf7-0d0b1a0ebee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"\"\"But Google is starting from behind. The company made a late push\n",
        "into hardware, and Appleâ€™s Siri, available on iPhones, and Amazonâ€™s Alexa\n",
        "software, which runs on its Echo and Dot devices, have clear leads in\n",
        "consumer adoption.\"\"\".replace(\"\\n\", \" \").strip())\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSsHTiVrOyaH",
        "outputId": "7ef1a332-eb88-4489-d3d0-485a745038c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google ORG\n",
            "Appleâ€™s Siri ORG\n",
            "iPhones ORG\n",
            "Amazon ORG\n",
            "Alexa ORG\n",
            "Echo GPE\n",
            "Dot ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008-V5QsQG25"
      },
      "source": [
        "###**3ï¸âƒ£ Dependency Parsing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfcodHQQPlt"
      },
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n",
        "* ë¬¸ì¥ì˜ ì „ì²´ì ì¸ êµ¬ì„±/êµ¬ì¡° ë³´ë‹¤ëŠ” ê° ê°œë³„ë‹¨ì–´ ê°„ì˜ 'ì˜ì¡´ê´€ê³„' ë˜ëŠ” 'ìˆ˜ì‹ê´€ê³„' ì™€ ê°™ì€ ë‹¨ì–´ê°„ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì´ ëª©ì ì¸ NLP Task\n",
        "* ë¬¸ì¥ í•´ì„ì˜ ëª¨í˜¸ì„±ì„ ì—†ì• ê¸° ìœ„í•´ Parsing ì„ í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJLAzZnbRNlL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "ğŸ”¹ **3-(1)** Dependency Parsing by spacy library\n",
        "\n",
        "\n",
        "* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) ğŸ‘‰ dependecy parsing ë¶€ë¶„ë§Œ í•„ìˆ˜\n",
        "* .dep_ ë©”ì„œë“œ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HbQEYt76bJXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e1a861-4a84-44b5-cd01-db2f6a81f877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'generator'>\n",
            "<class 'spacy.tokens.span.Span'>\n",
            "<class 'spacy.tokens.token.Token'>\n",
            "============================================================\n",
            "Text: The original noun chunk text.\n",
            "Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
            "Root dep: Dependency relation connecting the root to its head.\n",
            "Root head text: The text of the root token's head.\n",
            "============================================================\n",
            "          Autonomous cars                     cars                    nsubj                    shift\n",
            "      insurance liability                liability                     dobj                    shift\n",
            "            manufacturers            manufacturers                     pobj                   toward\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "\n",
        "noun_chunks = doc.noun_chunks\n",
        "print(type(noun_chunks))\n",
        "noun_chunk = list(noun_chunks)[0]\n",
        "print(type(noun_chunk))\n",
        "token = noun_chunk[0]\n",
        "print(type(token))\n",
        "\n",
        "print(\"==\"*30)\n",
        "print(\"\"\"\n",
        "Text: The original noun chunk text.\n",
        "Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
        "Root dep: Dependency relation connecting the root to its head.\n",
        "Root head text: The text of the root token's head.\n",
        "\"\"\".strip())\n",
        "print(\"==\"*30)\n",
        "str_format = \"{:>25}\"*4\n",
        "for chunk in doc.noun_chunks:\n",
        "  print(str_format.format(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9QAEsrLAxHP"
      },
      "outputs": [],
      "source": [
        "#nevigating parse tree\n",
        "\n",
        "doc=nlp(\"Autonomous cars shift insurance liability toward manufacurers\")\n",
        "for tok in doc:\n",
        "  print(tok.text)\n",
        "  children = list(tok.children)\n",
        "  print('childre:', children, 'head:', tok.head if tok.head != tok else \"!this is root node\")\n",
        "  print(\"==\"*16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ì´ë¥¼ ê°„ë‹¨í•˜ê²Œ ë„¤íŠ¸ì›Œí¬ë¡œ í‘œí˜„\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nG = nx.Graph()\n",
        "doc[2] ##root node\n",
        "\n",
        "def add_n_to_g(inputG, tok):\n",
        "  inputG.add_node(tok)\n",
        "  children = list(tok.children)\n",
        "  if children != []:\n",
        "    inputG.add_nodes_from(children)\n",
        "    for c in children:\n",
        "      inputG.add_edges_from([(tok, c, {'dependency':c.dep_})])\n",
        "      add_n_to_g(inputG, c)\n",
        "\n",
        "add_n_to_g(nG, doc[2])\n",
        "print(nG.nodes(data=True))\n",
        "print(\"==\"*20)\n",
        "for e in nG.edges(data=True):\n",
        "  print(f\"{e[0]}, {e[1]}, ### dependency: {e[2]['dependency']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6JlyuP_Sc3y",
        "outputId": "0dfb5014-52a0-4925-a801-ada62da5d80b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(shift, {}), (cars, {}), (liability, {}), (toward, {}), (Autonomous, {}), (insurance, {}), (manufacturers, {})]\n",
            "========================================\n",
            "shift, cars, ### dependency: nsubj\n",
            "shift, liability, ### dependency: dobj\n",
            "shift, toward, ### dependency: prep\n",
            "cars, Autonomous, ### dependency: amod\n",
            "liability, insurance, ### dependency: compound\n",
            "toward, manufacturers, ### dependency: pobj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQD5oiGgRfHe"
      },
      "source": [
        "ğŸ”¹ **3-(2)** Spacy (kaggle) \n",
        "\n",
        "* ìºê¸€ ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ì‹¤ìŠµí•´ë³´ëŠ” ê²ƒì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤!\n",
        "\n",
        "* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) ğŸ‘‰ í•„ìˆ˜\n",
        "  * ë„ë‚ ë“œ íŠ¸ëŸ¼í”„ íŠ¸ìœ„í„° íŠ¸ìœ— ë‚´ìš© ë°ì´í„° ë¶„ì„\n",
        "\n",
        "\n",
        "ğŸ‘€ **ë…¸íŠ¸ë¶ í‚¤í¬ì¸íŠ¸** \n",
        "  1. spacy.display ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œ NER ì‹œê°í™” \n",
        "  2. Tagging ì„ í†µí•œ íŠ¸ëŸ¼í”„ íŠ¸ìœ— ë¶„ì„ : noun_chunks ëŠ” dependency graphë¥¼ ê³ ë ¤í•˜ì—¬, noun phraseë¥¼ ë½‘ì•„ì¤€ë‹¤. \n",
        "  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : ì§ì ‘ ë¬¸ì¥/ë‹¨ì–´ íŒ¨í„´ì„ ë“±ë¡í•˜ì—¬ parsing\n",
        "  4. Question and answering task using Dependency Parsing\n",
        "    * spacy display :  ``style = 'dep'``\n",
        "    * .dep_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuHGKITRbKYq"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "!python -m spacy download en_vectors_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh9aW0ztYog9",
        "outputId": "051df29c-27ee-48a9-e52b-15a1ba92dacf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uMArOUrxAJ8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7510a3-b1dc-4b00-c328-f139b876b1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0,1,2,3,4,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "tweets = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/all_djt_tweets.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_text_entities(text):\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')"
      ],
      "metadata": {
        "id": "MZMShAaIZgx5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explain_text_entities(tweets['text'][9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JatTPATKZj3C",
        "outputId": "3a4aa607-b602-4699-eb6e-f3955832105f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Friday, Label: DATE, Absolute or relative dates or periods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_sentence = tweets['text'][0]\n",
        "doc = nlp(one_sentence)\n",
        "spacy.displacy.render(doc, style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "MJ_PGUF-Zmc1",
        "outputId": "4edf1551-e5e6-49a8-d31c-08c3c707756e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Over 90%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " approval rating for your all time favorite (I hope) President within \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Republican Party\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    52%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " overall. This despite all of the made up stories by \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Fake News Media\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " trying endlessly to make me look as bad and evil as possible. Look at the real villains please!</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_names(text):\n",
        "    doc = nlp(text)\n",
        "    redacted_sentence = []\n",
        "    for ent in doc.ents:\n",
        "        ent.merge()\n",
        "    for token in doc:\n",
        "        if token.ent_type_ == \"PERSON\":\n",
        "            redacted_sentence.append(\"[REDACTED]\")\n",
        "        else:\n",
        "            redacted_sentence.append(token.string)\n",
        "    return \"\".join(redacted_sentence)"
      ],
      "metadata": {
        "id": "Bvimts5jZ9Vv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tweets['text'][9]\n",
        "doc = nlp(example_text)\n",
        "spacy.displacy.render(doc, style='ent', jupyter=True)\n",
        "\n",
        "for idx, sentence in enumerate(doc.sents):\n",
        "    for noun in sentence.noun_chunks:\n",
        "        print(f\"sentence {idx+1} has noun chunk '{noun}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "pO341b4YabIV",
        "outputId": "c1962348-d9bb-493c-e924-18390b77f94a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Stock Market hit all time high on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Friday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Congratulations U.S.A.!</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence 1 has noun chunk 'Stock Market'\n",
            "sentence 1 has noun chunk 'all time'\n",
            "sentence 1 has noun chunk 'Friday'\n",
            "sentence 2 has noun chunk 'Congratulations U.S.A.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_sentence = tweets['text'][300]\n",
        "doc = nlp(one_sentence)\n",
        "spacy.displacy.render(doc, style='ent', jupyter=True)\n",
        "\n",
        "for token in doc:\n",
        "    print(token, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "eiDOcTfoado1",
        "outputId": "b411aca0-5864-41f8-ea2a-8a1a4ec839fe"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Incredibly beautiful ceremony as \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.S. Korean War\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " remains are returned to \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    American\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " soil. Thank you to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Honolulu\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and all of our great Military participants on a job well done. A special thanks to Vice President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mike Pence\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " on delivering a truly magnificent tribute!</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incredibly ADV\n",
            "beautiful ADJ\n",
            "ceremony NOUN\n",
            "as SCONJ\n",
            "U.S. PROPN\n",
            "Korean PROPN\n",
            "War PROPN\n",
            "remains VERB\n",
            "are AUX\n",
            "returned VERB\n",
            "to ADP\n",
            "American ADJ\n",
            "soil NOUN\n",
            ". PUNCT\n",
            "Thank VERB\n",
            "you PRON\n",
            "to ADP\n",
            "Honolulu PROPN\n",
            "and CCONJ\n",
            "all PRON\n",
            "of ADP\n",
            "our PRON\n",
            "great ADJ\n",
            "Military ADJ\n",
            "participants NOUN\n",
            "on ADP\n",
            "a DET\n",
            "job NOUN\n",
            "well ADV\n",
            "done VERB\n",
            ". PUNCT\n",
            "A DET\n",
            "special ADJ\n",
            "thanks NOUN\n",
            "to ADP\n",
            "Vice PROPN\n",
            "President PROPN\n",
            "Mike PROPN\n",
            "Pence PROPN\n",
            "on ADP\n",
            "delivering VERB\n",
            "a DET\n",
            "truly ADV\n",
            "magnificent ADJ\n",
            "tribute NOUN\n",
            "! PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = tweets['text'].str.cat(sep=' ')\n",
        "# spaCy enforces a max limit of 1000000 characters for NER and similar use cases.\n",
        "# Since `text` might be longer than that, we will slice it off here\n",
        "max_length = 1000000-1\n",
        "text = text[:max_length]\n",
        "\n",
        "# removing URLs and '&amp' substrings using regex\n",
        "import re\n",
        "url_reg  = r'[a-z]*[:.]+\\S+'\n",
        "text   = re.sub(url_reg, '', text)\n",
        "noise_reg = r'\\&amp'\n",
        "text   = re.sub(noise_reg, '', text)"
      ],
      "metadata": {
        "id": "MZyH-K3raf5h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "BKhqDtU_ahGR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items_of_interest = list(doc.noun_chunks)\n",
        "items_of_interest = [str(x) for x in items_of_interest]"
      ],
      "metadata": {
        "id": "N6K_Slf9azlh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trump_topics = []\n",
        "for token in doc:\n",
        "    if (not token.is_stop) and (token.pos_ == \"NOUN\") and (len(str(token))>2):\n",
        "        trump_topics.append(token)\n",
        "        \n",
        "trump_topics = [str(x) for x in trump_topics]"
      ],
      "metadata": {
        "id": "bjuNOwzDbUHj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trump_topics = []\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ not in [\"PERCENT\", \"CARDINAL\", \"DATE\"]:\n",
        "#         print(ent.text,ent.label_)\n",
        "        trump_topics.append(ent.text.strip())"
      ],
      "metadata": {
        "id": "NLjo4qnVbWsp"
      },
      "execution_count": 47,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}