{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "📌  **상단의 '파일-드라이브에 사본 저장' 해서 본인 드라이브에 저장된 사본 이용해서 실습 해주세요!!**\n",
        "\n",
        "📌 week13 복습습과제는 **NLG 실습**으로 구성되어 있습니다.\n",
        "\n",
        "📌 위키독스의 딥러닝을 이용한 자연어 처리 입문 교재 실습, 관련 블로그 등의 문서 자료로 구성되어 있는 과제입니다. \n",
        "\n",
        "📌 안내된 링크에 맞추어 **직접 코드를 따라 치면서 (필사)** 해당 nlp task 의 기본적인 라이브러리와 메서드를 숙지해보시면 좋을 것 같습니다😊 필수라고 체크한 부분은 과제에 반드시 포함시켜주시고, 선택으로 체크한 부분은 자율적으로 스터디 하시면 됩니다.\n",
        "\n",
        "📌 궁금한 사항은 깃허브 이슈나, 카톡방, 세션 발표 시작 이전 시간 등을 활용하여 자유롭게 공유해주세요!"
      ],
      "metadata": {
        "id": "BX3ac8Ag1RPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk colab 환경에서 실행시 필요한 코드입니다. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "4JEquLR91VBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2446901c-a092-4ea2-f9a2-43ddfa0a0786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🥰 **이하 예제를 실습하시면 됩니다.**\n",
        "\n",
        "**1-(1)~(2)는 필수과제, 2는 선택과제입니다.**\n"
      ],
      "metadata": {
        "id": "Kq8aMYKGPQR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1️⃣ NLG task 실습**"
      ],
      "metadata": {
        "id": "SHTPAk95iNtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👀 내용 복습\n",
        "\n",
        "NLG 는 새로운 text 를 만들어 내는 모든 task 를 의미하며 기계번역, 텍스트 요약, 채팅, 스토리텔링, QA 등이 있다. "
      ],
      "metadata": {
        "id": "j5msd7Igjz9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 1-(1) RNN 을 이용한 text generation \n",
        "\n",
        "📌 [Text generation with RNN](https://wikidocs.net/45101) \n",
        "\n",
        "* Simple RNN 을 이용한 간단한 한국어 text generation 예제와 LSTM 을 이용한 뉴욕 타임즈 기사 헤드라인 생성 예제를 필사해주세요."
      ],
      "metadata": {
        "id": "9L-jAHPkiBV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple RNN 이용한 간단한 한국어 text generation 예제"
      ],
      "metadata": {
        "id": "AM519BvUFhkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터에 대한 이해와 전처리\n",
        "\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Klj6gjETZdgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "metadata": {
        "id": "MsJZ9ldFiARK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합 생성 및 크기 확인\n",
        "#단어 집합의 크기를 저장할 때는 케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만,\n",
        "#패딩을 위한 0을 고려하여 +1을 해줌\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WhxIqwfFwHA",
        "outputId": "c1afac20-6220-48cd-d44e-1b53fc15b098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#각 단어와 단어에 부여된 정수 인덱스 출력\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G9_lB2tGP3j",
        "outputId": "9b09d43d-4f51-4be0-ca15-58f786b88d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터 만들기\n",
        "sequences = list()\n",
        "for line in text.split('\\n'): #줄바꿈 문자를 기준으로 문장 토큰화\n",
        "  encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(encoded)):\n",
        "    sequence = encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' %len(sequences))"
      ],
      "metadata": {
        "id": "ujH-MOEGGZuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f194909-be93-425b-c8d0-a524005ee5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전체 샘플 출력(아직 레이블로 사용될 분리하지 않은 훈련 데이터)\n",
        "print(sequences)\n",
        "#[2,3]:[경마장에, 있는], [2,3,1]:[경마장에, 있는, 말이]에 해당\n",
        "#전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리해야 함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2CTBRQ6Czpo",
        "outputId": "bf9fd9e6-90ce-449c-be7f-436d1a7f97d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#우선 전체 샘플에 대해 길이를 일치시켜줌(가장 긴 샘플의 길이를 기준으로)\n",
        "max_len = max(len(l) for  l in sequences) #모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "print('샘플의 최대 길이: {}'.format(max_len))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyPwnpdmDKF7",
        "outputId": "756dfd2b-ebdf-4680-e21a-53f1b1646187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전체 훈련 데이터에서 가장 긴 샘플의 길이가 6이므로 전체 샘플의 길이를 6으로 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "#pad_sequences()는 모든 샘플에 대해 0을 사용하여 길이를 맞춰줌.\n",
        "#maxlen의 값으로 6을 주면 모든 샘플의 길이를 6으로 맞춰주며,\n",
        "#padding의 인자로 'pre'를 주면 길이가 6보다 짧은 샘플의 앞에 0으로 채움."
      ],
      "metadata": {
        "id": "ZnPtuF5UDe3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1Pbw3q3Dqll",
        "outputId": "dab625be-c7a1-47f7-8b14-9fcb4f8c20da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#길이가 6보다 짧은 모든 샘플에 대해 앞에 0을 채워서 모든 샘플의 길이를 6으로 바꿨음.\n",
        "#이제 각 샘플의 마지막 단어를 레이블로 분리해야 함.\n",
        "#레이블의 분리는 Numpy이용해서 가능함.\n",
        "#리스트의 마지막 값을 제외하고 저장한 것은 X, 리스트의 마지막 값만 저장한 것은 y.<- 레이블\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:, -1]"
      ],
      "metadata": {
        "id": "UcCi_OPkEApy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#분리된 X와 y에 대해 출력\n",
        "print(X)\n",
        "print(y)\n",
        "#레이블이 분리됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2aX2tcpEb1S",
        "outputId": "42cdf8b1-dd54-4ed9-e6e3-ca26c5c1ed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n",
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN모델에 훈련 데이터를 훈련 시키기 전에 레이블에 대해 원-핫 인코딩을 수행\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "b6qqI4bXEkcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#원-핫 인코딩이 수행되었는지 출력\n",
        "print(y)\n",
        "#정상적으로 원-핫 인코딩이 수행됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQFF4CuTEyu7",
        "outputId": "b8631b68-2511-455c-c845-2e086187f0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모델 설계하기"
      ],
      "metadata": {
        "id": "2KAdsLf_E9zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN 모델에 데이터를 훈련시킴\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
      ],
      "metadata": {
        "id": "sUtvzuD-E_Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10 #하이퍼파라미터인 임베딩 벡터의 차원은 10\n",
        "hidden_units = 32 #은닉 상태의 크기는 32\n",
        "\n",
        "model = Sequential() #다 대일 구조의 RNN을 사용함\n",
        "model.add(Embedding(vocab_size, embedding_dim)) #전결합층을 출력층을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계함\n",
        "model.add(SimpleRNN(hidden_units)) #해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델\n",
        "model.add(Dense(vocab_size, activation = 'softmax')) #다중 클래스 분류 문제의 경우, 출력층에 소프트맥스 회귀를 사용해야 하므로 활성화 함수로 소프트맥스 함수 사용\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy']) #손실 함수로 크로스엔트로피 함수를 사용함\n",
        "model.fit(X, y, epochs=200, verbose = 2) #200에포크 수행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnlHvkajFMUl",
        "outputId": "c2f2d7c9-404f-42d4-ba39-8a2aec191737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 2.4794 - accuracy: 0.0909 - 1s/epoch - 1s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.4675 - accuracy: 0.1818 - 9ms/epoch - 9ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4555 - accuracy: 0.2727 - 7ms/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4434 - accuracy: 0.2727 - 10ms/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4311 - accuracy: 0.2727 - 13ms/epoch - 13ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4184 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.4053 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.3918 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.3778 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.3631 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3478 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.3318 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.3150 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.2973 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.2789 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.2596 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.2394 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.2183 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.1964 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.1739 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.1507 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.1270 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.1031 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.0792 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.0555 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 2.0325 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 2.0103 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.9894 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.9698 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.9519 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.9354 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.9201 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.9057 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.8916 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.8775 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.8629 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.8475 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.8313 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.8144 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.7970 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.7794 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.7618 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.7445 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.7276 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.7111 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.6950 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6791 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.6632 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.6472 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.6307 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.6138 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.5964 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.5784 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.5600 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.5414 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.5225 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.5035 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.4845 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.4656 - accuracy: 0.5455 - 14ms/epoch - 14ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.4466 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.4276 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.4085 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.3894 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.3701 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.3508 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.3316 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.3123 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.2931 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.2741 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.2552 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.2364 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.2176 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.1990 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.1804 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.1618 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.1433 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.1250 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.1067 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.0886 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 1.0706 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 1.0528 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 1.0351 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 1.0175 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 1.0001 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.9828 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.9657 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.9487 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.9319 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.9152 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.8987 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.8824 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.8663 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.8503 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.8345 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.8188 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.8033 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.7880 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.7729 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.7580 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7432 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.7286 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.7142 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.7000 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.6860 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.6721 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.6585 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.6450 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.6318 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.6188 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.6059 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.5933 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.5809 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.5687 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.5567 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5449 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5333 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.5220 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.5108 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.4999 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.4892 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.4787 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.4683 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.4582 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.4483 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4386 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4290 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4197 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4106 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4016 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.3928 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.3843 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.3759 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.3676 - accuracy: 0.9091 - 12ms/epoch - 12ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.3596 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.3517 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3441 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3365 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3292 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3220 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3150 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3081 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3014 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.2949 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.2885 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.2823 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.2762 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.2703 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.2645 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2589 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2534 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2480 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2428 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2377 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2327 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2279 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2232 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2186 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2141 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2097 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2054 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2013 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.1972 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.1933 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.1894 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.1857 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.1820 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.1784 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.1750 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.1716 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.1682 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1650 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1619 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1588 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1558 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1529 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1500 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1472 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1445 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1418 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1392 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1367 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1342 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1318 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1294 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1271 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1249 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1227 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1205 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1184 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1163 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1143 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1124 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1104 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1086 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1067 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1049 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1032 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1014 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.0997 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.0981 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd17c499c90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델이 정확하게 예측하고 있는지 문장을 생성하는 함수를 만들어 출력해봄\n",
        "\n",
        "def sentence_generation(model, tokenizer, current_word, n): #모델, 토크나이저, 현재단어, 반복할 횟수\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  #n번 반복\n",
        "  for _ in range(n):\n",
        "    # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "    # 입력한 X(현재 단어)에 대해 Y(예측단어)를 예측하고 Y를 result에 저장.\n",
        "\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis =1) \n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      #만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    current_word = current_word + ' ' + word\n",
        "\n",
        "    # 예측 단어를 문장에 저장\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word + sentence\n",
        "  return sentence\n",
        "\n",
        " #입력된 단어로부터 다음 단어를 예측해서 문장을 생성하는 함수 "
      ],
      "metadata": {
        "id": "68iG7JimG486"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_BaXb2vG88a",
        "outputId": "18affd7a-792d-45c1-c30c-87b6198f65c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의',2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a1Sb3l8IT-t",
        "outputId": "541b634e-9435-4774-e475-3baa75526d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4xbNUoDIbi4",
        "outputId": "bc5bd108-9f58-4c51-9e9f-24534c9ab55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> 앞의 문맥을 기준으로 '말이' 라는 단어 다음에 나올 단어를 기존 훈련 데이터와 일치하게 예측함을 보여줌.\n",
        "But, 이 모델은 충분한 훈련 데이터를 갖고 있지 못하므로 위에서 문장의 길이에 맞게 적절하게 예측해야하는 횟수 4,2,5를 각각 인자값으로 주었음. 이 이상의 숫자를 주면 기계는 '있다', '법이다', '곱다' 다음에 나오는 단어가 무엇인지 배운 적이 없으므로 임의 예측을 하게됨."
      ],
      "metadata": {
        "id": "yLOgsWWYIkyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 이용한 텍스트 생성하기"
      ],
      "metadata": {
        "id": "PEk_Vh5uI5gW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터에 대한 이해와 전처리"
      ],
      "metadata": {
        "id": "7vokB1IwJKV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "xPhKN_NSJJBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o00hw9_KkPS",
        "outputId": "cc04ed76-b823-40b3-988d-c2b19d77a1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ArticlesApril2018.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "X64YLWhhK32Y",
        "outputId": "c72391c5-3a98-40c5-99c8-07d2c7fd30f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  articleID  articleWordCount  \\\n",
              "0  5adf6684068401528a2aa69b               781   \n",
              "1  5adf653f068401528a2aa697               656   \n",
              "2  5adf4626068401528a2aa628              2427   \n",
              "3  5adf40d2068401528a2aa619               626   \n",
              "4  5adf3d64068401528a2aa60f               815   \n",
              "\n",
              "                                      byline documentType  \\\n",
              "0                             By JOHN BRANCH      article   \n",
              "1                           By LISA FRIEDMAN      article   \n",
              "2                              By PETE WELLS      article   \n",
              "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
              "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
              "\n",
              "                                            headline  \\\n",
              "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
              "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
              "2                            The New Noma, Explained   \n",
              "3                                            Unknown   \n",
              "4                                            Unknown   \n",
              "\n",
              "                                            keywords  multimedia     newDesk  \\\n",
              "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
              "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
              "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
              "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
              "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
              "\n",
              "   printPage              pubDate   sectionName  \\\n",
              "0          0  2018-04-24 17:16:49  Pro Football   \n",
              "1          0  2018-04-24 17:11:21       Unknown   \n",
              "2          0  2018-04-24 14:58:44       Unknown   \n",
              "3          0  2018-04-24 14:35:57        Europe   \n",
              "4          0  2018-04-24 14:21:21        Canada   \n",
              "\n",
              "                                             snippet              source  \\\n",
              "0  “I understand that they could meet with us, pa...  The New York Times   \n",
              "1  The agency plans to publish a new regulation T...  The New York Times   \n",
              "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
              "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
              "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
              "\n",
              "  typeOfMaterial                                             webURL  \n",
              "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
              "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
              "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
              "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
              "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41d654aa-62a1-442b-9862-1db3bb300afc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41d654aa-62a1-442b-9862-1db3bb300afc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41d654aa-62a1-442b-9862-1db3bb300afc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41d654aa-62a1-442b-9862-1db3bb300afc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#어떤 열이 있고, 열이 총 몇 개가 있는지 출력\n",
        "print('열의 개수: ', len(df.columns))\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16A8ofv1K8lv",
        "outputId": "eaa831d0-0989-4638-aea5-545f495337c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "열의 개수:  15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#총 15개의 열이 존재, 여기서 사용할 열은 제목에 해당되는 headline 열\n",
        "#Null 값이 있는지 확인\n",
        "\n",
        "print(df['headline'].isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2430TKEMO6z",
        "outputId": "a74d3a44-5186-4b6a-d2bb-5d582da5bb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#headline 열에서 모든 신문 기사의 제목을 뽑아서 하나의 리스트로 저장\n",
        "\n",
        "headline = []\n",
        "#헤드라인의 값들을 리스트로 저장\n",
        "headline.extend(list(df.headline.values))\n",
        "headline[:5]\n",
        "\n",
        "#4,5th 샘플에 Unknown값이 들어가 있음. Null값은 아니지만 실습에 도움이 되지 않는 노이즈 데이터 -> 제거\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dv5jkFVMb-P",
        "outputId": "7d3b0d5f-d723-4f3f-a43e-151e3b2f848d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#제거 전, 후의 샘플 개수 비교\n",
        "print('총 샘플의 개수: {}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH-5yoiCM29O",
        "outputId": "beeafbe8-b209-40f6-d1a4-4983b70a8090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수: 1324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unknown 값을 가진 샘플 제거\n",
        "headline = [word for word in headline if word != \"Unknown\"]\n",
        "print('노이즈값 제거 후 샘플의 개수: {}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE9_wwA9NBFH",
        "outputId": "2c595649-9354-4200-b43c-a2f04e8821d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "노이즈값 제거 후 샘플의 개수: 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPTJv_fiNPIJ",
        "outputId": "1e3871bb-7006-4182-a308-a8e0278e00f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 전처리 수행"
      ],
      "metadata": {
        "id": "b01irHKTNSve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#구두점 제거와 단어의 소문자화\n",
        "\n",
        "def repreprocessing(raw_sentence):\n",
        "  preprocessed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "  return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
        "\n",
        "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
        "preprocessed_headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt-z0K4SNScJ",
        "outputId": "cd94e0ce-0687-4e9a-f8ea-f06d016d21f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 집합(vocabulary)을 만들고 크기를 확인\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_headline)\n",
        "vocab_size = len(tokenizer.word_index) +1\n",
        "print('단어 집합의 크기: %d' %vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxX4I2-ROCzn",
        "outputId": "c01e690b-3bfe-4110-a7b2-75c1df5c7b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기: 3494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정수 인코딩을 진행하는 동시에 하나의 문장을 여러 줄로 분해하여 훈련 데이터를 구성\n",
        "\n",
        "sequences = list()\n",
        "\n",
        "for sentence in preprocessed_headline:\n",
        "\n",
        "  #각 샘플에 대한 정수 인코딩\n",
        "  encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1, len(encoded)):\n",
        "    sequence = encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RkyV4NsOYvu",
        "outputId": "69d05de8-c039-4c70-9b72-45550774b93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 위 sequences는 모든 문장을 각 단어가 각 시점(time step)마다 하나씩 추가적으로 등장하는 형태로 만들기는 했지만, 아직 예측할 단어에 해당되는 레이블을 분리하는 작업까지는 수행하지 않은 상태"
      ],
      "metadata": {
        "id": "z-JipZHERV_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#어떤 정수가 어떤 단어를 의미하는지 알아보기 위해 인덱스로부터 단어를 찾는 index_to_word를 만듦\n",
        "index_to_word = {}\n",
        "for key, value in tokenizer.word_index.items():\n",
        "  index_to_word[value] = key #인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWluiviGRqR5",
        "outputId": "05bb6148-ce64-4e27-9ef5-63c10282735f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y데이터를 분리하기 전에 전체 샘플의 길이를 동일하게 만드는 패딩 작업을 수행\n",
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이: {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRZuZIhXSpST",
        "outputId": "7e632181-8a08-4123-a57d-74e6e4ad8f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#가장 긴 샘플의 길이인 24로 모든 샘플의 길이를 패딩\n",
        "\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])\n",
        "\n",
        "#padding='pre'를 설정하여 샘플의 길이가 24보다 짧은 경우에 앞에 0으로 패딩됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ4jG8_IS6IX",
        "outputId": "f4f7bb90-9fd1-440d-ef40-38e48fa65626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#맨 우측 단어만 레이블로 분리\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "1MR93FIZTTMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련데이터 X에서 3개의 샘플만 출력 -> 맨 우측에 있던 정수값 3개가 사라짐\n",
        "#각 샘플의 길이가 24에서 23으로 줄음.\n",
        "print(X[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdo6dq2FTbEQ",
        "outputId": "96acfb4d-de3e-4e4e-85eb-9c1711f37d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  99 269]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  99 269 371]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터 y 중 3개의 샘플만 출력\n",
        "print([y[:3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDiMC7w_T0J4",
        "outputId": "351eb730-b038-4b03-a0c6-dfda372fff13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([ 269,  371, 1115], dtype=int32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#레이블 데이터 y에 대해 원-핫 인코딩 수행\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "kza2LYLVTp-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모델 설계"
      ],
      "metadata": {
        "id": "RRrG3qglT-v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "metadata": {
        "id": "arjXIf8OUADl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10 #임베딩 벡터의 차원은 10\n",
        "hidden_units = 128 #은닉 상태의 크기는 128\n",
        "\n",
        "model = Sequential() #다대일 구조의 LSTM 사용\n",
        "model.add(Embedding(vocab_size, embedding_dim)) #전결합층을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델 설계\n",
        "model.add(LSTM(hidden_units)) #마지막 시점에서 모든 가능한 단어 중 하나의 단어 예측하는 다중 클래스 분류문제 수행 모델\n",
        "model.add(Dense(vocab_size, activation='softmax')) #출력층에 소프트맥스 회귀를 사용 -> 활성화 함수로 소프트맥스 함수 사용\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #손실 함수로 크로스엔트로피 함수 사용\n",
        "model.fit(X,y, epochs=200, verbose =2) #200에포크 수행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5QMLhQ3UyJG",
        "outputId": "1454a910-8396-438f-b58f-050e320e4e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 12s - loss: 7.6701 - accuracy: 0.0249 - 12s/epoch - 48ms/step\n",
            "Epoch 2/200\n",
            "244/244 - 9s - loss: 7.1258 - accuracy: 0.0301 - 9s/epoch - 38ms/step\n",
            "Epoch 3/200\n",
            "244/244 - 9s - loss: 6.9836 - accuracy: 0.0322 - 9s/epoch - 38ms/step\n",
            "Epoch 4/200\n",
            "244/244 - 9s - loss: 6.8654 - accuracy: 0.0382 - 9s/epoch - 38ms/step\n",
            "Epoch 5/200\n",
            "244/244 - 11s - loss: 6.7312 - accuracy: 0.0419 - 11s/epoch - 46ms/step\n",
            "Epoch 6/200\n",
            "244/244 - 13s - loss: 6.5668 - accuracy: 0.0474 - 13s/epoch - 52ms/step\n",
            "Epoch 7/200\n",
            "244/244 - 12s - loss: 6.3828 - accuracy: 0.0495 - 12s/epoch - 49ms/step\n",
            "Epoch 8/200\n",
            "244/244 - 12s - loss: 6.1913 - accuracy: 0.0557 - 12s/epoch - 49ms/step\n",
            "Epoch 9/200\n",
            "244/244 - 13s - loss: 6.0056 - accuracy: 0.0625 - 13s/epoch - 53ms/step\n",
            "Epoch 10/200\n",
            "244/244 - 13s - loss: 5.8278 - accuracy: 0.0648 - 13s/epoch - 53ms/step\n",
            "Epoch 11/200\n",
            "244/244 - 12s - loss: 5.6591 - accuracy: 0.0659 - 12s/epoch - 50ms/step\n",
            "Epoch 12/200\n",
            "244/244 - 13s - loss: 5.5003 - accuracy: 0.0738 - 13s/epoch - 53ms/step\n",
            "Epoch 13/200\n",
            "244/244 - 12s - loss: 5.3494 - accuracy: 0.0737 - 12s/epoch - 48ms/step\n",
            "Epoch 14/200\n",
            "244/244 - 13s - loss: 5.2047 - accuracy: 0.0820 - 13s/epoch - 54ms/step\n",
            "Epoch 15/200\n",
            "244/244 - 14s - loss: 5.0678 - accuracy: 0.0879 - 14s/epoch - 56ms/step\n",
            "Epoch 16/200\n",
            "244/244 - 13s - loss: 4.9323 - accuracy: 0.0945 - 13s/epoch - 53ms/step\n",
            "Epoch 17/200\n",
            "244/244 - 14s - loss: 4.8033 - accuracy: 0.1050 - 14s/epoch - 56ms/step\n",
            "Epoch 18/200\n",
            "244/244 - 12s - loss: 4.6787 - accuracy: 0.1164 - 12s/epoch - 51ms/step\n",
            "Epoch 19/200\n",
            "244/244 - 13s - loss: 4.5542 - accuracy: 0.1285 - 13s/epoch - 55ms/step\n",
            "Epoch 20/200\n",
            "244/244 - 11s - loss: 4.4373 - accuracy: 0.1429 - 11s/epoch - 46ms/step\n",
            "Epoch 21/200\n",
            "244/244 - 12s - loss: 4.3217 - accuracy: 0.1598 - 12s/epoch - 51ms/step\n",
            "Epoch 22/200\n",
            "244/244 - 13s - loss: 4.2094 - accuracy: 0.1762 - 13s/epoch - 51ms/step\n",
            "Epoch 23/200\n",
            "244/244 - 10s - loss: 4.0989 - accuracy: 0.1927 - 10s/epoch - 43ms/step\n",
            "Epoch 24/200\n",
            "244/244 - 11s - loss: 3.9925 - accuracy: 0.2121 - 11s/epoch - 45ms/step\n",
            "Epoch 25/200\n",
            "244/244 - 12s - loss: 3.8862 - accuracy: 0.2332 - 12s/epoch - 48ms/step\n",
            "Epoch 26/200\n",
            "244/244 - 12s - loss: 3.7868 - accuracy: 0.2449 - 12s/epoch - 51ms/step\n",
            "Epoch 27/200\n",
            "244/244 - 12s - loss: 3.6910 - accuracy: 0.2602 - 12s/epoch - 51ms/step\n",
            "Epoch 28/200\n",
            "244/244 - 12s - loss: 3.5946 - accuracy: 0.2800 - 12s/epoch - 47ms/step\n",
            "Epoch 29/200\n",
            "244/244 - 10s - loss: 3.5045 - accuracy: 0.2936 - 10s/epoch - 40ms/step\n",
            "Epoch 30/200\n",
            "244/244 - 10s - loss: 3.4129 - accuracy: 0.3119 - 10s/epoch - 39ms/step\n",
            "Epoch 31/200\n",
            "244/244 - 10s - loss: 3.3295 - accuracy: 0.3260 - 10s/epoch - 41ms/step\n",
            "Epoch 32/200\n",
            "244/244 - 9s - loss: 3.2448 - accuracy: 0.3362 - 9s/epoch - 38ms/step\n",
            "Epoch 33/200\n",
            "244/244 - 9s - loss: 3.1670 - accuracy: 0.3585 - 9s/epoch - 39ms/step\n",
            "Epoch 34/200\n",
            "244/244 - 9s - loss: 3.0903 - accuracy: 0.3660 - 9s/epoch - 38ms/step\n",
            "Epoch 35/200\n",
            "244/244 - 9s - loss: 3.0142 - accuracy: 0.3822 - 9s/epoch - 39ms/step\n",
            "Epoch 36/200\n",
            "244/244 - 9s - loss: 2.9410 - accuracy: 0.3973 - 9s/epoch - 38ms/step\n",
            "Epoch 37/200\n",
            "244/244 - 9s - loss: 2.8725 - accuracy: 0.4051 - 9s/epoch - 38ms/step\n",
            "Epoch 38/200\n",
            "244/244 - 10s - loss: 2.8054 - accuracy: 0.4274 - 10s/epoch - 40ms/step\n",
            "Epoch 39/200\n",
            "244/244 - 14s - loss: 2.7401 - accuracy: 0.4323 - 14s/epoch - 58ms/step\n",
            "Epoch 40/200\n",
            "244/244 - 14s - loss: 2.6738 - accuracy: 0.4493 - 14s/epoch - 57ms/step\n",
            "Epoch 41/200\n",
            "244/244 - 9s - loss: 2.6131 - accuracy: 0.4623 - 9s/epoch - 38ms/step\n",
            "Epoch 42/200\n",
            "244/244 - 13s - loss: 2.5538 - accuracy: 0.4730 - 13s/epoch - 54ms/step\n",
            "Epoch 43/200\n",
            "244/244 - 12s - loss: 2.4937 - accuracy: 0.4817 - 12s/epoch - 49ms/step\n",
            "Epoch 44/200\n",
            "244/244 - 13s - loss: 2.4386 - accuracy: 0.4962 - 13s/epoch - 52ms/step\n",
            "Epoch 45/200\n",
            "244/244 - 13s - loss: 2.3866 - accuracy: 0.5076 - 13s/epoch - 53ms/step\n",
            "Epoch 46/200\n",
            "244/244 - 11s - loss: 2.3295 - accuracy: 0.5171 - 11s/epoch - 46ms/step\n",
            "Epoch 47/200\n",
            "244/244 - 9s - loss: 2.2804 - accuracy: 0.5295 - 9s/epoch - 38ms/step\n",
            "Epoch 48/200\n",
            "244/244 - 9s - loss: 2.2266 - accuracy: 0.5436 - 9s/epoch - 38ms/step\n",
            "Epoch 49/200\n",
            "244/244 - 13s - loss: 2.1775 - accuracy: 0.5543 - 13s/epoch - 53ms/step\n",
            "Epoch 50/200\n",
            "244/244 - 12s - loss: 2.1293 - accuracy: 0.5600 - 12s/epoch - 48ms/step\n",
            "Epoch 51/200\n",
            "244/244 - 9s - loss: 2.0797 - accuracy: 0.5714 - 9s/epoch - 38ms/step\n",
            "Epoch 52/200\n",
            "244/244 - 9s - loss: 2.0363 - accuracy: 0.5795 - 9s/epoch - 38ms/step\n",
            "Epoch 53/200\n",
            "244/244 - 9s - loss: 1.9893 - accuracy: 0.5907 - 9s/epoch - 38ms/step\n",
            "Epoch 54/200\n",
            "244/244 - 9s - loss: 1.9479 - accuracy: 0.5978 - 9s/epoch - 38ms/step\n",
            "Epoch 55/200\n",
            "244/244 - 9s - loss: 1.9038 - accuracy: 0.6091 - 9s/epoch - 38ms/step\n",
            "Epoch 56/200\n",
            "244/244 - 9s - loss: 1.8615 - accuracy: 0.6185 - 9s/epoch - 38ms/step\n",
            "Epoch 57/200\n",
            "244/244 - 9s - loss: 1.8208 - accuracy: 0.6260 - 9s/epoch - 38ms/step\n",
            "Epoch 58/200\n",
            "244/244 - 9s - loss: 1.7798 - accuracy: 0.6357 - 9s/epoch - 38ms/step\n",
            "Epoch 59/200\n",
            "244/244 - 9s - loss: 1.7387 - accuracy: 0.6446 - 9s/epoch - 38ms/step\n",
            "Epoch 60/200\n",
            "244/244 - 9s - loss: 1.7009 - accuracy: 0.6546 - 9s/epoch - 38ms/step\n",
            "Epoch 61/200\n",
            "244/244 - 9s - loss: 1.6653 - accuracy: 0.6587 - 9s/epoch - 38ms/step\n",
            "Epoch 62/200\n",
            "244/244 - 9s - loss: 1.6272 - accuracy: 0.6731 - 9s/epoch - 38ms/step\n",
            "Epoch 63/200\n",
            "244/244 - 9s - loss: 1.5902 - accuracy: 0.6797 - 9s/epoch - 38ms/step\n",
            "Epoch 64/200\n",
            "244/244 - 10s - loss: 1.5560 - accuracy: 0.6879 - 10s/epoch - 40ms/step\n",
            "Epoch 65/200\n",
            "244/244 - 9s - loss: 1.5233 - accuracy: 0.6950 - 9s/epoch - 39ms/step\n",
            "Epoch 66/200\n",
            "244/244 - 9s - loss: 1.4863 - accuracy: 0.7004 - 9s/epoch - 39ms/step\n",
            "Epoch 67/200\n",
            "244/244 - 9s - loss: 1.4561 - accuracy: 0.7073 - 9s/epoch - 38ms/step\n",
            "Epoch 68/200\n",
            "244/244 - 9s - loss: 1.4218 - accuracy: 0.7184 - 9s/epoch - 39ms/step\n",
            "Epoch 69/200\n",
            "244/244 - 9s - loss: 1.3886 - accuracy: 0.7238 - 9s/epoch - 38ms/step\n",
            "Epoch 70/200\n",
            "244/244 - 9s - loss: 1.3604 - accuracy: 0.7290 - 9s/epoch - 38ms/step\n",
            "Epoch 71/200\n",
            "244/244 - 9s - loss: 1.3291 - accuracy: 0.7342 - 9s/epoch - 38ms/step\n",
            "Epoch 72/200\n",
            "244/244 - 9s - loss: 1.2968 - accuracy: 0.7423 - 9s/epoch - 39ms/step\n",
            "Epoch 73/200\n",
            "244/244 - 9s - loss: 1.2713 - accuracy: 0.7498 - 9s/epoch - 38ms/step\n",
            "Epoch 74/200\n",
            "244/244 - 9s - loss: 1.2419 - accuracy: 0.7555 - 9s/epoch - 38ms/step\n",
            "Epoch 75/200\n",
            "244/244 - 9s - loss: 1.2132 - accuracy: 0.7619 - 9s/epoch - 38ms/step\n",
            "Epoch 76/200\n",
            "244/244 - 9s - loss: 1.1917 - accuracy: 0.7636 - 9s/epoch - 38ms/step\n",
            "Epoch 77/200\n",
            "244/244 - 9s - loss: 1.1599 - accuracy: 0.7712 - 9s/epoch - 38ms/step\n",
            "Epoch 78/200\n",
            "244/244 - 9s - loss: 1.1339 - accuracy: 0.7743 - 9s/epoch - 38ms/step\n",
            "Epoch 79/200\n",
            "244/244 - 9s - loss: 1.1084 - accuracy: 0.7805 - 9s/epoch - 38ms/step\n",
            "Epoch 80/200\n",
            "244/244 - 9s - loss: 1.0870 - accuracy: 0.7865 - 9s/epoch - 38ms/step\n",
            "Epoch 81/200\n",
            "244/244 - 9s - loss: 1.0607 - accuracy: 0.7912 - 9s/epoch - 38ms/step\n",
            "Epoch 82/200\n",
            "244/244 - 9s - loss: 1.0372 - accuracy: 0.7969 - 9s/epoch - 38ms/step\n",
            "Epoch 83/200\n",
            "244/244 - 9s - loss: 1.0123 - accuracy: 0.8035 - 9s/epoch - 38ms/step\n",
            "Epoch 84/200\n",
            "244/244 - 9s - loss: 0.9909 - accuracy: 0.8053 - 9s/epoch - 38ms/step\n",
            "Epoch 85/200\n",
            "244/244 - 9s - loss: 0.9695 - accuracy: 0.8093 - 9s/epoch - 38ms/step\n",
            "Epoch 86/200\n",
            "244/244 - 9s - loss: 0.9484 - accuracy: 0.8105 - 9s/epoch - 38ms/step\n",
            "Epoch 87/200\n",
            "244/244 - 9s - loss: 0.9289 - accuracy: 0.8205 - 9s/epoch - 38ms/step\n",
            "Epoch 88/200\n",
            "244/244 - 9s - loss: 0.9065 - accuracy: 0.8212 - 9s/epoch - 38ms/step\n",
            "Epoch 89/200\n",
            "244/244 - 9s - loss: 0.8874 - accuracy: 0.8253 - 9s/epoch - 38ms/step\n",
            "Epoch 90/200\n",
            "244/244 - 9s - loss: 0.8742 - accuracy: 0.8279 - 9s/epoch - 38ms/step\n",
            "Epoch 91/200\n",
            "244/244 - 9s - loss: 0.8523 - accuracy: 0.8321 - 9s/epoch - 38ms/step\n",
            "Epoch 92/200\n",
            "244/244 - 9s - loss: 0.8310 - accuracy: 0.8376 - 9s/epoch - 38ms/step\n",
            "Epoch 93/200\n",
            "244/244 - 9s - loss: 0.8129 - accuracy: 0.8393 - 9s/epoch - 38ms/step\n",
            "Epoch 94/200\n",
            "244/244 - 9s - loss: 0.7969 - accuracy: 0.8438 - 9s/epoch - 39ms/step\n",
            "Epoch 95/200\n",
            "244/244 - 9s - loss: 0.7787 - accuracy: 0.8440 - 9s/epoch - 38ms/step\n",
            "Epoch 96/200\n",
            "244/244 - 9s - loss: 0.7622 - accuracy: 0.8494 - 9s/epoch - 39ms/step\n",
            "Epoch 97/200\n",
            "244/244 - 9s - loss: 0.7448 - accuracy: 0.8525 - 9s/epoch - 38ms/step\n",
            "Epoch 98/200\n",
            "244/244 - 9s - loss: 0.7293 - accuracy: 0.8562 - 9s/epoch - 39ms/step\n",
            "Epoch 99/200\n",
            "244/244 - 9s - loss: 0.7147 - accuracy: 0.8571 - 9s/epoch - 39ms/step\n",
            "Epoch 100/200\n",
            "244/244 - 9s - loss: 0.7073 - accuracy: 0.8594 - 9s/epoch - 39ms/step\n",
            "Epoch 101/200\n",
            "244/244 - 9s - loss: 0.6946 - accuracy: 0.8622 - 9s/epoch - 38ms/step\n",
            "Epoch 102/200\n",
            "244/244 - 9s - loss: 0.6711 - accuracy: 0.8686 - 9s/epoch - 38ms/step\n",
            "Epoch 103/200\n",
            "244/244 - 9s - loss: 0.6579 - accuracy: 0.8671 - 9s/epoch - 38ms/step\n",
            "Epoch 104/200\n",
            "244/244 - 9s - loss: 0.6438 - accuracy: 0.8722 - 9s/epoch - 39ms/step\n",
            "Epoch 105/200\n",
            "244/244 - 9s - loss: 0.6283 - accuracy: 0.8731 - 9s/epoch - 38ms/step\n",
            "Epoch 106/200\n",
            "244/244 - 9s - loss: 0.6180 - accuracy: 0.8740 - 9s/epoch - 39ms/step\n",
            "Epoch 107/200\n",
            "244/244 - 9s - loss: 0.6089 - accuracy: 0.8763 - 9s/epoch - 38ms/step\n",
            "Epoch 108/200\n",
            "244/244 - 9s - loss: 0.6018 - accuracy: 0.8758 - 9s/epoch - 38ms/step\n",
            "Epoch 109/200\n",
            "244/244 - 9s - loss: 0.5848 - accuracy: 0.8816 - 9s/epoch - 39ms/step\n",
            "Epoch 110/200\n",
            "244/244 - 9s - loss: 0.5709 - accuracy: 0.8824 - 9s/epoch - 39ms/step\n",
            "Epoch 111/200\n",
            "244/244 - 9s - loss: 0.5595 - accuracy: 0.8865 - 9s/epoch - 38ms/step\n",
            "Epoch 112/200\n",
            "244/244 - 9s - loss: 0.5503 - accuracy: 0.8875 - 9s/epoch - 39ms/step\n",
            "Epoch 113/200\n",
            "244/244 - 9s - loss: 0.5383 - accuracy: 0.8900 - 9s/epoch - 38ms/step\n",
            "Epoch 114/200\n",
            "244/244 - 9s - loss: 0.5293 - accuracy: 0.8915 - 9s/epoch - 38ms/step\n",
            "Epoch 115/200\n",
            "244/244 - 9s - loss: 0.5206 - accuracy: 0.8932 - 9s/epoch - 38ms/step\n",
            "Epoch 116/200\n",
            "244/244 - 10s - loss: 0.5109 - accuracy: 0.8926 - 10s/epoch - 39ms/step\n",
            "Epoch 117/200\n",
            "244/244 - 9s - loss: 0.5017 - accuracy: 0.8956 - 9s/epoch - 38ms/step\n",
            "Epoch 118/200\n",
            "244/244 - 9s - loss: 0.4914 - accuracy: 0.8959 - 9s/epoch - 38ms/step\n",
            "Epoch 119/200\n",
            "244/244 - 9s - loss: 0.4821 - accuracy: 0.9003 - 9s/epoch - 38ms/step\n",
            "Epoch 120/200\n",
            "244/244 - 9s - loss: 0.4744 - accuracy: 0.8986 - 9s/epoch - 38ms/step\n",
            "Epoch 121/200\n",
            "244/244 - 9s - loss: 0.4689 - accuracy: 0.9009 - 9s/epoch - 39ms/step\n",
            "Epoch 122/200\n",
            "244/244 - 9s - loss: 0.4610 - accuracy: 0.9027 - 9s/epoch - 38ms/step\n",
            "Epoch 123/200\n",
            "244/244 - 9s - loss: 0.4484 - accuracy: 0.9036 - 9s/epoch - 38ms/step\n",
            "Epoch 124/200\n",
            "244/244 - 9s - loss: 0.4421 - accuracy: 0.9047 - 9s/epoch - 38ms/step\n",
            "Epoch 125/200\n",
            "244/244 - 9s - loss: 0.4352 - accuracy: 0.9031 - 9s/epoch - 38ms/step\n",
            "Epoch 126/200\n",
            "244/244 - 9s - loss: 0.4334 - accuracy: 0.9057 - 9s/epoch - 38ms/step\n",
            "Epoch 127/200\n",
            "244/244 - 9s - loss: 0.4280 - accuracy: 0.9050 - 9s/epoch - 38ms/step\n",
            "Epoch 128/200\n",
            "244/244 - 9s - loss: 0.4177 - accuracy: 0.9073 - 9s/epoch - 38ms/step\n",
            "Epoch 129/200\n",
            "244/244 - 9s - loss: 0.4075 - accuracy: 0.9093 - 9s/epoch - 38ms/step\n",
            "Epoch 130/200\n",
            "244/244 - 9s - loss: 0.4029 - accuracy: 0.9094 - 9s/epoch - 38ms/step\n",
            "Epoch 131/200\n",
            "244/244 - 9s - loss: 0.3960 - accuracy: 0.9117 - 9s/epoch - 38ms/step\n",
            "Epoch 132/200\n",
            "244/244 - 9s - loss: 0.3948 - accuracy: 0.9094 - 9s/epoch - 38ms/step\n",
            "Epoch 133/200\n",
            "244/244 - 9s - loss: 0.3868 - accuracy: 0.9094 - 9s/epoch - 39ms/step\n",
            "Epoch 134/200\n",
            "244/244 - 9s - loss: 0.3803 - accuracy: 0.9125 - 9s/epoch - 38ms/step\n",
            "Epoch 135/200\n",
            "244/244 - 9s - loss: 0.3783 - accuracy: 0.9104 - 9s/epoch - 38ms/step\n",
            "Epoch 136/200\n",
            "244/244 - 9s - loss: 0.3780 - accuracy: 0.9113 - 9s/epoch - 38ms/step\n",
            "Epoch 137/200\n",
            "244/244 - 9s - loss: 0.3721 - accuracy: 0.9130 - 9s/epoch - 38ms/step\n",
            "Epoch 138/200\n",
            "244/244 - 9s - loss: 0.3623 - accuracy: 0.9120 - 9s/epoch - 38ms/step\n",
            "Epoch 139/200\n",
            "244/244 - 9s - loss: 0.3561 - accuracy: 0.9135 - 9s/epoch - 38ms/step\n",
            "Epoch 140/200\n",
            "244/244 - 9s - loss: 0.3519 - accuracy: 0.9126 - 9s/epoch - 38ms/step\n",
            "Epoch 141/200\n",
            "244/244 - 9s - loss: 0.3480 - accuracy: 0.9134 - 9s/epoch - 38ms/step\n",
            "Epoch 142/200\n",
            "244/244 - 9s - loss: 0.3496 - accuracy: 0.9130 - 9s/epoch - 38ms/step\n",
            "Epoch 143/200\n",
            "244/244 - 9s - loss: 0.3451 - accuracy: 0.9145 - 9s/epoch - 38ms/step\n",
            "Epoch 144/200\n",
            "244/244 - 9s - loss: 0.3371 - accuracy: 0.9141 - 9s/epoch - 38ms/step\n",
            "Epoch 145/200\n",
            "244/244 - 9s - loss: 0.3345 - accuracy: 0.9140 - 9s/epoch - 38ms/step\n",
            "Epoch 146/200\n",
            "244/244 - 9s - loss: 0.3309 - accuracy: 0.9152 - 9s/epoch - 39ms/step\n",
            "Epoch 147/200\n",
            "244/244 - 9s - loss: 0.3285 - accuracy: 0.9148 - 9s/epoch - 38ms/step\n",
            "Epoch 148/200\n",
            "244/244 - 9s - loss: 0.3273 - accuracy: 0.9159 - 9s/epoch - 38ms/step\n",
            "Epoch 149/200\n",
            "244/244 - 9s - loss: 0.3246 - accuracy: 0.9136 - 9s/epoch - 38ms/step\n",
            "Epoch 150/200\n",
            "244/244 - 9s - loss: 0.3198 - accuracy: 0.9166 - 9s/epoch - 38ms/step\n",
            "Epoch 151/200\n",
            "244/244 - 9s - loss: 0.3173 - accuracy: 0.9144 - 9s/epoch - 38ms/step\n",
            "Epoch 152/200\n",
            "244/244 - 9s - loss: 0.3146 - accuracy: 0.9159 - 9s/epoch - 38ms/step\n",
            "Epoch 153/200\n",
            "244/244 - 9s - loss: 0.3149 - accuracy: 0.9149 - 9s/epoch - 39ms/step\n",
            "Epoch 154/200\n",
            "244/244 - 9s - loss: 0.3151 - accuracy: 0.9164 - 9s/epoch - 39ms/step\n",
            "Epoch 155/200\n",
            "244/244 - 9s - loss: 0.3086 - accuracy: 0.9168 - 9s/epoch - 38ms/step\n",
            "Epoch 156/200\n",
            "244/244 - 9s - loss: 0.3057 - accuracy: 0.9167 - 9s/epoch - 39ms/step\n",
            "Epoch 157/200\n",
            "244/244 - 9s - loss: 0.3031 - accuracy: 0.9157 - 9s/epoch - 39ms/step\n",
            "Epoch 158/200\n",
            "244/244 - 9s - loss: 0.3007 - accuracy: 0.9161 - 9s/epoch - 38ms/step\n",
            "Epoch 159/200\n",
            "244/244 - 9s - loss: 0.3045 - accuracy: 0.9136 - 9s/epoch - 38ms/step\n",
            "Epoch 160/200\n",
            "244/244 - 9s - loss: 0.3056 - accuracy: 0.9159 - 9s/epoch - 38ms/step\n",
            "Epoch 161/200\n",
            "244/244 - 9s - loss: 0.3075 - accuracy: 0.9162 - 9s/epoch - 39ms/step\n",
            "Epoch 162/200\n",
            "244/244 - 9s - loss: 0.3096 - accuracy: 0.9155 - 9s/epoch - 38ms/step\n",
            "Epoch 163/200\n",
            "244/244 - 9s - loss: 0.2968 - accuracy: 0.9170 - 9s/epoch - 38ms/step\n",
            "Epoch 164/200\n",
            "244/244 - 9s - loss: 0.2908 - accuracy: 0.9170 - 9s/epoch - 38ms/step\n",
            "Epoch 165/200\n",
            "244/244 - 9s - loss: 0.2895 - accuracy: 0.9173 - 9s/epoch - 38ms/step\n",
            "Epoch 166/200\n",
            "244/244 - 9s - loss: 0.2874 - accuracy: 0.9166 - 9s/epoch - 39ms/step\n",
            "Epoch 167/200\n",
            "244/244 - 9s - loss: 0.2869 - accuracy: 0.9155 - 9s/epoch - 39ms/step\n",
            "Epoch 168/200\n",
            "244/244 - 9s - loss: 0.2869 - accuracy: 0.9166 - 9s/epoch - 39ms/step\n",
            "Epoch 169/200\n",
            "244/244 - 9s - loss: 0.2838 - accuracy: 0.9176 - 9s/epoch - 38ms/step\n",
            "Epoch 170/200\n",
            "244/244 - 9s - loss: 0.2846 - accuracy: 0.9166 - 9s/epoch - 38ms/step\n",
            "Epoch 171/200\n",
            "244/244 - 9s - loss: 0.2843 - accuracy: 0.9157 - 9s/epoch - 38ms/step\n",
            "Epoch 172/200\n",
            "244/244 - 9s - loss: 0.2807 - accuracy: 0.9172 - 9s/epoch - 38ms/step\n",
            "Epoch 173/200\n",
            "244/244 - 9s - loss: 0.2852 - accuracy: 0.9148 - 9s/epoch - 38ms/step\n",
            "Epoch 174/200\n",
            "244/244 - 9s - loss: 0.2874 - accuracy: 0.9144 - 9s/epoch - 38ms/step\n",
            "Epoch 175/200\n",
            "244/244 - 9s - loss: 0.2819 - accuracy: 0.9163 - 9s/epoch - 39ms/step\n",
            "Epoch 176/200\n",
            "244/244 - 9s - loss: 0.2792 - accuracy: 0.9152 - 9s/epoch - 38ms/step\n",
            "Epoch 177/200\n",
            "244/244 - 9s - loss: 0.2772 - accuracy: 0.9181 - 9s/epoch - 38ms/step\n",
            "Epoch 178/200\n",
            "244/244 - 9s - loss: 0.2767 - accuracy: 0.9171 - 9s/epoch - 38ms/step\n",
            "Epoch 179/200\n",
            "244/244 - 9s - loss: 0.2749 - accuracy: 0.9159 - 9s/epoch - 38ms/step\n",
            "Epoch 180/200\n",
            "244/244 - 9s - loss: 0.2746 - accuracy: 0.9179 - 9s/epoch - 38ms/step\n",
            "Epoch 181/200\n",
            "244/244 - 9s - loss: 0.2740 - accuracy: 0.9149 - 9s/epoch - 38ms/step\n",
            "Epoch 182/200\n",
            "244/244 - 9s - loss: 0.2734 - accuracy: 0.9145 - 9s/epoch - 38ms/step\n",
            "Epoch 183/200\n",
            "244/244 - 9s - loss: 0.2726 - accuracy: 0.9157 - 9s/epoch - 38ms/step\n",
            "Epoch 184/200\n",
            "244/244 - 9s - loss: 0.2718 - accuracy: 0.9180 - 9s/epoch - 38ms/step\n",
            "Epoch 185/200\n",
            "244/244 - 9s - loss: 0.2723 - accuracy: 0.9175 - 9s/epoch - 38ms/step\n",
            "Epoch 186/200\n",
            "244/244 - 9s - loss: 0.2715 - accuracy: 0.9155 - 9s/epoch - 38ms/step\n",
            "Epoch 187/200\n",
            "244/244 - 9s - loss: 0.3546 - accuracy: 0.8999 - 9s/epoch - 38ms/step\n",
            "Epoch 188/200\n",
            "244/244 - 9s - loss: 0.2868 - accuracy: 0.9141 - 9s/epoch - 38ms/step\n",
            "Epoch 189/200\n",
            "244/244 - 9s - loss: 0.2699 - accuracy: 0.9168 - 9s/epoch - 39ms/step\n",
            "Epoch 190/200\n",
            "244/244 - 9s - loss: 0.2673 - accuracy: 0.9159 - 9s/epoch - 39ms/step\n",
            "Epoch 191/200\n",
            "244/244 - 9s - loss: 0.2673 - accuracy: 0.9154 - 9s/epoch - 38ms/step\n",
            "Epoch 192/200\n",
            "244/244 - 9s - loss: 0.2662 - accuracy: 0.9161 - 9s/epoch - 38ms/step\n",
            "Epoch 193/200\n",
            "244/244 - 9s - loss: 0.2661 - accuracy: 0.9153 - 9s/epoch - 38ms/step\n",
            "Epoch 194/200\n",
            "244/244 - 9s - loss: 0.2651 - accuracy: 0.9164 - 9s/epoch - 38ms/step\n",
            "Epoch 195/200\n",
            "244/244 - 9s - loss: 0.2649 - accuracy: 0.9159 - 9s/epoch - 38ms/step\n",
            "Epoch 196/200\n",
            "244/244 - 9s - loss: 0.2669 - accuracy: 0.9162 - 9s/epoch - 39ms/step\n",
            "Epoch 197/200\n",
            "244/244 - 9s - loss: 0.2647 - accuracy: 0.9176 - 9s/epoch - 38ms/step\n",
            "Epoch 198/200\n",
            "244/244 - 9s - loss: 0.2645 - accuracy: 0.9167 - 9s/epoch - 39ms/step\n",
            "Epoch 199/200\n",
            "244/244 - 9s - loss: 0.2644 - accuracy: 0.9157 - 9s/epoch - 38ms/step\n",
            "Epoch 200/200\n",
            "244/244 - 10s - loss: 0.2646 - accuracy: 0.9162 - 10s/epoch - 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd175899150>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#문장 생성함수 sentence_generation 만들어서 문장 생성\n",
        "\n",
        "def sentence_generation(model, tokenizer, current_word, n):\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  #n번 반복\n",
        "  for _ in range(n):\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "    #입력한 X(현재 단어)에 대해 y를 예측하고, 이를 result에 저장\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      #만약 예측한 단어와 인덱스가 동일한 단어가 있다면\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    current_word = current_word + ' ' + word\n",
        "\n",
        "    #예측 단어를 문장에 저장\n",
        "    sentence = sentence + ' ' +word\n",
        "\n",
        "  sentence = init_word + sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "BELphF4PV3Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#임의의 단어 'i'에 대해 10개의 단어를 추가 생성\n",
        "print(sentence_generation(model, tokenizer, 'i', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J92uQffgXUoj",
        "outputId": "7d54116b-52d0-4aad-f5cd-f281c6812528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i disapprove of school vouchers can i still apply for them\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#임의의 단어 'how'에 대해 10개의 단어를 추가 생성\n",
        "print(sentence_generation(model, tokenizer, 'how', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqLDWA1jXlib",
        "outputId": "1b912a33-054d-4ba2-b9d8-f4a3042ddaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how to make facebook more accountable my exhusband who my cograndparent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 1-(2) Text summarization with attention\n",
        "\n",
        "📌 [아마존 리뷰 요약](https://wikidocs.net/72820) \n",
        "\n",
        "* seq2seq + attention 을 이용한 아마존 리뷰 글 text summarization 예제를 필사해주세요."
      ],
      "metadata": {
        "id": "ktAuag_Nk5Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import urllib.request\n",
        "np.random.seed(seed=0)"
      ],
      "metadata": {
        "id": "mLmPLEYdZlzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로드하기\n",
        "#Reviews.csv 파일을 data라는 이름의 df에 저장. 단 10만개의 행으로 제한\n",
        "data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Reviews.csv\", nrows=100000)\n",
        "print('전체 리뷰 개수:', (len(data)))"
      ],
      "metadata": {
        "id": "xcgptSxJ3zhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6000dd6-3b55-47ab-989c-64aed3118f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 리뷰 개수: 100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n",
        "#이 중 필요한 열은 'Text'열과 'Summary'열 뿐이므로 분리"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "nF7hM00ci7zc",
        "outputId": "19be3f36-f3f9-49e6-c640-7c6b2b590ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7ff394b-b742-426f-9dfa-429e8d1944d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7ff394b-b742-426f-9dfa-429e8d1944d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7ff394b-b742-426f-9dfa-429e8d1944d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7ff394b-b742-426f-9dfa-429e8d1944d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Text', 'Summary']]\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4Exv1zlJjHje",
        "outputId": "bd0cfe58-4f1d-45fe-8da3-3f0b13d2da76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text                Summary\n",
              "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
              "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
              "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
              "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
              "4  Great taffy at a great price.  There was a wid...            Great taffy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e6701e0-b072-428b-afa6-e307cf1e5e95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>Not as Advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>Cough Medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>Great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e6701e0-b072-428b-afa6-e307cf1e5e95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e6701e0-b072-428b-afa6-e307cf1e5e95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e6701e0-b072-428b-afa6-e307cf1e5e95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤으로 10개의 샘플 출력\n",
        "data.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "HMFBkVFhjQYJ",
        "outputId": "49a0ac0d-9904-43b1-98a8-c7629d1c20e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Text  \\\n",
              "3582   I rarely eat anything but whole wheat pasta, b...   \n",
              "60498  I absolutely love 5-hour ENERGY! I use it afte...   \n",
              "53227  this chocolate is a true treat to eat, perfect...   \n",
              "21333  Greenies are very muched loved as a tatsy Trea...   \n",
              "3885   I love these noodles.  They are really great f...   \n",
              "51521  These are great! As a lover of all chips I'm s...   \n",
              "84261  Like other customers I divide these into handf...   \n",
              "10685  I recommend this instead for the same price: <...   \n",
              "59948  The noodles were all very broken, but the tast...   \n",
              "41032  Despite claiming they use the \"finest ingredie...   \n",
              "\n",
              "                                            Summary  \n",
              "3582                            reminds me of Italy  \n",
              "60498               5-hour ENERGY Highly Recommend!  \n",
              "53227                             supreme chocolate  \n",
              "21333                       Excellent Teeth Cleaner  \n",
              "3885                          Great and good price!  \n",
              "51521  Delicious, just like Salt and Vinegar Chips!  \n",
              "84261                      Great snack, great value  \n",
              "10685     It's ok, but certainly not worth the cost  \n",
              "59948                          Knorr's beef noodles  \n",
              "41032                          HORRIBLE INGREDIENTS  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a59180f-8f16-4113-856f-c8c1c145da26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3582</th>\n",
              "      <td>I rarely eat anything but whole wheat pasta, b...</td>\n",
              "      <td>reminds me of Italy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60498</th>\n",
              "      <td>I absolutely love 5-hour ENERGY! I use it afte...</td>\n",
              "      <td>5-hour ENERGY Highly Recommend!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53227</th>\n",
              "      <td>this chocolate is a true treat to eat, perfect...</td>\n",
              "      <td>supreme chocolate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21333</th>\n",
              "      <td>Greenies are very muched loved as a tatsy Trea...</td>\n",
              "      <td>Excellent Teeth Cleaner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>I love these noodles.  They are really great f...</td>\n",
              "      <td>Great and good price!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51521</th>\n",
              "      <td>These are great! As a lover of all chips I'm s...</td>\n",
              "      <td>Delicious, just like Salt and Vinegar Chips!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84261</th>\n",
              "      <td>Like other customers I divide these into handf...</td>\n",
              "      <td>Great snack, great value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10685</th>\n",
              "      <td>I recommend this instead for the same price: &lt;...</td>\n",
              "      <td>It's ok, but certainly not worth the cost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59948</th>\n",
              "      <td>The noodles were all very broken, but the tast...</td>\n",
              "      <td>Knorr's beef noodles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41032</th>\n",
              "      <td>Despite claiming they use the \"finest ingredie...</td>\n",
              "      <td>HORRIBLE INGREDIENTS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a59180f-8f16-4113-856f-c8c1c145da26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a59180f-8f16-4113-856f-c8c1c145da26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a59180f-8f16-4113-856f-c8c1c145da26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 정제"
      ],
      "metadata": {
        "id": "LjzAwwdPjWax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터에 중복 샘플이 있는지 확인\n",
        "print('Text 열에서 중복을 배제한 유일한 샘플의 수: ', data['Text'].nunique())\n",
        "print('Summary 열에서 중복을 배제한 유일한 샘플의 수: ', data['Summary'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4DXjVFQjX2_",
        "outputId": "8ee46c47-aa1b-4cd8-b98f-f45389920577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 열에서 중복을 배제한 유일한 샘플의 수:  88426\n",
            "Summary 열에서 중복을 배제한 유일한 샘플의 수:  72348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text 열에서 중복 내용 있다면 중복 제거\n",
        "data.drop_duplicates(subset=['Text'], inplace=True)\n",
        "print(\"전체 샘플 수: \", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZz0RUbvjw-K",
        "outputId": "096a531c-18af-413c-da0f-eaea08bda965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수:  88426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsExRC5ekJYI",
        "outputId": "3adc4eae-2cbb-483d-813c-17bc0e2fa182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text       0\n",
            "Summary    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Null 값 가진 샘플 제거\n",
        "data.dropna(axis=0, inplace=True)\n",
        "print('전체 샘플 수: ', (len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "203xCqFkkM1Y",
        "outputId": "fbc8ac7b-f369-4492-a259-d92d65832d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수:  88425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 함수 내 사용\n",
        "contractions = {\"'cause\": 'because',\n",
        " \"I'd\": 'I would',\n",
        " \"I'd've\": 'I would have',\n",
        " \"I'll\": 'I will',\n",
        " \"I'll've\": 'I will have',\n",
        " \"I'm\": 'I am',\n",
        " \"I've\": 'I have',\n",
        " \"ain't\": 'is not',\n",
        " \"aren't\": 'are not',\n",
        " \"can't\": 'cannot',\n",
        " \"could've\": 'could have',\n",
        " \"couldn't\": 'could not',\n",
        " \"didn't\": 'did not',\n",
        " \"doesn't\": 'does not',\n",
        " \"don't\": 'do not',\n",
        " \"hadn't\": 'had not',\n",
        " \"hasn't\": 'has not',\n",
        " \"haven't\": 'have not',\n",
        " \"he'd\": 'he would',\n",
        " \"he'll\": 'he will',\n",
        " \"he's\": 'he is',\n",
        " \"here's\": 'here is',\n",
        " \"how'd\": 'how did',\n",
        " \"how'd'y\": 'how do you',\n",
        " \"how'll\": 'how will',\n",
        " \"how's\": 'how is',\n",
        " \"i'd\": 'i would',\n",
        " \"i'd've\": 'i would have',\n",
        " \"i'll\": 'i will',\n",
        " \"i'll've\": 'i will have',\n",
        " \"i'm\": 'i am',\n",
        " \"i've\": 'i have',\n",
        " \"isn't\": 'is not',\n",
        " \"it'd\": 'it would',\n",
        " \"it'd've\": 'it would have',\n",
        " \"it'll\": 'it will',\n",
        " \"it'll've\": 'it will have',\n",
        " \"it's\": 'it is',\n",
        " \"let's\": 'let us',\n",
        " \"ma'am\": 'madam',\n",
        " \"mayn't\": 'may not',\n",
        " \"might've\": 'might have',\n",
        " \"mightn't\": 'might not',\n",
        " \"mightn't've\": 'might not have',\n",
        " \"must've\": 'must have',\n",
        " \"mustn't\": 'must not',\n",
        " \"mustn't've\": 'must not have',\n",
        " \"needn't\": 'need not',\n",
        " \"needn't've\": 'need not have',\n",
        " \"o'clock\": 'of the clock',\n",
        " \"oughtn't\": 'ought not',\n",
        " \"oughtn't've\": 'ought not have',\n",
        " \"sha'n't\": 'shall not',\n",
        " \"shan't\": 'shall not',\n",
        " \"shan't've\": 'shall not have',\n",
        " \"she'd\": 'she would',\n",
        " \"she'd've\": 'she would have',\n",
        " \"she'll\": 'she will',\n",
        " \"she'll've\": 'she will have',\n",
        " \"she's\": 'she is',\n",
        " \"should've\": 'should have',\n",
        " \"shouldn't\": 'should not',\n",
        " \"shouldn't've\": 'should not have',\n",
        " \"so's\": 'so as',\n",
        " \"so've\": 'so have',\n",
        " \"that'd\": 'that would',\n",
        " \"that'd've\": 'that would have',\n",
        " \"that's\": 'that is',\n",
        " \"there'd\": 'there would',\n",
        " \"there'd've\": 'there would have',\n",
        " \"there's\": 'there is',\n",
        " \"they'd\": 'they would',\n",
        " \"they'd've\": 'they would have',\n",
        " \"they'll\": 'they will',\n",
        " \"they'll've\": 'they will have',\n",
        " \"they're\": 'they are',\n",
        " \"they've\": 'they have',\n",
        " \"this's\": 'this is',\n",
        " \"to've\": 'to have',\n",
        " \"wasn't\": 'was not',\n",
        " \"we'd\": 'we would',\n",
        " \"we'd've\": 'we would have',\n",
        " \"we'll\": 'we will',\n",
        " \"we'll've\": 'we will have',\n",
        " \"we're\": 'we are',\n",
        " \"we've\": 'we have',\n",
        " \"weren't\": 'were not',\n",
        " \"what'll\": 'what will',\n",
        " \"what'll've\": 'what will have',\n",
        " \"what're\": 'what are',\n",
        " \"what's\": 'what is',\n",
        " \"what've\": 'what have',\n",
        " \"when's\": 'when is',\n",
        " \"when've\": 'when have',\n",
        " \"where'd\": 'where did',\n",
        " \"where's\": 'where is',\n",
        " \"where've\": 'where have',\n",
        " \"who'll\": 'who will',\n",
        " \"who'll've\": 'who will have',\n",
        " \"who's\": 'who is',\n",
        " \"who've\": 'who have',\n",
        " \"why's\": 'why is',\n",
        " \"why've\": 'why have',\n",
        " \"will've\": 'will have',\n",
        " \"won't\": 'will not',\n",
        " \"won't've\": 'will not have',\n",
        " \"would've\": 'would have',\n",
        " \"wouldn't\": 'would not',\n",
        " \"wouldn't've\": 'would not have',\n",
        " \"y'all\": 'you all',\n",
        " \"y'all'd\": 'you all would',\n",
        " \"y'all'd've\": 'you all would have',\n",
        " \"y'all're\": 'you all are',\n",
        " \"y'all've\": 'you all have',\n",
        " \"you'd\": 'you would',\n",
        " \"you'd've\": 'you would have',\n",
        " \"you'll\": 'you will',\n",
        " \"you'll've\": 'you will have',\n",
        " \"you're\": 'you are',\n",
        " \"you've\": 'you have'}"
      ],
      "metadata": {
        "id": "mgXPJxMrpHv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#지금까지는 불필요한 샘플 수 줄이기 위한 정제 과정이었음.\n",
        "#이제 샘플 내부를 전처리(단어 정규화, 불용어 제거)\n",
        "#NLTK의 불용어\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print('불용어 개수: ', len(stop_words))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWe49jHrkkgi",
        "outputId": "de751a98-842c-4561-c26f-7a902cf60958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 개수:  179\n",
            "{'from', 'will', 'who', 'are', 'about', 'or', 're', 'am', 'him', 'the', 'aren', 'through', 'all', 'myself', 'other', \"didn't\", 'those', 'against', \"don't\", 'up', 'at', 'where', \"needn't\", 'having', \"it's\", 'isn', \"mustn't\", 'after', 'how', 'below', 'shouldn', 'herself', \"shouldn't\", \"you'll\", 'in', 'but', 'them', \"won't\", 'then', 'mustn', 'for', 'just', 'll', 'because', 'why', \"hadn't\", 'weren', 'as', 'needn', 'himself', 'my', 'was', 'which', 'does', 'mightn', 'before', 'her', 'yourself', 'on', 'both', 'most', 'nor', 'they', 'further', 'hasn', 'too', 'don', 'were', 'be', 'very', 'being', 'these', 'own', 'couldn', 'itself', \"isn't\", \"haven't\", 'few', 'only', 'been', 'during', 'd', \"aren't\", 've', 's', 'its', \"mightn't\", 'did', 'to', \"should've\", 'is', 'ma', 'this', 'do', 'he', 'by', 'm', \"she's\", 'themselves', 'until', 'some', 'theirs', \"you'd\", 'with', 'ain', \"you've\", 'while', 'a', 'out', 'of', \"wasn't\", 'our', 'into', 'same', \"weren't\", 'o', 'once', 'above', \"couldn't\", 'an', 'can', 'than', 'down', 'no', 'such', 'wouldn', 'so', 'she', 'what', 'haven', \"hasn't\", 'your', 'and', 'if', 'doing', 'now', \"shan't\", 'more', 'ourselves', 'y', 'each', 'hadn', 'didn', 'their', 'ours', 'when', 'not', 'there', 'under', 'here', 'that', 't', 'yours', 'wasn', 'we', 'had', \"you're\", \"doesn't\", 'any', 'shan', 'you', 'again', 'his', \"that'll\", 'have', 'should', 'it', 'off', 'hers', 'between', 'over', 'doesn', 'me', 'whom', 'yourselves', 'has', \"wouldn't\", 'i', 'won'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전처리 함수\n",
        "def preprocess_sentence(sentence, remove_stopwords = True):\n",
        "  sentence = sentence.lower() #text 소문자화\n",
        "  sentence = BeautifulSoup(sentence, \"lxml\").text #<br />, <a href = ...> 등의 html 태그 제거\n",
        "  sentence = re.sub(r'\\([^)]*\\)', '', sentence) #괄호로 닫힌 문자열 제거\n",
        "  sentence = re.sub('\"','', sentence) #쌍따옴표 \" 제거\n",
        "  sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) #약어 정규화\n",
        "  sentence = re.sub(r\"'s\\b\",\"\",sentence) #소유격 제거\n",
        "  sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) #영어 외 문자(숫자, 특수 문자 등) 공백으로 변환\n",
        "  sentence = re.sub('[m]{2,}', 'mm', sentence) #m이 3개 이상이면 2개로 변경\n",
        "\n",
        "  #불용어 제거\n",
        "  if remove_stopwords:\n",
        "    tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word)>1)\n",
        "  #불용어 미제거 (Summary)\n",
        "  else:\n",
        "    tokens = ' '.join(word for word in sentence.split() if len(word)>1)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "YgZMYRZ5lVVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father'\n",
        "temp_summary = 'Great way to start (or finish) the day!!!'\n",
        "print(preprocess_sentence(temp_text))\n",
        "print(preprocess_sentence(temp_summary, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doGKwtA9nlFX",
        "outputId": "6c3bb8a0-20b7-4b90-ff21-f453427098e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "everything bought great infact ordered twice third ordered wasfor mother father\n",
            "great way to start the day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text 열에 대해서 전처리 수행\n",
        "clean_text = []\n",
        "for s in data['Text']:\n",
        "  clean_text.append(preprocess_sentence(s))\n",
        "clean_text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI5Bl25JumKg",
        "outputId": "b3bbb46d-128d-40d1-d0fd-fb554ea9bbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary 열 전처리\n",
        "clean_summary = []\n",
        "for s in data['Summary']:\n",
        "  clean_summary.append(preprocess_sentence(s, 0))\n",
        "clean_summary[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi-HZEmCvdT0",
        "outputId": "40482263-0c61-4f5f-ed3d-64e4d3469f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전처리 후의 결과를 다시 df에 저장\n",
        "\n",
        "data['Text'] = clean_text\n",
        "data['Summary'] = clean_summary"
      ],
      "metadata": {
        "id": "w64aFmFywT5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 과정에서 null값 생겼을 가능성 존재 확인\n",
        "\n",
        "data.replace('', np.nan, inplace=True)\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ingO5rcvwc14",
        "outputId": "f0c4d5a8-7c98-4e89-c751-1bb611613d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text        0\n",
            "Summary    70\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary 열에서 생긴 70개 Null 샘플 제거 후 전체 샘플 수 확인\n",
        "\n",
        "data.dropna(axis=0, inplace = True)\n",
        "print('전체 샘플 수: ', len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_8Vh2arwqUv",
        "outputId": "4bbc73ba-3193-4f7f-aceb-f07745f2ea33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수:  88355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#길이 분포 출력\n",
        "text_len = [len(s.split()) for s in data['Text']]\n",
        "summary_len = [len(s.split()) for s in data['Summary']]\n",
        "\n",
        "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
        "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
        "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
        "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
        "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
        "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(summary_len)\n",
        "plt.title('Summary')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Summary')\n",
        "plt.hist(summary_len, bins=40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Text')\n",
        "plt.hist(text_len, bins=40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "be1SNZWMw47R",
        "outputId": "6d92ca00-4c63-4709-8957-3cf551abc53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "요약의 최소 길이 : 1\n",
            "요약의 최대 길이 : 28\n",
            "요약의 평균 길이 : 4.010729443721352\n",
            "텍스트의 최소 길이 : 2\n",
            "텍스트의 최대 길이 : 1235\n",
            "텍스트의 평균 길이 : 38.792428272310566\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원문 텍스트는 대체적으로 100 이하의 길이를, 평균 길이는 38.\n",
        "요약의 경우 대체적으로 15이하의 길이, 평균 길이는 4를 가짐.\n",
        "-> 패딩의 길이는 평균 길이보다는 크게 잡아 각각 50과 8로 결정"
      ],
      "metadata": {
        "id": "l343GHCSyiB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_max_len = 50\n",
        "summary_max_len = 8"
      ],
      "metadata": {
        "id": "59N0uSw4ytf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 길이가 얼마나 많은 샘플들의 길이보다 큰지 확인\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s.split()) <= max_len):\n",
        "      cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt/len(nested_list))))\n"
      ],
      "metadata": {
        "id": "RWDUoCPxyxmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "below_threshold_len(text_max_len, data['Text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84BQy3JdzQfV",
        "outputId": "cbcb8464-5240-4e81-a248-c3c995f7b2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text열은 약 23%의 샘플이 길이 50보다 큼."
      ],
      "metadata": {
        "id": "aQ8Xq1K3zhC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "below_threshold_len(summary_max_len, data['Summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl_D-Ocrzk8Q",
        "outputId": "0f7251e6-f8ec-4b9e-8a64-dd48804a9fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary열은 약 6%의 샘플이 길이 8보다 큼 "
      ],
      "metadata": {
        "id": "ErdZ53hFzt1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#정해준 최대 길이보다 큰 샘플들은 제거\n",
        "\n",
        "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
        "data = data[data['Summary'].apply(lambda x: len(x.split())<= summary_max_len)]\n",
        "\n",
        "print('전체 샘플 수: ', (len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd8C6PNQz4PX",
        "outputId": "d8e903f3-b5f8-4b9a-86c0-2732db0e8263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수:  65818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정제 작업이 완료된 상위 샘플 5개 출력\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DqN_AJvl0aD2",
        "outputId": "aeacef7f-36a9-4374-a479-3a765be2eacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text                Summary\n",
              "0  bought several vitality canned dog food produc...  good quality dog food\n",
              "1  product arrived labeled jumbo salted peanuts p...      not as advertised\n",
              "2  confection around centuries light pillowy citr...    delight says it all\n",
              "3  looking secret ingredient robitussin believe f...         cough medicine\n",
              "4  great taffy great price wide assortment yummy ...            great taffy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c576ac28-461d-4150-913f-1b72aa983314\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food produc...</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "      <td>not as advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "      <td>delight says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c576ac28-461d-4150-913f-1b72aa983314')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c576ac28-461d-4150-913f-1b72aa983314 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c576ac28-461d-4150-913f-1b72aa983314');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seq2seq 훈련을 위해 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요 \n",
        "#시작 토큰은 'sostoken', 종료 토큰은 'eostoken'이라 명명하고 앞, 뒤로 추가\n",
        "\n",
        "data['decoder_input'] = data['Summary'].apply(lambda x: 'sostoken'+x)\n",
        "data['decoder_target'] = data['Summary'].apply(lambda x: x+'esotoken')\n",
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "tUifAshn0fvD",
        "outputId": "0a0baacf-c453-4ff8-d576-d383584154b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text                Summary  \\\n",
              "0  bought several vitality canned dog food produc...  good quality dog food   \n",
              "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
              "2  confection around centuries light pillowy citr...    delight says it all   \n",
              "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
              "4  great taffy great price wide assortment yummy ...            great taffy   \n",
              "\n",
              "                   decoder_input                 decoder_target  \n",
              "0  sostokengood quality dog food  good quality dog foodesotoken  \n",
              "1      sostokennot as advertised      not as advertisedesotoken  \n",
              "2    sostokendelight says it all    delight says it allesotoken  \n",
              "3         sostokencough medicine         cough medicineesotoken  \n",
              "4            sostokengreat taffy            great taffyesotoken  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a99af004-67e6-40fb-8f95-b651d544ab23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "      <th>decoder_input</th>\n",
              "      <th>decoder_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food produc...</td>\n",
              "      <td>good quality dog food</td>\n",
              "      <td>sostokengood quality dog food</td>\n",
              "      <td>good quality dog foodesotoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "      <td>not as advertised</td>\n",
              "      <td>sostokennot as advertised</td>\n",
              "      <td>not as advertisedesotoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "      <td>delight says it all</td>\n",
              "      <td>sostokendelight says it all</td>\n",
              "      <td>delight says it allesotoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "      <td>cough medicine</td>\n",
              "      <td>sostokencough medicine</td>\n",
              "      <td>cough medicineesotoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "      <td>great taffy</td>\n",
              "      <td>sostokengreat taffy</td>\n",
              "      <td>great taffyesotoken</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a99af004-67e6-40fb-8f95-b651d544ab23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a99af004-67e6-40fb-8f95-b651d544ab23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a99af004-67e6-40fb-8f95-b651d544ab23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인코더의 입력, 디코더의 입력과 레이블을 각각 저장\n",
        "\n",
        "encoder_input = np.array(data['Text'])\n",
        "decoder_input = np.array(data['decoder_input'])\n",
        "decoder_target = np.array(data['decoder_target'])"
      ],
      "metadata": {
        "id": "CGWuwI9c1Ejo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*데이터의 분리"
      ],
      "metadata": {
        "id": "RzhB-9E81WDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터와 테스트 데이터를 분리\n",
        "#먼저 순서가 섞인 정수 시퀀스를 만들어줌\n",
        "\n",
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTAqcuS01X_P",
        "outputId": "b1e4fd15-1e8f-4909-8b59-3f0d70c1df69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[61165 60938 37145 ... 45440 26023  1298]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#위 정수 시퀀스를 데이터의 샘플 순서로 정의 -> 샘플의 순서 셔플\n",
        "\n",
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "kfiBbj3w1qQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리\n",
        "n_of_val = int(len(encoder_input)*0.2)\n",
        "print('테스트 데이터의 수: ', n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlksrLjc2A9K",
        "outputId": "2a208e81-db22-4a5b-9ae9-bf192d4ed6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터의 수:  13163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "hyAKjWJn2T55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :',len(decoder_input_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_idiXNN4lOb",
        "outputId": "9915af1a-aec4-4008-fef8-d3494f4e47d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 개수 : 52655\n",
            "훈련 레이블의 개수 : 52655\n",
            "테스트 데이터의 개수 : 13163\n",
            "테스트 레이블의 개수 : 13163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*정수 인코딩: 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터에 정수 인코딩을 수행 -> 훈련 데이터에 대해 단어 집합 만들기"
      ],
      "metadata": {
        "id": "P_uRZyTh4qYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#우선 원문에 해당하는 encoder_input_train에 대해 수행\n",
        "\n",
        "src_tokenizer = Tokenizer()\n",
        "src_tokenizer.fit_on_texts(encoder_input_train)\n",
        "#단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여됨.\n",
        "#이는 src_tokenizer.word_index에 저장되어져 있음.\n",
        "#이 중 빈도수가 낮은 단어들은 자연어 처리에서 배제하고자 함.\n",
        "#등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인"
      ],
      "metadata": {
        "id": "V06kt4lx5FYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) #단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총합\n",
        "\n",
        "#단어와 빈도수의 쌍(pair)을 key와 value로 받음\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "  if(value < threshold):\n",
        "    rare_cnt = rare_cnt + 1\n",
        "    rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기: ', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s' %(threshold -1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s' %(total_cnt - rare_cnt))\n",
        "print('단어 집합에서 희귀 단어의 비율:', (rare_cnt/total_cnt)*100)\n",
        "print('전체 등장 빈도에서 희귀 단어 등장 빈도 비율:', (rare_freq/total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o02vYsqX5mJo",
        "outputId": "bd481c94-82e2-471a-c138-9eefa86ed13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기:  31987\n",
            "등장 빈도가 6번 이하인 희귀 단어의 수: 23700\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8287\n",
            "단어 집합에서 희귀 단어의 비율: 74.09260011879826\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.383968496474902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = 8000\n",
        "src_tokenizer = Tokenizer(num_words = src_vocab)\n",
        "src_tokenizer.fit_on_texts(encoder_input_train)\n",
        "\n",
        "#텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
      ],
      "metadata": {
        "id": "zCKXEKnV7M3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정수 인코딩이 정상 진행되었는지 확인\n",
        "\n",
        "print(encoder_input_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZaTBAmv7sDx",
        "outputId": "5afddf8e-f793-4037-bb42-460cdf5d4ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[632, 179, 39, 1, 4640, 1303, 70, 1393, 7, 57, 980, 414, 361, 20, 447, 255, 54, 7683, 1241, 385, 298, 1772, 147, 39, 3, 49, 4388, 108], [4, 489, 206, 446, 91, 583, 100, 2009, 611, 867, 2202, 138, 2766, 334, 2202, 7, 4523, 871, 54, 446, 138, 55, 208, 611, 2009, 2708, 2766, 33, 446, 35, 2766, 2009, 618, 98, 9, 3147, 2767, 75, 100, 4054], [143, 93, 514, 123, 525, 197, 96, 190, 338, 856, 223, 71, 21, 5086, 394, 394, 239, 15, 531, 197]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#레이블에 해당하는 요약 데이터에 대해서도 수행\n",
        "\n",
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "\n",
        "#단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여됨.\n",
        "#이는 tar_tokenizer.word_index에 저장됨.\n"
      ],
      "metadata": {
        "id": "mupBZ4U17ytm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인\n",
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) #단어의 수\n",
        "rare_cnt = 0 #등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 #훈련 데이터의 전체 단어 빈도수 총합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총합\n",
        "\n",
        "#단어와 빈도수의 쌍은 key와 value로 받음.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  #단어의 등장 빈도수가 threshold보다 작으면\n",
        "  if(value<threshold):\n",
        "    rare_cnt = rare_cnt + 1\n",
        "    rare_freq = rare_freq + value\n",
        "\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기:', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s' %(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기: %s' %(total_cnt - rare_cnt))\n",
        "print('단어 집합에서 희귀 단어의 비율:', (rare_cnt/total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq/total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOTqNc9y8E9f",
        "outputId": "ce60ffd2-4381-4353-ae6d-775d6fc500ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기: 13578\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 10826\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기: 2752\n",
            "단어 집합에서 희귀 단어의 비율: 79.73191928119016\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 10.105962623687988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar_vocab = 2000\n",
        "tar_tokenizer = Tokenizer(num_words = tar_vocab)\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer.fit_on_texts(decoder_target_train)"
      ],
      "metadata": {
        "id": "UzQDoDhn9ao8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
      ],
      "metadata": {
        "id": "a9JET-xY_c5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1icerKMg9ywj",
        "outputId": "7e6964f9-0bc7-4086-a697-e7388335a193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[702, 13], [127, 10, 555], [215, 58, 411, 376, 176], [1416], [101, 181]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_target_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_fyyAZe_7N8",
        "outputId": "e69ea587-ccbd-4301-bb69-3d69d3520393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[153, 183], [13, 10, 587], [69, 58, 411, 376, 345], [419], [49, 380]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*빈 샘플 제거: 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것 = 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈 샘플이 되었음 -> 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우, 이 현상이 두드러졌을 가능성이 높아 위험.\n",
        "∇\n",
        "주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플수와 동일하여 단어 집합 제한에도 삭제되지 않음. 따라서 이제 길이가 0이된 요약문의 실질적 길이는 1임. decoder_input에는 sostoken, decoder_target에는 eostoken만 남았을 것이기 때문."
      ],
      "metadata": {
        "id": "bxoh8MKaAAV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train과 test 데이터에 대해 요약문의 길이가 1인 경우의 인덱스를 각각 저장\n",
        "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence)==1]\n",
        "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) ==1]"
      ],
      "metadata": {
        "id": "yaLkwRjHAtqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('삭제할 훈련 데이터의 개수: ', len(drop_train))\n",
        "print('삭제할 테스트 데이터의 개수: ', len(drop_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlQFM011BFT1",
        "outputId": "6a345f88-6468-451b-e63b-2c55291b70a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제할 훈련 데이터의 개수:  9043\n",
            "삭제할 테스트 데이터의 개수:  2335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#삭제 후의 개수\n",
        "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
        "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
        "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
        "\n",
        "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
        "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
        "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
        "\n",
        "print('훈련 데이터의 개수: ', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수: ', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수: ', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수: ', len(decoder_input_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoNPPHYQBh5l",
        "outputId": "b87ae52c-70c1-44f6-f2e3-a991be400e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 개수:  43612\n",
            "훈련 레이블의 개수:  43612\n",
            "테스트 데이터의 개수:  10828\n",
            "테스트 레이블의 개수:  10828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = asarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 패딩하기"
      ],
      "metadata": {
        "id": "QJ6jdO3FCrAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#앞서 계산해둔 최대 길이로 맞추어 훈련 데이터와 테스트 데이터에 대해 패딩 작업 수행\n",
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
        "\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')\n"
      ],
      "metadata": {
        "id": "oGJo6a4vCsjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# seq2seq + attention으로 요약 모델 설계 및 훈련 시키기"
      ],
      "metadata": {
        "id": "ab3NaB3uDo4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "dh3tbZ_xDt8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#인코더 설계 - 인코더는 LSTM 층을 3개 쌓음\n",
        "\n",
        "embedding_dim = 128\n",
        "hidden_size = 256\n",
        "\n",
        "#인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "#인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
        "\n",
        "#인코더의 LSTM 1\n",
        "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#인코더의 LSTM 2\n",
        "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#인코더의 LSTM 3\n",
        "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)"
      ],
      "metadata": {
        "id": "yMyKWFFAEHAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#디코더 설계 - 인코더와 동일하지만 초기 상태를 인코더의 상태로 주어야 하는 것에 주의\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#디코더의 임베딩 층\n",
        "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "#디코더의 LSTM\n",
        "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
      ],
      "metadata": {
        "id": "9p4XDZsoFnW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#디코더의 출력층 설계\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "#모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnErbzS2GRuC",
        "outputId": "dc14dd42-9a41-480e-c6c0-d0f2c8b8e6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, 50, 128)      1024000     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, 50, 256),    394240      ['embedding_7[0][0]']            \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  [(None, 50, 256),    525312      ['lstm_5[0][0]']                 \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)        (None, None, 128)    256000      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  [(None, 50, 256),    525312      ['lstm_6[0][0]']                 \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)                  [(None, None, 256),  394240      ['embedding_8[0][0]',            \n",
            "                                 (None, 256),                     'lstm_7[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_7[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, None, 2000)   514000      ['lstm_8[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,633,104\n",
            "Trainable params: 3,633,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#어텐션 메커니즘이 결합된 새로운 출력층 설계\n",
        "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/20.%20Text%20Summarization/attention.py\", filename=\"attention.py\")\n",
        "#from attention import AttentionLayer\n",
        "#위 주소 막힘"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "X3Fc9uKuGwwh",
        "outputId": "c25beae7-c1ba-4df5-dfd5-b14d54279fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-d69e1ba81110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/20.%20Text%20Summarization/attention.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttentionLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "uaAsZPIhJjWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
        "                    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "                    batch_size = 256, callbacks=[es], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_zMeE9NI2uC",
        "outputId": "11bcccbb-5c6d-49aa-9413-67614897af51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "171/171 [==============================] - 934s 5s/step - loss: 2.5749 - val_loss: 2.1009\n",
            "Epoch 2/50\n",
            "171/171 [==============================] - 994s 6s/step - loss: 1.8029 - val_loss: 1.4609\n",
            "Epoch 3/50\n",
            "171/171 [==============================] - 880s 5s/step - loss: 1.2771 - val_loss: 1.0473\n",
            "Epoch 4/50\n",
            "171/171 [==============================] - 879s 5s/step - loss: 0.9486 - val_loss: 0.8023\n",
            "Epoch 5/50\n",
            "171/171 [==============================] - 1191s 7s/step - loss: 0.7372 - val_loss: 0.6352\n",
            "Epoch 6/50\n",
            "171/171 [==============================] - 956s 6s/step - loss: 0.5943 - val_loss: 0.5382\n",
            "Epoch 7/50\n",
            "171/171 [==============================] - 892s 5s/step - loss: 0.4965 - val_loss: 0.4597\n",
            "Epoch 8/50\n",
            "171/171 [==============================] - 884s 5s/step - loss: 0.4335 - val_loss: 0.4114\n",
            "Epoch 9/50\n",
            "171/171 [==============================] - 883s 5s/step - loss: 0.3889 - val_loss: 0.3845\n",
            "Epoch 10/50\n",
            "171/171 [==============================] - 881s 5s/step - loss: 0.3521 - val_loss: 0.3594\n",
            "Epoch 11/50\n",
            "171/171 [==============================] - 884s 5s/step - loss: 0.3238 - val_loss: 0.3428\n",
            "Epoch 12/50\n",
            "171/171 [==============================] - 890s 5s/step - loss: 0.3025 - val_loss: 0.3309\n",
            "Epoch 13/50\n",
            "171/171 [==============================] - 891s 5s/step - loss: 0.2838 - val_loss: 0.3238\n",
            "Epoch 14/50\n",
            "171/171 [==============================] - 887s 5s/step - loss: 0.2692 - val_loss: 0.3196\n",
            "Epoch 15/50\n",
            "171/171 [==============================] - 886s 5s/step - loss: 0.2557 - val_loss: 0.3134\n",
            "Epoch 16/50\n",
            "171/171 [==============================] - 884s 5s/step - loss: 0.2438 - val_loss: 0.3110\n",
            "Epoch 17/50\n",
            "171/171 [==============================] - 886s 5s/step - loss: 0.2331 - val_loss: 0.3127\n",
            "Epoch 18/50\n",
            "171/171 [==============================] - 884s 5s/step - loss: 0.2228 - val_loss: 0.3114\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 과정 중 기록된 훈련 데이터의 손실과 테스트 데이터의 손실 히스토리 시각화\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b68Nsa67J7PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2seq + attention으로 요약 모델 테스트하기"
      ],
      "metadata": {
        "id": "UvGj0KF3M_J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트를 위해 필요한 3개의 사전 만들기\n",
        "\n",
        "#원문 단어 집합에서 정수 -> 단어를 얻음\n",
        "src_index_to_word = src_tokenizer.index_word\n",
        "\n",
        "#요약 단어 집합에서 단어 -> 정수를 얻음\n",
        "tar_word_to_index = tar_tokenizer.word_index\n",
        "\n",
        "#요약 단어 집합에서 정수 -> 단어를 얻음\n",
        "tar_index_to_word = tar_tokenizer.index_word"
      ],
      "metadata": {
        "id": "m8qakPMqO72H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seq2seq는 훈련 단계와 테스트 단계의 동작이 다르므로 테스트 단계의 모델을 별도로 설계\n",
        "#다시 새로운 seq2seq 모델 설계\n",
        "\n",
        "#인코더 설계\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n"
      ],
      "metadata": {
        "id": "O_n6C8ewPXW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "#문장의 다음 단어를 예측하기 위해서 초기 상태를 이전 시점의 상태로 사용. \n",
        "#이는 뒤의 함수 decode_sequence()에 구현\n",
        "#훈련 과정에서와 다르게 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음\n",
        "decoder_output2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
      ],
      "metadata": {
        "id": "URcchAMoPr-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#어텐션 함수\n",
        "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hideen_state_input,decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "#디코더의 출력층\n",
        "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
        "\n",
        "#최종 디코더 모델\n",
        "decoder_mode = Model([decoder_inputs]+[decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "                     [decoder_outputs2]+[state_h2, state_c2])\n",
        "\n",
        "#테스트 단계를 위한 모델 완성"
      ],
      "metadata": {
        "id": "YOpK7cIWYjuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트를 위해 사용되는 함수 decode_sequence를 설계\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  #입력으로부터 인코더의 상태를 얻음\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "  #<SOS>에 해당하는 토큰 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0,0] = tar_word_to_index['sostoken']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition: #stop_condition이 True가 될 때까지 루프 반복\n",
        "    \n",
        "    output_tokens, h, c = decoder_model.predict([target_seq]+[e_out, e_h, e_c])\n",
        "    sampled_token_index = np.argmax(output_tokens[0,-1,:])\n",
        "    sampled_token = tar_index_to_word[sampled_token_index]\n",
        "\n",
        "    if(sampled_token!='eostoken'):\n",
        "      decoded_sentence += ' '+sampled_token\n",
        "\n",
        "      # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "    if(sampled_token=='eostoken' or len(decoded_sentence.split())>=(summary_max_len-1)):\n",
        "      stop_condition = True\n",
        "\n",
        "      #길이가 1인 타겟 시퀀스를 업데이트\n",
        "      target_seq = np.zeros((1,1))\n",
        "      target_seq[0,0] = sampled_token_index\n",
        "\n",
        "      #상태를 업데이트\n",
        "      e_h, e_c = h,c\n",
        "\n",
        "  return decoded_sentence\n"
      ],
      "metadata": {
        "id": "Ya8dXrpnZuGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 단계에서 원문과 실제 요약문, 예측 요약문을 비교하기 위해 정수 시퀀스를 텍스트 시퀀스로 만드는 함수 설계\n",
        "\n",
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2text(input_seq):\n",
        "  sentence=''\n",
        "  for i in input_seq:\n",
        "    if(i!=0):\n",
        "      sentence = sentence + src_index_to_word[i]+' '\n",
        "  return sentence\n",
        "\n",
        "#요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2summary(input_seq):\n",
        "  sentence = ''\n",
        "  for i in input_seq:\n",
        "    if(i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
        "      sentence = sentence + tar_index_to_word[i] +' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "Y-I4Bn6hb3kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 샘플 중 500-1000번까지 테스트\n",
        "\n",
        "for i in range(500,1000):\n",
        "  print(\"원문: \", seq2text(encoder_input_test[i]))\n",
        "  print(\"실제 요약문: \", seq2summary(decoder_input_test[i]))\n",
        "  print(\"예측 요약문: \", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "  print(\"\\n\")\n",
        "  "
      ],
      "metadata": {
        "id": "J4QcNWh4csrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2️⃣ Text summarization task**"
      ],
      "metadata": {
        "id": "HfTr_BPwGc8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 2-(1) Pororo - text summarization \n",
        "\n",
        "📌 [공식문서](https://kakaobrain.github.io/pororo/seq2seq/summary.html) \n",
        "\n",
        "📌 [예제 실습](https://teddylee777.github.io/machine-learning/nlp-korean-pororo) \n",
        "\n",
        "* PORORO : 카카오 브레인에서 제공한 자연어 처리 라이브러리"
      ],
      "metadata": {
        "id": "eu3adOV2bDs_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2WbVbbsatD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmVEEfAqdSa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 2-(2) BERT 를 이용한 text summarization \n",
        "\n",
        "📌 [논문 리뷰](https://medium.com/@eyfydsyd97/bert%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%9A%94%EC%95%BD-text-summary-b582b5cc7d) \n",
        "\n",
        "📌 [BERT Extractive summarizer Library](https://github.com/dmmiller612/bert-extractive-summarizer) \n",
        "\n",
        "\n",
        "📌 [Text summarization Github Repo](https://github.com/uoneway/Text-Summarization-Repo) \n",
        "\n",
        "\n",
        "\n",
        "➕ [BERT 를 이용한 뉴스 요약 자동화 App 구현 Repo](https://github.com/huydang90/News-Summarization-with-BERT) 👉 프로젝트 예시 참고 자료\n",
        "\n"
      ],
      "metadata": {
        "id": "xsx6OgzwbnIt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "svtikbdZatBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnfL6KIZdSuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}