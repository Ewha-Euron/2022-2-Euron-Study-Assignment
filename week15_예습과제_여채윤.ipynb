{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTojKTeBufaWcchoE18Bbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyunyeo/2022-2-Euron-Study-Assignment/blob/week15/week15_%EC%98%88%EC%8A%B5%EA%B3%BC%EC%A0%9C_%EC%97%AC%EC%B1%84%EC%9C%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.1 컨텐츠 기반 필터링 실습 – TMDB 5000 Movie Dataset"
      ],
      "metadata": {
        "id": "xOzTfxOcCrYM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3mXxc7RCmw9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "movies =pd.read_csv('./tmdb-5000-movie-dataset/tmdb_5000_movies.csv')\n",
        "print(movies.shape)\n",
        "movies.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = movies[['id','title', 'genres', 'vote_average', 'vote_count',\n",
        "                 'popularity', 'keywords', 'overview']]\n",
        "pd.set_option('max_colwidth', 100)\n",
        "movies_df[['genres','keywords']][:1]"
      ],
      "metadata": {
        "id": "0-Yl_0-ZCtzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "movies_df['genres'] = movies_df['genres'].apply(literal_eval)\n",
        "movies_df['keywords'] = movies_df['keywords'].apply(literal_eval)\n",
        "movies_df['genres'].head(1)"
      ],
      "metadata": {
        "id": "Mfs2nxI3Ctwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df['genres'] = movies_df['genres'].apply(lambda x : [ y['name'] for y in x])\n",
        "movies_df['keywords'] = movies_df['keywords'].apply(lambda x : [ y['name'] for y in x])\n",
        "movies_df[['genres', 'keywords']][:1]"
      ],
      "metadata": {
        "id": "V9Rb7-yECtty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(('*').join(['test', 'test2']))"
      ],
      "metadata": {
        "id": "Zz5vbGUECtrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizer를 적용하기 위해 공백문자로 word 단위가 구분되는 문자열로 변환. \n",
        "movies_df['genres_literal'] = movies_df['genres'].apply(lambda x : (' ').join(x))\n",
        "count_vect = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
        "genre_mat = count_vect.fit_transform(movies_df['genres_literal'])\n",
        "print(genre_mat.shape)"
      ],
      "metadata": {
        "id": "-4_559MICtoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "genre_sim = cosine_similarity(genre_mat, genre_mat)\n",
        "print(genre_sim.shape)\n",
        "print(genre_sim[:2])"
      ],
      "metadata": {
        "id": "OWEC2QHyCtmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_sim_sorted_ind = genre_sim.argsort()[:, ::-1]\n",
        "print(genre_sim_sorted_ind[:1])"
      ],
      "metadata": {
        "id": "fQUwalt2Ctji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sim_movie(df, sorted_ind, title_name, top_n=10):\n",
        "    \n",
        "    # 인자로 입력된 movies_df DataFrame에서 'title' 컬럼이 입력된 title_name 값인 DataFrame추출\n",
        "    title_movie = df[df['title'] == title_name]\n",
        "    \n",
        "    # title_named을 가진 DataFrame의 index 객체를 ndarray로 반환하고 \n",
        "    # sorted_ind 인자로 입력된 genre_sim_sorted_ind 객체에서 유사도 순으로 top_n 개의 index 추출\n",
        "    title_index = title_movie.index.values\n",
        "    similar_indexes = sorted_ind[title_index, :(top_n)]\n",
        "    \n",
        "    # 추출된 top_n index들 출력. top_n index는 2차원 데이터 임. \n",
        "    #dataframe에서 index로 사용하기 위해서 1차원 array로 변경\n",
        "    print(similar_indexes)\n",
        "    similar_indexes = similar_indexes.reshape(-1)\n",
        "    \n",
        "    return df.iloc[similar_indexes]\n",
        "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)\n",
        "similar_movies[['title', 'vote_average']]"
      ],
      "metadata": {
        "id": "gHMuMAHiCtg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df[['title','vote_average','vote_count']].sort_values('vote_average', ascending=False)[:10]"
      ],
      "metadata": {
        "id": "pGc2EZwFCtef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = movies_df['vote_average'].mean()\n",
        "m = movies_df['vote_count'].quantile(0.6)\n",
        "print('C:',round(C,3), 'm:',round(m,3))"
      ],
      "metadata": {
        "id": "-3Uk60tgCtb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentile = 0.6\n",
        "m = movies_df['vote_count'].quantile(percentile)\n",
        "C = movies_df['vote_average'].mean()\n",
        "\n",
        "def weighted_vote_average(record):\n",
        "    v = record['vote_count']\n",
        "    R = record['vote_average']\n",
        "    \n",
        "    return ( (v/(v+m)) * R ) + ( (m/(m+v)) * C )   \n",
        "\n",
        "movies_df['weighted_vote'] = movies_df.apply(weighted_vote_average, axis=1) \n",
        "movies_df[['title','vote_average','weighted_vote','vote_count']].sort_values('weighted_vote',\n",
        "                                                                          ascending=False)[:10]"
      ],
      "metadata": {
        "id": "57grpkKQC6Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sim_movie(df, sorted_ind, title_name, top_n=10):\n",
        "    title_movie = df[df['title'] == title_name]\n",
        "    title_index = title_movie.index.values\n",
        "    \n",
        "    # top_n의 2배에 해당하는 쟝르 유사성이 높은 index 추출 \n",
        "    similar_indexes = sorted_ind[title_index, :(top_n*2)]\n",
        "    similar_indexes = similar_indexes.reshape(-1)\n",
        "# 기준 영화 index는 제외\n",
        "    similar_indexes = similar_indexes[similar_indexes != title_index]\n",
        "    \n",
        "    # top_n의 2배에 해당하는 후보군에서 weighted_vote 높은 순으로 top_n 만큼 추출 \n",
        "    return df.iloc[similar_indexes].sort_values('weighted_vote', ascending=False)[:top_n]\n",
        "\n",
        "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)\n",
        "similar_movies[['title', 'vote_average', 'weighted_vote']]"
      ],
      "metadata": {
        "id": "gDWYK1cOC6Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.2 아이템 기반 인접 이웃 협업 필터링 실습"
      ],
      "metadata": {
        "id": "RHFeBpHMDAOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
        "print(movies.shape)\n",
        "print(ratings.shape)"
      ],
      "metadata": {
        "id": "3E5n-NF0C6AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings[['userId', 'movieId', 'rating']]\n",
        "ratings_matrix = ratings.pivot_table('rating', index='userId', columns='movieId')\n",
        "ratings_matrix.head(3)"
      ],
      "metadata": {
        "id": "XZHom7DqC59g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# title 컬럼을 얻기 이해 movies 와 조인 수행\n",
        "rating_movies = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# columns='title' 로 title 컬럼으로 pivot 수행. \n",
        "ratings_matrix = rating_movies.pivot_table('rating', index='userId', columns='title')\n",
        "\n",
        "# NaN 값을 모두 0 으로 변환\n",
        "ratings_matrix = ratings_matrix.fillna(0)\n",
        "ratings_matrix.head(3)"
      ],
      "metadata": {
        "id": "cRIVYVEPC567"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_matrix_T = ratings_matrix.transpose()\n",
        "ratings_matrix_T.head(3)"
      ],
      "metadata": {
        "id": "Vn4nqXjhC54h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_matrix_T.shape"
      ],
      "metadata": {
        "id": "g0SMvdt3C517"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "item_sim = cosine_similarity(ratings_matrix_T, ratings_matrix_T)\n",
        "\n",
        "# cosine_similarity() 로 반환된 넘파이 행렬을 영화명을 매핑하여 DataFrame으로 변환\n",
        "item_sim_df = pd.DataFrame(data=item_sim, index=ratings_matrix.columns,\n",
        "                          columns=ratings_matrix.columns)\n",
        "print(item_sim_df.shape)\n",
        "item_sim_df.head(3)"
      ],
      "metadata": {
        "id": "aaHrxGTVC5zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_sim_df[\"Godfather, The (1972)\"].sort_values(ascending=False)[:6]\n"
      ],
      "metadata": {
        "id": "Yd4zUHB_DH8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_sim_df[\"Inception (2010)\"].sort_values(ascending=False)[1:6]\n"
      ],
      "metadata": {
        "id": "uhP7YzE5DH5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating(ratings_arr, item_sim_arr ):\n",
        "    ratings_pred = ratings_arr.dot(item_sim_arr)/ np.array([np.abs(item_sim_arr).sum(axis=1)])\n",
        "    return ratings_pred\n",
        "ratings_matrix.head(3)"
      ],
      "metadata": {
        "id": "xutiC8CHDH28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_pred = predict_rating(ratings_matrix.values , item_sim_df.values)\n",
        "ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index= ratings_matrix.index,\n",
        "                                   columns = ratings_matrix.columns)\n",
        "print(ratings_pred_matrix.shape)\n",
        "ratings_pred_matrix.head(3)"
      ],
      "metadata": {
        "id": "c7wORdhIDH0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 사용자가 평점을 부여한 영화에 대해서만 예측 성능 평가 MSE 를 구함. \n",
        "def get_mse(pred, actual):\n",
        "    # Ignore nonzero terms.\n",
        "    pred = pred[actual.nonzero()].flatten()\n",
        "    actual = actual[actual.nonzero()].flatten()\n",
        "    return mean_squared_error(pred, actual)\n",
        "\n",
        "print('아이템 기반 모든 인접 이웃 MSE: ', get_mse(ratings_pred, ratings_matrix.values ))"
      ],
      "metadata": {
        "id": "0r8NmC6NDHxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating_topsim(ratings_arr, item_sim_arr, n=20):\n",
        "    # 사용자-아이템 평점 행렬 크기만큼 0으로 채운 예측 행렬 초기화\n",
        "    pred = np.zeros(ratings_arr.shape)\n",
        "\n",
        "    # 사용자-아이템 평점 행렬의 열 크기만큼 Loop 수행. \n",
        "    for col in range(ratings_arr.shape[1]):\n",
        "        # 유사도 행렬에서 유사도가 큰 순으로 n개 데이터 행렬의 index 반환\n",
        "        top_n_items = [np.argsort(item_sim_arr[:, col])[:-n-1:-1]]\n",
        "        # 개인화된 예측 평점을 계산\n",
        "        for row in range(ratings_arr.shape[0]):\n",
        "            pred[row, col] = item_sim_arr[col, :][top_n_items].dot(ratings_arr[row, :][top_n_items].T) \n",
        "            pred[row, col] /= np.sum(np.abs(item_sim_arr[col, :][top_n_items]))        \n",
        "    return pred"
      ],
      "metadata": {
        "id": "0FYyjeFgDHvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_pred = predict_rating_topsim(ratings_matrix.values , item_sim_df.values, n=20)\n",
        "print('아이템 기반 인접 TOP-20 이웃 MSE: ', get_mse(ratings_pred, ratings_matrix.values ))\n",
        "\n",
        "\n",
        "# 계산된 예측 평점 데이터는 DataFrame으로 재생성\n",
        "ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index= ratings_matrix.index,\n",
        "                                   columns = ratings_matrix.columns)"
      ],
      "metadata": {
        "id": "DEolu1kfDHsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_rating_id = ratings_matrix.loc[9, :]\n",
        "user_rating_id[ user_rating_id > 0].sort_values(ascending=False)[:10]"
      ],
      "metadata": {
        "id": "myP0vkuKDHpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unseen_movies(ratings_matrix, userId):\n",
        "    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n",
        "    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n",
        "    user_rating = ratings_matrix.loc[userId,:]\n",
        "    \n",
        "    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n",
        "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
        "    \n",
        "    # 모든 영화명을 list 객체로 만듬. \n",
        "    movies_list = ratings_matrix.columns.tolist()\n",
        "    \n",
        "    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n",
        "    unseen_list = [ movie for movie in movies_list if movie not in already_seen]\n",
        "    \n",
        "    return unseen_list"
      ],
      "metadata": {
        "id": "Vn0qbf44DR_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):\n",
        "    # 예측 평점 DataFrame에서 사용자id index와 unseen_list로 들어온 영화명 컬럼을 추출하여\n",
        "    # 가장 예측 평점이 높은 순으로 정렬함. \n",
        "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
        "    return recomm_movies\n",
        "    \n",
        "# 사용자가 관람하지 않는 영화명 추출   \n",
        "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
        "\n",
        "# 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천 \n",
        "recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, unseen_list, top_n=10)\n",
        "\n",
        "# 평점 데이타를 DataFrame으로 생성. \n",
        "recomm_movies = pd.DataFrame(data=recomm_movies.values,index=recomm_movies.index,columns=['pred_score'])\n",
        "recomm_movies"
      ],
      "metadata": {
        "id": "iISGuG-vDR86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "경사하강을 이용한 행렬 분해"
      ],
      "metadata": {
        "id": "3doQ7CrODYQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재요인 차원 K는 3 설정. \n",
        "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
        "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
        "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
        "              [5, 2, 1, 2, np.NaN ]])\n",
        "\n",
        "num_users, num_items = R.shape\n",
        "K=3\n",
        "\n",
        "# P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 random한 값으로 입력합니다. \n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
        "print(\"P:\",P)\n",
        "print(\"Q:\",Q)"
      ],
      "metadata": {
        "id": "TwX1aetODR6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R, P, Q, non_zeros):\n",
        "    error = 0\n",
        "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "    full_pred_matrix = np.dot(P, Q.T)\n",
        "    \n",
        "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
        "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "      \n",
        "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "    rmse = np.sqrt(mse)\n",
        "    \n",
        "    return rmse"
      ],
      "metadata": {
        "id": "txNjcrDbDR3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장. \n",
        "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
        "\n",
        "steps=1000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
        "for step in range(steps):\n",
        "    for i, j, r in non_zeros:\n",
        "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
        "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
        "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "        P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
        "        Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
        "\n",
        "    rmse = get_rmse(R, P, Q, non_zeros)\n",
        "    if (step % 50) == 0 :\n",
        "        print(\"### iteration step : \", step,\" rmse : \", rmse)"
      ],
      "metadata": {
        "id": "oQ96CQwnDR1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_matrix = np.dot(P, Q.T)\n",
        "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
      ],
      "metadata": {
        "id": "Vrvv6WmgDRyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
        "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
        "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
        "              [5, 2, 1, 2, np.NaN ]])"
      ],
      "metadata": {
        "id": "NnIEX9MVDRv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_factorization(R, K, steps=200, learning_rate=0.01, r_lambda = 0.01):\n",
        "    num_users, num_items = R.shape\n",
        "    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다. \n",
        "    np.random.seed(1)\n",
        "    P = np.random.normal(scale=1./K, size=(num_users, K))\n",
        "    Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
        "\n",
        "    break_count = 0\n",
        "       \n",
        "    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장. \n",
        "    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
        "   \n",
        "    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
        "    for step in range(steps):\n",
        "        for i, j, r in non_zeros:\n",
        "            # 실제 값과 예측 값의 차이인 오류 값 구함\n",
        "            eij = r - np.dot(P[i, :], Q[j, :].T)\n",
        "            # Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
        "            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
        "       \n",
        "        rmse = get_rmse(R, P, Q, non_zeros)\n",
        "        if (step % 10) == 0 :\n",
        "            print(\"### iteration step : \", step,\" rmse : \", rmse)\n",
        "            \n",
        "    return P, Q"
      ],
      "metadata": {
        "id": "jnMYwDdwDRs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
        "ratings = ratings[['userId', 'movieId', 'rating']]\n",
        "ratings_matrix = ratings.pivot_table('rating', index='userId', columns='movieId')\n",
        "\n",
        "# title 컬럼을 얻기 이해 movies 와 조인 수행\n",
        "rating_movies = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# columns='title' 로 title 컬럼으로 pivot 수행. \n",
        "ratings_matrix = rating_movies.pivot_table('rating', index='userId', columns='title')\n",
        "P, Q = matrix_factorization(ratings_matrix.values, K=50, steps=200, learning_rate=0.01, r_lambda = 0.01)\n",
        "pred_matrix = np.dot(P, Q.T)"
      ],
      "metadata": {
        "id": "rRxPegiKDRqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index= ratings_matrix.index,\n",
        "                                   columns = ratings_matrix.columns)\n",
        "\n",
        "ratings_pred_matrix.head(3)"
      ],
      "metadata": {
        "id": "ZWy696iwDRn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unseen_movies(ratings_matrix, userId):\n",
        "    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n",
        "    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n",
        "    user_rating = ratings_matrix.loc[userId,:]\n",
        "    \n",
        "    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n",
        "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
        "    \n",
        "    # 모든 영화명을 list 객체로 만듬. \n",
        "    movies_list = ratings_matrix.columns.tolist()\n",
        "    \n",
        "    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n",
        "    unseen_list = [ movie for movie in movies_list if movie not in already_seen]\n",
        "    \n",
        "    return unseen_list"
      ],
      "metadata": {
        "id": "EWc6brhQDjqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):\n",
        "    # 예측 평점 DataFrame에서 사용자id index와 unseen_list로 들어온 영화명 컬럼을 추출하여\n",
        "    # 가장 예측 평점이 높은 순으로 정렬함. \n",
        "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
        "    return recomm_movies"
      ],
      "metadata": {
        "id": "A3CMQCwVDjn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자가 관람하지 않는 영화명 추출   \n",
        "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
        "\n",
        "# 잠재요인 기반 협업 필터링으로 영화 추천 \n",
        "recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, unseen_list, top_n=10)\n",
        "\n",
        "# 평점 데이타를 DataFrame으로 생성. \n",
        "recomm_movies = pd.DataFrame(data=recomm_movies.values,index=recomm_movies.index,columns=['pred_score'])\n",
        "recomm_movies"
      ],
      "metadata": {
        "id": "8wCOoWMODjlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surprise 를 이용한 추천 시스템 구축\n",
        "from surprise import SVD"
      ],
      "metadata": {
        "id": "XJ5ro8jPDpbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset \n",
        "from surprise import accuracy \n",
        "from surprise.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tDaB3VeuDjii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.load_builtin('ml-100k') \n",
        "trainset, testset = train_test_split(data, test_size=.25, random_state=0) "
      ],
      "metadata": {
        "id": "latmRErhDjgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = SVD()\n",
        "algo.fit(trainset) "
      ],
      "metadata": {
        "id": "H9jbHca_DsPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = algo.test(testset)\n",
        "print('prediction type :',type(predictions), ' size:',len(predictions))\n",
        "print('prediction 결과의 최초 5개 추출')\n",
        "predictions[:5]\n",
        "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
      ],
      "metadata": {
        "id": "0-hHy-KBDsMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함. \n",
        "uid = str(196)\n",
        "iid = str(302)\n",
        "pred = algo.predict(uid, iid)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "WjQs7ISqDsKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "id": "NCsCJnsyDsHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
        "# ratings_noh.csv 파일로 unload 시 index 와 header를 모두 제거한 새로운 파일 생성.  \n",
        "ratings.to_csv('./ml-latest-small/ratings_noh.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "0fmYoLASDsFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Reader\n",
        "\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
        "data=Dataset.load_from_file('./ml-latest-small/ratings_noh.csv',reader=reader)"
      ],
      "metadata": {
        "id": "UYoo1nxuDsCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
        "\n",
        "# 수행시마다 동일한 결과 도출을 위해 random_state 설정 \n",
        "algo = SVD(n_factors=50, random_state=0)\n",
        "\n",
        "# 학습 데이터 세트로 학습 후 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
        "algo.fit(trainset) \n",
        "predictions = algo.test( testset )\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "id": "10Blq6VJDy1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Reader, Dataset\n",
        "\n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv') \n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "\n",
        "# ratings DataFrame 에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 합니다. \n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
        "\n",
        "algo = SVD(n_factors=50, random_state=0)\n",
        "algo.fit(trainset) \n",
        "predictions = algo.test( testset )\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "id": "1q6G-YmoDyy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import cross_validate \n",
        "\n",
        "# Pandas DataFrame에서 Surprise Dataset으로 데이터 로딩 \n",
        "ratings = pd.read_csv('./ml-latest-small/ratings.csv') # reading data in pandas df\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "algo = SVD(random_state=0) \n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True) "
      ],
      "metadata": {
        "id": "qhDNBul6DywS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "# 최적화할 파라미터들을 딕셔너리 형태로 지정. \n",
        "param_grid = {'n_epochs': [20, 40, 60], 'n_factors': [50, 100, 200] }\n",
        "\n",
        "# CV를 3개 폴드 세트로 지정, 성능 평가는 rmse, mse 로 수행 하도록 GridSearchCV 구성\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "# 최고 RMSE Evaluation 점수와 그때의 하이퍼 파라미터\n",
        "print(gs.best_score['rmse'])\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "QsbNSFu3DyuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 코드는 train_test_split( )으로 분리되지 않는 Dataset에 fit( )을 호출하여 오류를 발생합니다.\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "algo = SVD(n_factors=50, random_state=0)\n",
        "algo.fit(data)"
      ],
      "metadata": {
        "id": "nY4PivelDyrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.dataset import DatasetAutoFolds\n",
        "\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
        "# DatasetAutoFolds 클래스를 ratings_noh.csv 파일 기반으로 생성. \n",
        "data_folds = DatasetAutoFolds(ratings_file='./ml-latest-small/ratings_noh.csv', reader=reader)\n",
        "\n",
        "#전체 데이터를 학습데이터로 생성함. \n",
        "trainset = data_folds.build_full_trainset()"
      ],
      "metadata": {
        "id": "DMP5gjjRDypF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
        "algo.fit(trainset)\n",
        "# 영화에 대한 상세 속성 정보 DataFrame로딩\n",
        "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
        "\n",
        "# userId=9 의 movieId 데이터 추출하여 movieId=42 데이터가 있는지 확인. \n",
        "movieIds = ratings[ratings['userId']==9]['movieId']\n",
        "if movieIds[movieIds==42].count() == 0:\n",
        "    print('사용자 아이디 9는 영화 아이디 42의 평점 없음')\n",
        "\n",
        "print(movies[movies['movieId']==42])"
      ],
      "metadata": {
        "id": "ol935aZHDym8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uid = str(9)\n",
        "iid = str(42)\n",
        "\n",
        "pred = algo.predict(uid, iid, verbose=True)"
      ],
      "metadata": {
        "id": "J1rWyKUSDyka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unseen_surprise(ratings, movies, userId):\n",
        "    #입력값으로 들어온 userId에 해당하는 사용자가 평점을 매긴 모든 영화를 리스트로 생성\n",
        "    seen_movies = ratings[ratings['userId']== userId]['movieId'].tolist()\n",
        "    \n",
        "    # 모든 영화들의 movieId를 리스트로 생성. \n",
        "    total_movies = movies['movieId'].tolist()\n",
        "    \n",
        "    # 모든 영화들의 movieId중 이미 평점을 매긴 영화의 movieId를 제외하여 리스트로 생성\n",
        "    unseen_movies= [movie for movie in total_movies if movie not in seen_movies]\n",
        "    print('평점 매긴 영화수:',len(seen_movies), '추천대상 영화수:',len(unseen_movies), \\\n",
        "          '전체 영화수:',len(total_movies))\n",
        "    \n",
        "    return unseen_movies\n",
        "\n",
        "unseen_movies = get_unseen_surprise(ratings, movies, 9)"
      ],
      "metadata": {
        "id": "OQnLJN0bD8QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
        "    # 알고리즘 객체의 predict() 메서드를 평점이 없는 영화에 반복 수행한 후 결과를 list 객체로 저장\n",
        "    predictions = [algo.predict(str(userId), str(movieId)) for movieId in unseen_movies]\n",
        "    \n",
        "    # predictions list 객체는 surprise의 Predictions 객체를 원소로 가지고 있음.\n",
        "    # [Prediction(uid='9', iid='1', est=3.69), Prediction(uid='9', iid='2', est=2.98),,,,]\n",
        "    # 이를 est 값으로 정렬하기 위해서 아래의 sortkey_est 함수를 정의함.\n",
        "    # sortkey_est 함수는 list 객체의 sort() 함수의 키 값으로 사용되어 정렬 수행.\n",
        "    def sortkey_est(pred):\n",
        "        return pred.est\n",
        "    \n",
        "    # sortkey_est( ) 반환값의 내림 차순으로 정렬 수행하고 top_n개의 최상위 값 추출.\n",
        "    predictions.sort(key=sortkey_est, reverse=True)\n",
        "    top_predictions= predictions[:top_n]\n",
        "    \n",
        "    # top_n으로 추출된 영화의 정보 추출. 영화 아이디, 추천 예상 평점, 제목 추출\n",
        "    top_movie_ids = [ int(pred.iid) for pred in top_predictions]\n",
        "    top_movie_rating = [ pred.est for pred in top_predictions]\n",
        "    top_movie_titles = movies[movies.movieId.isin(top_movie_ids)]['title']\n",
        "    top_movie_preds = [ (id, title, rating) for id, title, rating in zip(top_movie_ids, top_movie_titles, top_movie_rating)]\n",
        "    \n",
        "    return top_movie_preds\n",
        "\n",
        "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
        "top_movie_preds = recomm_movie_by_surprise(algo, 9, unseen_movies, top_n=10)\n",
        "print('##### Top-10 추천 영화 리스트 #####')\n",
        "\n",
        "for top_movie in top_movie_preds:\n",
        "    print(top_movie[1], \":\", top_movie[2])"
      ],
      "metadata": {
        "id": "mRGkU-pPD8Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgqlKRIeD8LI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}