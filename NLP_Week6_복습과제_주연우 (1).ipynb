{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUHfXkPAORh"
      },
      "source": [
        "ğŸ“Œ week5 ë‚´ìš© ì£¼ì°¨ì— í•´ë‹¹ë˜ëŠ” ê³¼ì œëŠ” Glove ëª¨ë¸ ì‹¤ìŠµ, NER task ì‹¤ìŠµ, Dependency Parsing task ì‹¤ìŠµìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (**ì°¸ê³ ** : **ì œì¶œì€ week6 branch ë³µìŠµê³¼ì œë¡œ!**)\n",
        "\n",
        "ğŸ“Œ ìœ„í‚¤ë…ìŠ¤ì˜ ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ êµì¬ ì‹¤ìŠµ, ìºê¸€ ë…¸íŠ¸ë¶ ë“±ì˜ ìë£Œë¡œ êµ¬ì„±ë˜ì–´ìˆëŠ” ê³¼ì œì…ë‹ˆë‹¤. \n",
        "\n",
        "ğŸ“Œ ì•ˆë‚´ëœ ë§í¬ì— ë§ì¶”ì–´ **ì§ì ‘ ì½”ë“œë¥¼ ë”°ë¼ ì¹˜ë©´ì„œ (í•„ì‚¬)** í•´ë‹¹ nlp task ì˜ ê¸°ë³¸ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë©”ì„œë“œë¥¼ ìˆ™ì§€í•´ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ğŸ˜Š í•„ìˆ˜ë¼ê³  ì²´í¬í•œ ë¶€ë¶„ì€ ê³¼ì œì— ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì£¼ì‹œê³ , ì„ íƒìœ¼ë¡œ ì²´í¬í•œ ë¶€ë¶„ì€ ììœ¨ì ìœ¼ë¡œ ìŠ¤í„°ë”” í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Œ ê¶ê¸ˆí•œ ì‚¬í•­ì€ ê¹ƒí—ˆë¸Œ ì´ìŠˆë‚˜, ì¹´í†¡ë°©, ì„¸ì…˜ ë°œí‘œ ì‹œì‘ ì´ì „ ì‹œê°„ ë“±ì„ í™œìš©í•˜ì—¬ ììœ ë¡­ê²Œ ê³µìœ í•´ì£¼ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjTSbcxBB6o",
        "outputId": "634eb0b5-36b3-48df-c98f-e1b0e63a3993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk colab í™˜ê²½ì—ì„œ ì‹¤í–‰ì‹œ í•„ìš”í•œ ì½”ë“œì…ë‹ˆë‹¤. \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPZn15zBHIv"
      },
      "source": [
        "### 1ï¸âƒ£ **Glove**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11biHcUuBaH"
      },
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n",
        "* ìŠ¤íƒ í¬ë“œ ëŒ€í•™ì—ì„œ ê°œë°œí•œ ì¹´ìš´íŠ¸ ê¸°ë°˜ê³¼ ì˜ˆì¸¡ ê¸°ë°˜ì„ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” ë‹¨ì–´ ì„ë² ë”© ë°©ë²•ë¡  \n",
        "* word2vec ì˜ ë‹¨ì ì„ ë³´ì™„í•´ì„œ ë‚˜ì˜¨ ëª¨ë¸ \n",
        "* glove model ì˜ **input ì€ ë°˜ë“œì‹œ ë™ì‹œë“±ì¥í–‰ë ¬ í˜•íƒœ**ì—¬ì•¼ í•œë‹¤ â­\n",
        "\n",
        "![1](https://www.dropbox.com/s/nz0ji4yzre56ifv/word_presentation.png?raw=1) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ğŸ¤” í•œêµ­ì–´ ì˜ˆì œëŠ” ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” k-Glove ë¡œ ì†Œê°œë˜ëŠ” ì—°êµ¬ê°€ ìˆê¸´ í•œë°, ì¢€ ë” ì•Œì•„ë´ì•¼ í•  ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "â• [ë…¼ë¬¸1](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NPAP13255003&dbt=NPAP)\n",
        "\n",
        "\n",
        "â•[ë…¼ë¬¸2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=CFKO201832073078664&oCn=NPAP13255064&dbt=CFKO&journal=NPRO00383361&keyword=%ED%95%9C%EA%B5%AD%EC%96%B4%20%EB%8C%80%ED%99%94%20%EC%97%94%EC%A7%84%EC%97%90%EC%84%9C%EC%9D%98%20%EB%AC%B8%EC%9E%A5%EB%B6%84%EB%A5%98)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asGcGy6fBM1E"
      },
      "source": [
        "ğŸ”¹ **1-(1)** glove python\n",
        "\n",
        "* [ì‹¤ìŠµ : basic code](https://wikidocs.net/22885) ğŸ‘‰ í•„ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V31NoJdu5t3p",
        "outputId": "8c748535-ba24-46fc-952a-61329c4971b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting glove_python_binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 948 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.21.6)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install glove_python_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ta6QgoKO5uXJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "5df803b8-80d6-40a0-c2c3-5ca052632096"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-157d785d5cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus() \n",
        "\n",
        "corpus.fit(result, window=5)\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "\n",
        "\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove.most_similar(\"man\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "NUbXjrvuihls",
        "outputId": "3c760cd1-eaf3-42da-f219-8e8c41a2e070"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b847cae73192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"man\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ADfVM9lO9NE"
      },
      "source": [
        "ğŸ”¹ **1-(2)** pre-trained glove \n",
        "\n",
        "* **ì‚¬ì „í•™ìŠµëª¨ë¸** : ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë“¤ì„ ë‹¤ë¥¸ ë¬¸ì œì— í•™ìŠµì‹œí‚¨ ê°€ì¤‘ì¹˜ë“¤ë¡œ ì´ˆê¸°í™”í•˜ëŠ” ë°©ë²•ì´ë‹¤.ì‚¬ì „ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•´ í•™ìŠµí•˜ê³ ì í•˜ëŠ” ë³¸ë˜ ë¬¸ì œë¥¼ í•˜ìœ„ë¬¸ì œë¼ê³  í•œë‹¤. \n",
        "\n",
        "* [ì‹¤ìŠµ : ë¬¸ì¥ì˜ ê¸ë¶€ì •ì„ íŒë‹¨í•˜ëŠ” ê°ì„± ë¶„ë¥˜ ëª¨ë¸ ë§Œë“¤ê¸°](https://wikidocs.net/33793) ğŸ‘‰ í•„ìˆ˜\n",
        "  * [ì„¤ëª…ì°¸ê³ ](https://omicro03.medium.com/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-16%EC%9D%BC%EC%B0%A8-pre-trained-word-embedding-bb30db424a35)\n",
        "* pre-trained data ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¼\n",
        "* kaggle ëŒ€íšŒì—ì„œ ì£¼ë¡œ ì´ ë°©ì‹ì„ ë§ì´ ì‚¬ìš©í•¨\n",
        "  * [ì°¸ê³ ](https://lsjsj92.tistory.com/455)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZlngY35O53sk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # íŒ¨ë”©ì„ ê³ ë ¤í•˜ì—¬ +1\n",
        "print('ë‹¨ì–´ ì§‘í•© :',vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH3rD648jDxQ",
        "outputId": "9ef5fe4f-b5fb-4345-9a61-9a9365c90b4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‹¨ì–´ ì§‘í•© : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print('ì •ìˆ˜ ì¸ì½”ë”© ê²°ê³¼ :',X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl2kvYX-jHcW",
        "outputId": "c565d27c-0a14-4d7b-e1a2-d7d9c3ea748e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì •ìˆ˜ ì¸ì½”ë”© ê²°ê³¼ : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('ìµœëŒ€ ê¸¸ì´ :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGuLygJWjMB6",
        "outputId": "1d9f7022-12fe-4f0a-fd7c-b5d5070fe0f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìµœëŒ€ ê¸¸ì´ : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_train = np.array(y_train)\n",
        "print('íŒ¨ë”© ê²°ê³¼ :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAiVGdGEjPpA",
        "outputId": "490a6d35-3e20-4cce-bde8-848fa5e163e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "íŒ¨ë”© ê²°ê³¼ :\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "embedding_dim = 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHNEruJTjPtm",
        "outputId": "90e51784-248e-4b6c-c3eb-dc184ff45d1b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 1s - loss: 0.7020 - acc: 0.4286 - 849ms/epoch - 849ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 0.7005 - acc: 0.4286 - 8ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 0.6990 - acc: 0.4286 - 7ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 0.6976 - acc: 0.4286 - 8ms/epoch - 8ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 0.6961 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.6947 - acc: 0.5714 - 9ms/epoch - 9ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.6933 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.6918 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.6904 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.6890 - acc: 0.5714 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.6876 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.6862 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.6847 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.6833 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.6819 - acc: 0.5714 - 7ms/epoch - 7ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.6805 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.6791 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.6777 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.6763 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.6749 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.6735 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.6721 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.6707 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.6693 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.6679 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.6664 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.6650 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.6636 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.6621 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.6607 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.6592 - acc: 0.5714 - 5ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.6578 - acc: 0.5714 - 4ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.6563 - acc: 0.5714 - 6ms/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.6548 - acc: 0.7143 - 6ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.6533 - acc: 0.7143 - 5ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.6518 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.6503 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.6488 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.6473 - acc: 0.8571 - 7ms/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.6458 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.6442 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.6427 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.6411 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.6395 - acc: 0.8571 - 7ms/epoch - 7ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.6379 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.6363 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.6347 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.6331 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.6315 - acc: 0.8571 - 8ms/epoch - 8ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.6299 - acc: 0.8571 - 6ms/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.6282 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.6266 - acc: 0.8571 - 4ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.6249 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.6232 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.6215 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.6198 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.6181 - acc: 0.8571 - 5ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.6164 - acc: 0.8571 - 8ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.6147 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.6129 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.6112 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.6094 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.6077 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.6059 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.6041 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.6023 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.6005 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.5987 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.5968 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.5950 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.5931 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.5913 - acc: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.5894 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.5875 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.5856 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.5838 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.5818 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.5799 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.5780 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.5761 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.5741 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.5722 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.5702 - acc: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.5683 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.5663 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.5643 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.5624 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.5604 - acc: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.5584 - acc: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.5564 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.5543 - acc: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.5523 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.5503 - acc: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.5483 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.5462 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.5442 - acc: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.5421 - acc: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.5401 - acc: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.5380 - acc: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.5359 - acc: 1.0000 - 5ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01fa69d850>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLIevUh6jYCA",
        "outputId": "c2bf0dbe-1427-4105-f14f-7251d5d378c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100uDZrFjc6J",
        "outputId": "ba508955-ded2-4523-8170-19f5e6d7efd3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve, urlopen\n",
        "import gzip\n",
        "import zipfile\n",
        "\n",
        "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
        "zf = zipfile.ZipFile('glove.6B.zip')\n",
        "zf.extractall() \n",
        "zf.close()"
      ],
      "metadata": {
        "id": "RKzFuA_AjdEx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dict = dict()\n",
        "\n",
        "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%sê°œì˜ Embedding vectorê°€ ìˆìŠµë‹ˆë‹¤.' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxEvelVRjlnZ",
        "outputId": "f63ceffd-1ff4-463c-be87-de908c212434"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000ê°œì˜ Embedding vectorê°€ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print('ë²¡í„°ì˜ ì°¨ì› ìˆ˜ :',len(embedding_dict['respectable']))\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('ì„ë² ë”© í–‰ë ¬ì˜ í¬ê¸°(shape) :',np.shape(embedding_matrix)\n",
        "\n",
        "print(tokenizer.word_index.items())\n",
        "\n",
        "print('ë‹¨ì–´ greatì˜ ë§µí•‘ëœ ì •ìˆ˜ :',tokenizer.word_index['great']\n",
        "      \n",
        "print(embedding_dict['great'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbRBvhmwjpjp",
        "outputId": "31255950-a09a-4ee4-bac6-ae8b88ed8288"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "ë²¡í„°ì˜ ì°¨ì› ìˆ˜ : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    vector_value = embedding_dict.get(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value\n",
        "embedding_matrix[2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "B2RzSu5Lj5De",
        "outputId": "06e29c5a-ec41-4e24-a110-dae9bf56fcde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-852b0a99dc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvector_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvector_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "output_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, output_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "id": "20mA2SLUkFQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_wcrE5PtLMI"
      },
      "source": [
        "ğŸ”¹ **1-(3)** fine tuning glove\n",
        "* ë¯¸ì„¸ì¡°ì • : ì‚¬ì „ í•™ìŠµí•œ ëª¨ë“  ê°€ì¤‘ì¹˜ì™€ ë”ë¶ˆì–´ í•˜ìœ„ ë¬¸ì œë¥¼ ìœ„í•œ ìµœì†Œí•œì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¶”ê°€í•´ ëª¨ë¸ì„ ì¶”ê°€ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ë‹¤. \n",
        "\n",
        "* fine tuning ì´ í•„ìš”í•œ ê²½ìš° \n",
        "  * pretrained model ì— ë°ì´í„°ì…‹ì— ìˆëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš° \n",
        "  * ë°ì´í„° ì§‘í•©ì´ ë„ˆë¬´ ì‘ì•„ì„œ ì „ì²´ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ì–´ë ¤ìš´ ê²½ìš° \n",
        "\n",
        "* [Mittens ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ fine tuning](https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39) ğŸ‘‰ í•„ìˆ˜\n",
        "  *  GloVe ì„ë² ë”©ì„ fine-tuning í•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "  * [github](https://github.com/roamanalytics/mittens)\n",
        "\n",
        "* [í•œêµ­ì–´ ì†Œì„¤ í…ìŠ¤íŠ¸ ë°ì´í„° ë¯¸ì„¸ì¡°ì • ëª¨ë¸ í•™ìŠµ - GPT2](https://m.blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=horajjan&logNo=222104684132&categoryNo=120&proxyReferer=) ğŸ‘‰ ì„ íƒ (glove ëª¨ë¸ ì˜ˆì œëŠ” ì•„ë‹™ë‹ˆë‹¤. fine-tuning ì— ì´ˆì ì„ ë‘ì–´ì„œ ì°¸ê³ í•´ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "def glove2dict(glove_filename):\n",
        "    with open(glove_filename) as f:\n",
        "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
        "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
        "                for line in reader}\n",
        "    return embed"
      ],
      "metadata": {
        "id": "U0ULLh_smGr0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def glove2dict(glove_filename):\n",
        "    with open(glove_filename, encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, delimiter=' ',quoting=csv.QUOTE_NONE)\n",
        "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
        "                for line in reader}\n",
        "    return embed\n",
        "glove_path = \"glove.6B.50d.txt\"\n",
        "pre_glove = glove2dict(glove_path)\n",
        "\n",
        "sw = list(stop_words.ENGLISH_STOP_WORDS)\n",
        "brown_data = brown.words()[:200000]\n",
        "brown_nonstop = [token.lower() for token in brown_data if (token.lower() not in sw)]\n",
        "oov = [token for token in brown_nonstop if token not in pre_glove.keys()]\n",
        "\n",
        "def get_rareoov(xdict, val):\n",
        "    return [k for (k,v) in Counter(xdict).items() if v<=val]\n",
        "oov_rare = get_rareoov(oov, 1)\n",
        "corp_vocab = list(set(oov) - set(oov_rare))\n",
        "\n",
        "brown_tokens = [token for token in brown_nonstop if token not in oov_rare]\n",
        "brown_doc = [' '.join(brown_tokens)]\n",
        "corp_vocab = list(set(oov))\n",
        "\n",
        "cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n",
        "X = cv.fit_transform(brown_doc)\n",
        "Xc = (X.T * X)\n",
        "Xc.setdiag(0)\n",
        "coocc_ar = Xc.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "F8qFD_jWjnmU",
        "outputId": "ec5bd6b5-158e-412d-dd9e-7a4ccb666b66"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-11f0e63555fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpre_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbrown_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbrown_nonstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbrown_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mittens_model = Mittens(n=50, max_iter=1000)\n",
        "new_embeddings = mittens_model.fit(\n",
        "    coocc_ar,\n",
        "    vocab=corp_vocab,\n",
        "    initial_embedding_dict= pre_glove)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "BKka9jKrjNGM",
        "outputId": "dac0010c-991a-46b1-ffb1-ad150519376a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c6f33a93ab11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmittens_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMittens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m new_embeddings = mittens_model.fit(\n\u001b[1;32m      3\u001b[0m     \u001b[0mcoocc_ar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorp_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     initial_embedding_dict= pre_glove)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Mittens' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xDBDn64S58U5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "42b31e46-b42e-42d8-b6a1-bc1bdee9162e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-cf04d4b24823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorp_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"repo_glove.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewglove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'corp_vocab' is not defined"
          ]
        }
      ],
      "source": [
        "newglove = dict(zip(corp_vocab, new_embeddings))\n",
        "f = open(\"repo_glove.pkl\",\"wb\")\n",
        "pickle.dump(newglove, f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-OB9Siga3G"
      },
      "source": [
        "* (ì°¸ê³ ) word2vec pretrained example\n",
        "\n",
        "â• [word2vec ì‚¬ì „í•™ìŠµ ëª¨ë¸ -í•œêµ­ì–´1](http://doc.mindscale.kr/km/unstructured/11.html)\n",
        "\n",
        "â• [word2vec ì‚¬ì „í•™ìŠµ - í•œêµ­ì–´2](https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/#%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec-%EB%A7%8C%EB%93%A4%EA%B8%B0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUWWDwdiPLS9"
      },
      "source": [
        "### **2ï¸âƒ£ NER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N0B4VknPkTk"
      },
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n",
        "* ê°œì²´ëª… ì¸ì‹ì„ ì‚¬ìš©í•˜ë©´ ì½”í¼ìŠ¤ë¡œë¶€í„° ì–´ë–¤ ë‹¨ì–´ê°€ ì‚¬ëŒ, ì¥ì†Œ, ì¡°ì§ ë“±ì„ ì˜ë¯¸í•˜ëŠ” ë‹¨ì–´ì¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWgla1BuPRqJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "ğŸ”¹ **2-(1)** NER task by nltk library\n",
        "\n",
        "\n",
        "* nltk ì—ì„œëŠ” ê°œì²´ëª… ì¸ì‹ê¸° (NER chunker) ë¥¼ ì§€ì›í•˜ê³  ìˆë‹¤. \n",
        "* ne_chunk ëŠ” ê°œì²´ëª…ì„ íƒœê¹…í•˜ê¸° ìœ„í•´ì„œ ì•ì„œ í’ˆì‚¬ íƒœê¹… pos_tag ê°€ ìˆ˜í–‰ë˜ì–´ì•¼ í•œë‹¤. \n",
        "\n",
        "\n",
        "ğŸ“Œ [basic code](https://wikidocs.net/30682) ğŸ‘‰ í•„ìˆ˜ \n",
        "\n",
        "ğŸ“Œ [BIO í‘œí˜„, LSTMì„ í™œìš©í•œ NER ì‹¤ìŠµ](https://wikidocs.net/24682) ğŸ‘‰ ì„ íƒ\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "diaZweMyAxJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5271c9d7-585e-4918-ad2a-e63081feb75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"James is working at Disney in London\"\n",
        "\n",
        "tokenized_sentence = pos_tag(word_tokenize(sentence))\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1k09tKha3Lgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac2157b-0eac-4795-cfd4-22ecbc540ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ],
      "source": [
        "ner_sentence = ne_chunk(tokenized_sentence)\n",
        "print(ner_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX-WtSvPmm6"
      },
      "source": [
        "ğŸ”¹ **2-(2)** NER task by spacy library\n",
        "\n",
        "\n",
        "* spaCy ëŠ” ìì—°ì–´ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ ê¸°ë°˜ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. \n",
        "  * Tokenization \n",
        "  * POS tagging \n",
        "  * Lemmatization \n",
        "  * Sentence Boundary Detection (SBD)\n",
        "  * Named Entity Recognition (NER)\n",
        "  * Similarity\n",
        "  * Text Classification\n",
        "  * Rule-based Matching\n",
        "  * Training\n",
        "  * Serialization\n",
        "\n",
        "* spaCy ì™€ NER\n",
        "  * .ents â†’ .label_\n",
        "\n",
        "\n",
        "ğŸ“Œ [basic code](https://frhyme.github.io/python-lib/nlp_spacy_1/) ğŸ‘‰ í•„ìˆ˜ (NER ë¶€ë¶„ë§Œ)\n",
        "\n",
        "ğŸ“Œ [kaggle_Custom NER using SpaCy](https://www.kaggle.com/code/amarsharma768/custom-ner-using-spacy/notebook) ğŸ‘‰ ì„ íƒ\n",
        "\n",
        "  * í›ˆë ¨ë˜ì§€ ì•Šì€ ë°ì´í„° ì„¸íŠ¸ì— ëª…ëª…ëœ ì—”í‹°í‹°ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²• : ì´ë ¥ì„œ pdf ë°ì´í„° í™œìš© \n",
        "  * manually labelled \n",
        "\n",
        "ğŸ“Œ [í•œêµ­ì–´ NER](https://github.com/monologg/KoBERT-NER) ğŸ‘‰ ì°¸ê³ í•˜ë©´ ì¢‹ì„ ìë£Œ\n",
        "\n",
        "â• [ì°¸ê³ ](http://aispiration.com/nlp2/nlp-ner-python.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python -m spacy download en_core_web_md\n",
        "python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "RNhqXgI4qfmY",
        "outputId": "487d20a2-5574-4d22-8504-05958d0c4d39"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-7aad6ab4aea4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -m spacy download en_core_web_md\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "WXjRfz-qP0Xx",
        "outputId": "4861d64d-5a04-4d9a-cd63-cc65f28bf32e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-bd7ce8546402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_md'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# make sure to use larger model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'dog cat banana'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')  \n",
        "tokens = nlp(u'dog cat banana')\n",
        "\n",
        "for token1 in tokens:\n",
        "    for token2 in tokens:\n",
        "        print(token1.text, token2.text, token1.similarity(token2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')  \n",
        "tokens = nlp(u'dog cat banana')\n",
        "\n",
        "for token1 in tokens:\n",
        "    for token2 in tokens:\n",
        "        sim = cosine_similarity(token1.vector.reshape(1, 300), \n",
        "                          token2.vector.reshape(1, 300)\n",
        "                         )\n",
        "        print(token1.text, token2.text, sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "af_E5fuJqaKb",
        "outputId": "6ccf421f-9e51-45db-9e1a-2a197fb76a84"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2d8cf08c6d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_md'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# make sure to use larger model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'dog cat banana'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008-V5QsQG25"
      },
      "source": [
        "###**3ï¸âƒ£ Dependency Parsing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfcodHQQPlt"
      },
      "source": [
        "ğŸ‘€ **ë‚´ìš© ë³µìŠµ** \n",
        "* ë¬¸ì¥ì˜ ì „ì²´ì ì¸ êµ¬ì„±/êµ¬ì¡° ë³´ë‹¤ëŠ” ê° ê°œë³„ë‹¨ì–´ ê°„ì˜ 'ì˜ì¡´ê´€ê³„' ë˜ëŠ” 'ìˆ˜ì‹ê´€ê³„' ì™€ ê°™ì€ ë‹¨ì–´ê°„ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì´ ëª©ì ì¸ NLP Task\n",
        "* ë¬¸ì¥ í•´ì„ì˜ ëª¨í˜¸ì„±ì„ ì—†ì• ê¸° ìœ„í•´ Parsing ì„ í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJLAzZnbRNlL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "ğŸ”¹ **3-(1)** Dependency Parsing by spacy library\n",
        "\n",
        "\n",
        "* [basic](https://frhyme.github.io/python-lib/nlp_spacy_1/#navigating-parse-tree) ğŸ‘‰ dependecy parsing ë¶€ë¶„ë§Œ í•„ìˆ˜\n",
        "* .dep_ ë©”ì„œë“œ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U pip setuptools wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "GtDNTzthsPzV",
        "outputId": "779a3ef2-3bb1-43b7-92a8-22361a140542"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.4.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "numba 0.56.2 requires setuptools<60, but you have setuptools 65.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-22.2.2 setuptools-65.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HbQEYt76bJXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "5a3ef63e-920e-4bbd-af3b-a6183255af3d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bd9106339298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjupyter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
          ]
        }
      ],
      "source": [
        "one_sentence = tweets['text'][300]\n",
        "doc = nlp(one_sentence)\n",
        "spacy.displacy.render(doc, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W9QAEsrLAxHP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "103bd236-0610-4e51-9eb3-d888b9c7d733"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed5907cd642e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrump_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"PERCENT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CARDINAL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DATE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mtrump_topics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"
          ]
        }
      ],
      "source": [
        "trump_topics = []\n",
        "for ent in doc.ents:\n",
        "  if ent.label_ not in [\"PERCENT\", \"CARDINAL\", \"DATE\"]:\n",
        "      trump_topics.append(ent.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQD5oiGgRfHe"
      },
      "source": [
        "ğŸ”¹ **3-(2)** Spacy (kaggle) \n",
        "\n",
        "* ìºê¸€ ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ì‹¤ìŠµí•´ë³´ëŠ” ê²ƒì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤!\n",
        "\n",
        "* [kaggle_spaCy](https://www.kaggle.com/code/nirant/hitchhiker-s-guide-to-nlp-in-spacy) ğŸ‘‰ í•„ìˆ˜\n",
        "  * ë„ë‚ ë“œ íŠ¸ëŸ¼í”„ íŠ¸ìœ„í„° íŠ¸ìœ— ë‚´ìš© ë°ì´í„° ë¶„ì„\n",
        "\n",
        "\n",
        "ğŸ‘€ **ë…¸íŠ¸ë¶ í‚¤í¬ì¸íŠ¸** \n",
        "  1. spacy.display ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œ NER ì‹œê°í™” \n",
        "  2. Tagging ì„ í†µí•œ íŠ¸ëŸ¼í”„ íŠ¸ìœ— ë¶„ì„ : noun_chunks ëŠ” dependency graphë¥¼ ê³ ë ¤í•˜ì—¬, noun phraseë¥¼ ë½‘ì•„ì¤€ë‹¤. \n",
        "  3. [spacy Match](https://yujuwon.tistory.com/entry/spaCy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-Rule-based-Matching) : ì§ì ‘ ë¬¸ì¥/ë‹¨ì–´ íŒ¨í„´ì„ ë“±ë¡í•˜ì—¬ parsing\n",
        "  4. Question and answering task using Dependency Parsing\n",
        "    * spacy display :  ``style = 'dep'``\n",
        "    * .dep_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LuHGKITRbKYq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "outputId": "1382cc01-08ea-4893-bf21-7ebb35abb10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-10 11:44:10.005812: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (65.4.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4249206b45fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python -m spacy download en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kZLkmD_-ypWd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uMArOUrxAJ8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "efd0f5f3-a5ff-4182-94b0-bd4e5aba090b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a7de15603c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/all-djtrum-tweets/all_djt_tweets.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/all-djtrum-tweets/all_djt_tweets.csv'"
          ]
        }
      ],
      "source": [
        "tweets = pd.read_csv(\"../input/all-djtrum-tweets/all_djt_tweets.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_text_entities(text):\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')\n",
        "\n",
        "explain_text_entities(tweets['text'][9])\n",
        "\n",
        "one_sentence = tweets['text'][0]\n",
        "doc = nlp(one_sentence)\n",
        "spacy.displacy.render(doc, style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "dsxhaBLktkvZ",
        "outputId": "c8378afd-4f2f-4233-b885-e53e73357c45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7c006202f2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexplain_text_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mone_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}