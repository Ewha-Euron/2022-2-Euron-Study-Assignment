{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\ucef4\ud4e8\ud130 \ube44\uc804(Vision)\uc744 \uc704\ud55c \uc804\uc774\ud559\uc2b5(Transfer Learning)\n=======================================================\n**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n  **\ubc88\uc5ed**: `\ubc15\uc815\ud658 <http://github.com/9bow>`_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \uc804\uc774\ud559\uc2b5(Transfer Learning)\uc744 \uc774\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \ubd84\ub958\ub97c \uc704\ud55c\n\ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\uc744 \uc5b4\ub5bb\uac8c \ud559\uc2b5\uc2dc\ud0a4\ub294\uc9c0 \ubc30\uc6cc\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc804\uc774\ud559\uc2b5\uc5d0 \ub300\ud574\uc11c\ub294\n`CS231n \ub178\ud2b8 <http://cs231n.github.io/transfer-learning/>`__ \uc5d0\uc11c \ub354 \ub9ce\uc740 \ub0b4\uc6a9\uc744\n\uc77d\uc5b4\ubcf4\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc704 \ub178\ud2b8\ub97c \uc778\uc6a9\ud574\ubcf4\uba74,\n\n    \uc2e4\uc81c\ub85c \ucda9\ubd84\ud55c \ud06c\uae30\uc758 \ub370\uc774\ud130\uc14b\uc744 \uac16\ucd94\uae30\ub294 \uc0c1\ub300\uc801\uc73c\ub85c \ub4dc\ubb3c\uae30 \ub54c\ubb38\uc5d0,\n    (\ubb34\uc791\uc704 \ucd08\uae30\ud654\ub97c \ud1b5\ud574) \ub9e8 \ucc98\uc74c\ubd80\ud130 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd(Convolutional\n    Network) \uc804\uccb4\ub97c \ud559\uc2b5\ud558\ub294 \uc0ac\ub78c\uc740 \ub9e4\uc6b0 \uc801\uc2b5\ub2c8\ub2e4. \ub300\uc2e0, \ub9e4\uc6b0 \ud070 \ub370\uc774\ud130\uc14b(\uc608.\n    100\uac00\uc9c0 \ubd84\ub958\uc5d0 \ub300\ud574 120\ub9cc\uac1c\uc758 \uc774\ubbf8\uc9c0\uac00 \ud3ec\ud568\ub41c ImageNet)\uc5d0\uc11c \ud569\uc131\uacf1\n    \uc2e0\uacbd\ub9dd(ConvNet)\uc744 \ubbf8\ub9ac \ud559\uc2b5\ud55c \ud6c4, \uc774 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\uc744 \uad00\uc2ec\uc788\ub294 \uc791\uc5c5\n    \uc744 \uc704\ud55c \ucd08\uae30 \uc124\uc815 \ub610\ub294 \uace0\uc815\ub41c \ud2b9\uc9d5 \ucd94\ucd9c\uae30(fixed feature extractor)\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\uc774\ub7ec\ud55c \uc804\uc774\ud559\uc2b5 \uc2dc\ub098\ub9ac\uc624\uc758 \uc8fc\uc694\ud55c 2\uac00\uc9c0\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n-  **\ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\uc758 \ubbf8\uc138\uc870\uc815(finetuning)**: \ubb34\uc791\uc704 \ucd08\uae30\ud654 \ub300\uc2e0, \uc2e0\uacbd\ub9dd\uc744\n   ImageNet 1000 \ub370\uc774\ud130\uc14b \ub4f1\uc73c\ub85c \ubbf8\ub9ac \ud559\uc2b5\ud55c \uc2e0\uacbd\ub9dd\uc73c\ub85c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4. \ud559\uc2b5\uc758 \ub098\uba38\uc9c0\n   \uacfc\uc815\ub4e4\uc740 \ud3c9\uc0c1\uc2dc\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n-  **\uace0\uc815\ub41c \ud2b9\uc9d5 \ucd94\ucd9c\uae30\ub85c\uc368\uc758 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd**: \uc5ec\uae30\uc11c\ub294 \ub9c8\uc9c0\ub9c9\uc5d0 \uc644\uc804\ud788 \uc5f0\uacb0\n   \ub41c \uacc4\uce35\uc744 \uc81c\uc678\ud55c \ubaa8\ub4e0 \uc2e0\uacbd\ub9dd\uc758 \uac00\uc911\uce58\ub97c \uace0\uc815\ud569\ub2c8\ub2e4. \uc774 \ub9c8\uc9c0\ub9c9\uc758 \uc644\uc804\ud788 \uc5f0\uacb0\ub41c\n   \uacc4\uce35\uc740 \uc0c8\ub85c\uc6b4 \ubb34\uc791\uc704\uc758 \uac00\uc911\uce58\ub97c \uac16\ub294 \uacc4\uce35\uc73c\ub85c \ub300\uccb4\ub418\uc5b4 \uc774 \uacc4\uce35\ub9cc \ud559\uc2b5\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\ncudnn.benchmark = True\nplt.ion()   # \ub300\ud654\ud615 \ubaa8\ub4dc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n---------------\n\n\ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc624\uae30 \uc704\ud574 torchvision\uacfc torch.utils.data \ud328\ud0a4\uc9c0\ub97c \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc5ec\uae30\uc11c \ud480\uace0\uc790 \ud558\ub294 \ubb38\uc81c\ub294 **\uac1c\ubbf8** \uc640 **\ubc8c** \uc744 \ubd84\ub958\ud558\ub294 \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uac1c\ubbf8\uc640 \ubc8c \uac01\uac01\uc758 \ud559\uc2b5\uc6a9 \uc774\ubbf8\uc9c0\ub294 \ub300\ub7b5 120\uc7a5 \uc815\ub3c4 \uc788\uace0, 75\uac1c\uc758 \uac80\uc99d\uc6a9 \uc774\ubbf8\uc9c0\uac00\n\uc788\uc2b5\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \ub9e8 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\uc744 \ud55c\ub2e4\uba74 \uc774\ub294 \uc77c\ubc18\ud654\ud558\uae30\uc5d0\ub294 \uc544\uc8fc \uc791\uc740\n\ub370\uc774\ud130\uc14b\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc6b0\ub9ac\ub294 \uc804\uc774\ud559\uc2b5\uc744 \ud560 \uac83\uc774\ubbc0\ub85c, \uc77c\ubc18\ud654\ub97c \uc81c\ubc95 \uc798 \ud560 \uc218 \uc788\uc744\n\uac83\uc785\ub2c8\ub2e4.\n\n\uc774 \ub370\uc774\ud130\uc14b\uc740 ImageNet\uc758 \uc544\uc8fc \uc791\uc740 \uc77c\ubd80\uc785\ub2c8\ub2e4.\n\n.. Note ::\n   \ub370\uc774\ud130\ub97c `\uc5ec\uae30 <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_\n   \uc5d0\uc11c \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uc544 \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud559\uc2b5\uc744 \uc704\ud574 \ub370\uc774\ud130 \uc99d\uac00(augmentation) \ubc0f \uc77c\ubc18\ud654(normalization)\n# \uac80\uc99d\uc744 \uc704\ud55c \uc77c\ubc18\ud654\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data/hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc77c\ubd80 \uc774\ubbf8\uc9c0 \uc2dc\uac01\ud654\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\ub370\uc774\ud130 \uc99d\uac00\ub97c \uc774\ud574\ud558\uae30 \uc704\ud574 \uc77c\ubd80 \ud559\uc2b5\uc6a9 \uc774\ubbf8\uc9c0\ub97c \uc2dc\uac01\ud654\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # \uac31\uc2e0\uc774 \ub420 \ub54c\uae4c\uc9c0 \uc7a0\uc2dc \uae30\ub2e4\ub9bd\ub2c8\ub2e4.\n\n\n# \ud559\uc2b5 \ub370\uc774\ud130\uc758 \ubc30\uce58\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\ninputs, classes = next(iter(dataloaders['train']))\n\n# \ubc30\uce58\ub85c\ubd80\ud130 \uaca9\uc790 \ud615\ud0dc\uc758 \uc774\ubbf8\uc9c0\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \ud559\uc2b5\ud558\uae30\n--------------\n\n\uc774\uc81c \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\uae30 \uc704\ud55c \uc77c\ubc18 \ud568\uc218\ub97c \uc791\uc131\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \ub2e4\uc74c \ub0b4\uc6a9\ub4e4\uc744\n\uc124\uba85\ud569\ub2c8\ub2e4:\n\n-  \ud559\uc2b5\ub960(learning rate) \uad00\ub9ac(scheduling)\n-  \ucd5c\uc801\uc758 \ubaa8\ub378 \uad6c\ud558\uae30\n\n\uc544\ub798\uc5d0\uc11c ``scheduler`` \ub9e4\uac1c\ubcc0\uc218\ub294 ``torch.optim.lr_scheduler`` \uc758 LR \uc2a4\ucf00\uc974\ub7ec\n\uac1d\uccb4(Object)\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # \uac01 \uc5d0\ud3ed(epoch)\uc740 \ud559\uc2b5 \ub2e8\uacc4\uc640 \uac80\uc99d \ub2e8\uacc4\ub97c \uac16\uc2b5\ub2c8\ub2e4.\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # \ubaa8\ub378\uc744 \ud559\uc2b5 \ubaa8\ub4dc\ub85c \uc124\uc815\n            else:\n                model.eval()   # \ubaa8\ub378\uc744 \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # \ub370\uc774\ud130\ub97c \ubc18\ubcf5\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # \ub9e4\uac1c\ubcc0\uc218 \uacbd\uc0ac\ub3c4\ub97c 0\uc73c\ub85c \uc124\uc815\n                optimizer.zero_grad()\n\n                # \uc21c\uc804\ud30c\n                # \ud559\uc2b5 \uc2dc\uc5d0\ub9cc \uc5f0\uc0b0 \uae30\ub85d\uc744 \ucd94\uc801\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # \ud559\uc2b5 \ub2e8\uacc4\uc778 \uacbd\uc6b0 \uc5ed\uc804\ud30c + \ucd5c\uc801\ud654\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # \ud1b5\uacc4\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # \ubaa8\ub378\uc744 \uae4a\uc740 \ubcf5\uc0ac(deep copy)\ud568\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # \uac00\uc7a5 \ub098\uc740 \ubaa8\ub378 \uac00\uc911\uce58\ub97c \ubd88\ub7ec\uc634\n    model.load_state_dict(best_model_wts)\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc608\uce21\uac12 \uc2dc\uac01\ud654\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^\n\n\uc77c\ubd80 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc608\uce21\uac12\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc77c\ubc18\ud654\ub41c \ud568\uc218\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd \ubbf8\uc138\uc870\uc815(finetuning)\n----------------------------------\n\n\ubbf8\ub9ac \ud559\uc2b5\ud55c \ubaa8\ub378\uc744 \ubd88\ub7ec\uc628 \ud6c4 \ub9c8\uc9c0\ub9c9\uc758 \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \uacc4\uce35\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n# \uc5ec\uae30\uc11c \uac01 \ucd9c\ub825 \uc0d8\ud50c\uc758 \ud06c\uae30\ub294 2\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n# \ub610\ub294, nn.Linear(num_ftrs, len (class_names))\ub85c \uc77c\ubc18\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc774 \ucd5c\uc801\ud654\ub418\uc5c8\ub294\uc9c0 \uad00\ucc30\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# 7 \uc5d0\ud3ed\ub9c8\ub2e4 0.1\uc529 \ud559\uc2b5\ub960 \uac10\uc18c\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ubc0f \ud3c9\uac00\ud558\uae30\n^^^^^^^^^^^^^^^^^^\n\nCPU\uc5d0\uc11c\ub294 15-25\ubd84 \uac00\ub7c9, GPU\uc5d0\uc11c\ub294 1\ubd84\ub3c4 \uc774\ub0b4\uc758 \uc2dc\uac04\uc774 \uac78\ub9bd\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uace0\uc815\ub41c \ud2b9\uc9d5 \ucd94\ucd9c\uae30\ub85c\uc368\uc758 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\n---------------------------------------\n\n\uc774\uc81c, \ub9c8\uc9c0\ub9c9 \uacc4\uce35\uc744 \uc81c\uc678\ud55c \uc2e0\uacbd\ub9dd\uc758 \ubaa8\ub4e0 \ubd80\ubd84\uc744 \uace0\uc815\ud574\uc57c \ud569\ub2c8\ub2e4.\n``requires_grad = False`` \ub85c \uc124\uc815\ud558\uc5ec \ub9e4\uac1c\ubcc0\uc218\ub97c \uace0\uc815\ud558\uc5ec ``backward()`` \uc911\uc5d0\n\uacbd\uc0ac\ub3c4\uac00 \uacc4\uc0b0\ub418\uc9c0 \uc54a\ub3c4\ub85d \ud574\uc57c\ud569\ub2c8\ub2e4.\n\n\uc774\uc5d0 \ub300\ud55c \ubb38\uc11c\ub294\n`\uc5ec\uae30 <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__\n\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# \uc0c8\ub85c \uc0dd\uc131\ub41c \ubaa8\ub4c8\uc758 \ub9e4\uac1c\ubcc0\uc218\ub294 \uae30\ubcf8\uac12\uc774 requires_grad=True \uc784\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# \uc774\uc804\uacfc\ub294 \ub2e4\ub974\uac8c \ub9c8\uc9c0\ub9c9 \uacc4\uce35\uc758 \ub9e4\uac1c\ubcc0\uc218\ub4e4\ub9cc \ucd5c\uc801\ud654\ub418\ub294\uc9c0 \uad00\ucc30\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# 7 \uc5d0\ud3ed\ub9c8\ub2e4 0.1\uc529 \ud559\uc2b5\ub960 \uac10\uc18c\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ubc0f \ud3c9\uac00\ud558\uae30\n^^^^^^^^^^^^^^^^^\n\nCPU\uc5d0\uc11c \uc2e4\ud589\ud558\ub294 \uacbd\uc6b0 \uc774\uc804\uacfc \ube44\uad50\ud588\uc744 \ub54c \uc57d \uc808\ubc18 \uac00\ub7c9\uc758 \uc2dc\uac04\ub9cc\uc774 \uc18c\uc694\ub420 \uac83\uc785\ub2c8\ub2e4.\n\uc774\ub294 \ub300\ubd80\ubd84\uc758 \uc2e0\uacbd\ub9dd\uc5d0\uc11c \uacbd\uc0ac\ub3c4\ub97c \uacc4\uc0b0\ud560 \ud544\uc694\uac00 \uc5c6\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc,\n\uc21c\uc804\ud30c\ub294 \uacc4\uc0b0\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_conv)\n\nplt.ioff()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub354 \ubc30\uc6cc\ubcfc \ub0b4\uc6a9\n-----------------\n\n\uc804\uc774\ud559\uc2b5\uc758 \uc751\uc6a9 \uc0ac\ub840(application)\ub4e4\uc744 \ub354 \uc54c\uc544\ubcf4\ub824\uba74,\n:doc:`/intermediate/quantized_transfer_learning_tutorial` \uc744 \ucc38\uc870\ud574\ubcf4\uc138\uc694.\n\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}