{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKMqoXNh4T8Z73Ka1iPHI1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyunyeo/2022-2-Euron-Study-Assignment/blob/week13/Week13_%EB%B3%B5%EC%8A%B5%EA%B3%BC%EC%A0%9C_%EC%97%AC%EC%B1%84%EC%9C%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis(NLP)\n"
      ],
      "metadata": {
        "id": "db1ooRvnzcia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrs7Q-LOzJDt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import re\n",
        "import string\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer \n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from textblob import TextBlob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\", index_col=0)\n",
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "YU8AKKoOzbOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['Rating', 'Recommended IND'])['Recommended IND'].count()\n"
      ],
      "metadata": {
        "id": "bd2yBb7OzbMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df.Rating==5) & (df['Recommended IND']==0)]['Review Text'].iloc[1]"
      ],
      "metadata": {
        "id": "FerSsu9lzbJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = df[['Title', 'Review Text', 'Recommended IND']]\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "LS78Uk3ozbHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Review'] = text_df['Title'] + ' ' + text_df['Review Text']\n",
        "text_df = text_df.drop(labels=['Title','Review Text'] , axis=1)\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "vSocfNuZzbEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.Review.isna().sum()"
      ],
      "metadata": {
        "id": "p2SzolYKzbCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = text_df[~text_df.Review.isna()]\n",
        "text_df = text_df.rename(columns={\"Recommended IND\": \"Recommended\"})\n",
        "print(\"My data's shape is:\", text_df.shape)\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "ag4dH5H2za_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Recommended'].unique()"
      ],
      "metadata": {
        "id": "YBqJ9wjUza9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Recommended'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "QjWYIHV9za6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Review_length'] = text_df['Review'].apply(len)\n",
        "print(text_df.shape)\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "UeJD3vd1za4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Review_length'].describe()"
      ],
      "metadata": {
        "id": "pLvKvjUZzazu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(11,5)})\n",
        "sns.distplot(text_df['Review_length'] ,hist=True, bins=100)"
      ],
      "metadata": {
        "id": "Nk-iqTlezaxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_zero = text_df[text_df['Recommended']==0]\n",
        "df_one = text_df[text_df['Recommended']==1]\n",
        "sns.distplot(df_zero[['Review_length']] ,hist=False)\n",
        "sns.distplot(df_one[['Review_length']], hist=False)"
      ],
      "metadata": {
        "id": "JftDbDKJzpOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_exclamation_mark(string_text):\n",
        "    count = 0\n",
        "    for char in string_text:\n",
        "        if char == '!':\n",
        "            count += 1\n",
        "    return count\n",
        "text_df['count_exc'] = text_df['Review'].apply(count_exclamation_mark)\n",
        "text_df.head(5)"
      ],
      "metadata": {
        "id": "BRYUVmK3zpME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['count_exc'].describe(np.arange(0.2, 1.0, 0.2))\n"
      ],
      "metadata": {
        "id": "YAMd6uMQzpJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['count_exc'].value_counts().sort_index().plot(kind='bar')"
      ],
      "metadata": {
        "id": "NMlnvqcYzpGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df[text_df['count_exc']== 41].index"
      ],
      "metadata": {
        "id": "-6JfBnE3zpEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Review'][3301]\n"
      ],
      "metadata": {
        "id": "dYKOAO6rzpBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Polarity'] = text_df['Review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "text_df.head(5)"
      ],
      "metadata": {
        "id": "a-yq1u4Qzo_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['Polarity'].plot(kind='hist', bins=100)\n"
      ],
      "metadata": {
        "id": "Ejx40CP-zo8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_prep = text_df.copy()\n"
      ],
      "metadata": {
        "id": "Q2frLaYMzzLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "id": "RWxknJSAzzJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def punctuation_removal(messy_str):\n",
        "    clean_list = [char for char in messy_str if char not in string.punctuation]\n",
        "    clean_str = ''.join(clean_list)\n",
        "    return clean_str\n",
        "text_prep['Review'] = text_prep['Review'].apply(punctuation_removal)\n",
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "Izt7Cxn2zzG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url= \"http://josecarilloforum.com/imgs/longnounphrase_schematic-1B.png\", width=600, height=10)"
      ],
      "metadata": {
        "id": "iF99hYCXzzEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adj_collector(review_string):\n",
        "    new_string=[]\n",
        "    review_string = word_tokenize(review_string)\n",
        "    tup_word = nltk.pos_tag(review_string)\n",
        "    for tup in tup_word:\n",
        "        if 'VB' in tup[1] or tup[1]=='JJ':  #Verbs and Adjectives\n",
        "            new_string.append(tup[0])  \n",
        "    return ' '.join(new_string)\n",
        "text_prep['Review'] = text_prep['Review'].apply(adj_collector)\n",
        "text_prep['Review'].head(7)"
      ],
      "metadata": {
        "id": "UE1KhmNWzzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words('english')[::12])"
      ],
      "metadata": {
        "id": "D9fmqMHyzy_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop = stopwords.words('english')\n",
        "stop.append(\"i'm\")"
      ],
      "metadata": {
        "id": "ICmowsnxzy9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = []\n",
        "\n",
        "for item in stop: \n",
        "    new_item = punctuation_removal(item)\n",
        "    stop_words.append(new_item) \n",
        "print(stop_words[::12])"
      ],
      "metadata": {
        "id": "00Wj7lbKzy6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clothes_list =['dress', 'top','sweater','shirt',\n",
        "               'skirt','material', 'white', 'black',\n",
        "              'jeans', 'fabric', 'color','order', 'wear']\n",
        "def stopwords_removal(messy_str):\n",
        "    messy_str = word_tokenize(messy_str)\n",
        "    return [word.lower() for word in messy_str \n",
        "            if word.lower() not in stop_words and word.lower() not in clothes_list ]\n",
        "text_prep['Review'] = text_prep['Review'].apply(stopwords_removal)\n",
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "yVSj2qEGzy3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_prep['Review'][3301])\n"
      ],
      "metadata": {
        "id": "Y3e2R6xaz82u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_prep['Review'][267]) \n"
      ],
      "metadata": {
        "id": "gGGlYHtBz80g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_numbers(list_text):\n",
        "    list_text_new = []\n",
        "    for i in list_text:\n",
        "        if not re.search('\\d', i):\n",
        "            list_text_new.append(i)\n",
        "    return ' '.join(list_text_new)\n",
        "text_prep['Review'] = text_prep['Review'].apply(drop_numbers)\n",
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "jNEqWhUfz8yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_prep['Review'][267]) "
      ],
      "metadata": {
        "id": "dleMyf9jz8YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_prep['Review'][2293])"
      ],
      "metadata": {
        "id": "0OI_YLJLz8Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "text_prep['Review'] = text_prep['Review'].apply(lambda x: x.split())\n",
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "IVwpv5eEz8TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_update(text_list):\n",
        "    text_list_new = []\n",
        "    for word in text_list:\n",
        "        word = porter.stem(word)\n",
        "        text_list_new.append(word) \n",
        "    return text_list_new\n",
        "text_prep['Review'] = text_prep['Review'].apply(stem_update)\n",
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "bqQ2HGNrz8Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_prep['Review'] = text_prep['Review'].apply(lambda x: ' '.join(x))\n",
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "XsSZSxYsz8Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_prep['Review'][2293])"
      ],
      "metadata": {
        "id": "hl2OfDAX0E7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_df = text_prep[text_prep.Recommended== 1]\n",
        "neg_df = text_prep[text_prep.Recommended== 0]\n",
        "pos_df.head(3)"
      ],
      "metadata": {
        "id": "i-G33EQ20E42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_words =[]\n",
        "neg_words = []\n",
        "\n",
        "for review in pos_df.Review:\n",
        "    pos_words.append(review) \n",
        "pos_words = ' '.join(pos_words)\n",
        "pos_words[:40]\n",
        "\n",
        "for review in neg_df.Review:\n",
        "    neg_words.append(review)\n",
        "neg_words = ' '.join(neg_words)\n",
        "neg_words[:400]"
      ],
      "metadata": {
        "id": "X8OGylHT0E2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud = WordCloud().generate(pos_words)\n",
        "\n",
        "wordcloud = WordCloud(background_color=\"white\",max_words=len(pos_words),\\\n",
        "                      max_font_size=40, relative_scaling=.5, colormap='summer').generate(pos_words)\n",
        "plt.figure(figsize=(13,13))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pYzeLyul0E0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud = WordCloud().generate(neg_words)\n",
        "\n",
        "wordcloud = WordCloud(background_color=\"white\",max_words=len(neg_words),\\\n",
        "                      max_font_size=40, relative_scaling=.5, colormap='gist_heat').generate(neg_words)\n",
        "plt.figure(figsize=(13,13))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wEAq3tye0Exf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_prep['Review'].head()"
      ],
      "metadata": {
        "id": "A8EaxvGP0EvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_vectorizing_process(sentence_string):\n",
        "    return [word for word in sentence_string.split()]\n",
        "bow_transformer = CountVectorizer(text_vectorizing_process)\n",
        "bow_transformer.fit(text_prep['Review'])"
      ],
      "metadata": {
        "id": "ZmI1WCKf0Esv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_prep['Review'].iloc[3])"
      ],
      "metadata": {
        "id": "K8KNJjsx0En-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = bow_transformer.transform([text_prep['Review'].iloc[3]])\n",
        "print(example)"
      ],
      "metadata": {
        "id": "wlDrQHT60ElO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Reviews = bow_transformer.transform(text_prep['Review'])\n",
        "Reviews"
      ],
      "metadata": {
        "id": "eD5mZXv70OzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Sparse Matrix', Reviews.shape)\n",
        "print('Amount of Non-Zero occurences:', Reviews.nnz)"
      ],
      "metadata": {
        "id": "gYyfnQlM0Own"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer().fit(Reviews)\n",
        "\n",
        "tfidf_example = tfidf_transformer.transform(example)\n",
        "print (tfidf_example)"
      ],
      "metadata": {
        "id": "8Azbq_w90OuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[i for i in bow_transformer.vocabulary_.items() if i[1]==3507]\n"
      ],
      "metadata": {
        "id": "uKcXa6qX0Orw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[i for i in bow_transformer.vocabulary_.items()][6:60:10]"
      ],
      "metadata": {
        "id": "9t2bF7wM0Opf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages_tfidf = tfidf_transformer.transform(Reviews)\n",
        "messages_tfidf.shape"
      ],
      "metadata": {
        "id": "zH_MHqwZ0Om-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(messages_tfidf[:1]) "
      ],
      "metadata": {
        "id": "voSO1W7a0Okx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages_tfidf = messages_tfidf.toarray()\n",
        "messages_tfidf = pd.DataFrame(messages_tfidf)\n",
        "print(messages_tfidf.shape)\n",
        "messages_tfidf.head()"
      ],
      "metadata": {
        "id": "7wJ_NsQO0OiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.merge(text_prep.drop(columns='Review'),messages_tfidf, \n",
        "                  left_index=True, right_index=True )\n",
        "df_all.head()"
      ],
      "metadata": {
        "id": "zSLyy4tZ0Ofe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report(y_true, y_pred, labels):\n",
        "    cm = pd.DataFrame(confusion_matrix(y_true=y_true, y_pred=y_pred), \n",
        "                                        index=labels, columns=labels)\n",
        "    rep = classification_report(y_true=y_true, y_pred=y_pred)\n",
        "    return (f'Confusion Matrix:\\n{cm}\\n\\nClassification Report:\\n{rep}')"
      ],
      "metadata": {
        "id": "uriSIqmo0OdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_model = SVC(C=1.0, \n",
        "             kernel='linear',\n",
        "             class_weight='balanced', \n",
        "             probability=True,\n",
        "             random_state=111)\n",
        "svc_model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "H4QW-pJv0bOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = svc_model.predict(X_test_scaled)\n",
        "print(report(y_test, test_predictions, svc_model.classes_ ))"
      ],
      "metadata": {
        "id": "IX5JcfCn0bLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(class_weight='balanced', \n",
        "                              random_state=111, \n",
        "                              solver='lbfgs',\n",
        "                              C=1.0)\n",
        "\n",
        "gs_lr_model = GridSearchCV(lr_model, \n",
        "                           param_grid={'C': [0.01, 0.1, 0.5, 1.0, 5.0]}, \n",
        "                           cv=5, \n",
        "                           scoring='roc_auc')\n",
        "\n",
        "gs_lr_model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "MC2VDf9e0bJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = gs_lr_model.predict(X_test_scaled)\n",
        "print(report(y_test, test_predictions, gs_lr_model.classes_ ))"
      ],
      "metadata": {
        "id": "SknJmw-I0bHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=555)\n",
        "\n",
        "ada_model = AdaBoostClassifier(base_estimator=dt, learning_rate=0.001, n_estimators=1000, random_state=222)\n",
        "ada_model.fit(X_train ,y_train)"
      ],
      "metadata": {
        "id": "39G71-ts0bEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = ada_model.predict(X_test)\n",
        "print(report(y_test, test_predictions, ada_model.classes_ ))"
      ],
      "metadata": {
        "id": "TIZFEEfO0bCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=1000, max_depth=5, \n",
        "                                  class_weight='balanced', random_state=3)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Sjahn8-q0kEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = rf_model.predict(X_test)\n",
        "print(report(y_test, test_predictions, rf_model.classes_ ))"
      ],
      "metadata": {
        "id": "BrdVorpG0kBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = rf_model.predict_proba(X_train)\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_train, probs[:,1])\n",
        "#Train\n",
        "plt.subplots(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, '-', label=\"ROC curve\")\n",
        "plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\n",
        "for x, y, txt in zip(fpr[::100], tpr[::100], thresholds[::100]):\n",
        "    plt.annotate(np.round(txt,3), (x, y-0.03), fontsize='x-small')\n",
        "rnd_idx = 700\n",
        "plt.annotate('this point refers to the tpr and the fpr\\n at a probability threshold of {}'\\\n",
        "             .format(np.round(thresholds[rnd_idx], 4)), \n",
        "             xy=(fpr[rnd_idx], tpr[rnd_idx]), xytext=(fpr[rnd_idx]+0.2, tpr[rnd_idx]-0.25),\n",
        "             arrowprops=dict(facecolor='black', lw=2, arrowstyle='->',color='r'),)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")"
      ],
      "metadata": {
        "id": "sKRYR6QM0j_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = rf_model.predict_proba(X_test)\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:,1])\n",
        "#Test\n",
        "plt.subplots(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, '-', label=\"ROC curve\")\n",
        "plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\n",
        "for x, y, txt in zip(fpr[::70], tpr[::70], thresholds[::70]):\n",
        "    plt.annotate(np.round(txt,4), (x, y-0.01))\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")"
      ],
      "metadata": {
        "id": "dzC7L_s00j8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FObGdX6y0j6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}