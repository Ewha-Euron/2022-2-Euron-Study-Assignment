{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc13db1debca4a688fe45181f942c6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8049cdecd9c740acae12d7c3cbc8aade",
              "IPY_MODEL_d8c77966a65c4b9fb8bd0d8d7c42eb56",
              "IPY_MODEL_179ca67859414661b4ca2bde0939040e"
            ],
            "layout": "IPY_MODEL_18c83471236a46a9a884065c39676639"
          }
        },
        "8049cdecd9c740acae12d7c3cbc8aade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4835e10ee81748beb7a3456ff735770b",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac9d33280184bcbac6f991c0bd5564e",
            "value": "Dl Completed...: 100%"
          }
        },
        "d8c77966a65c4b9fb8bd0d8d7c42eb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d03fe20257447cf9773ba50cb27e8fd",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea0315a7220c4296a79c044765dea5be",
            "value": 5
          }
        },
        "179ca67859414661b4ca2bde0939040e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e905bd4ed545678822f178b7fd5627",
            "placeholder": "​",
            "style": "IPY_MODEL_7315d58ab3b64e49b3b7b67bba982ca8",
            "value": " 5/5 [00:00&lt;00:00, 15.85 file/s]"
          }
        },
        "18c83471236a46a9a884065c39676639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4835e10ee81748beb7a3456ff735770b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac9d33280184bcbac6f991c0bd5564e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d03fe20257447cf9773ba50cb27e8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea0315a7220c4296a79c044765dea5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32e905bd4ed545678822f178b7fd5627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7315d58ab3b64e49b3b7b67bba982ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**T5모델 사용 실습**"
      ],
      "metadata": {
        "id": "1nkuaDTBAR64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Construct a tf.data.Dataset\n",
        "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
        "\n",
        "# Build your input pipeline\n",
        "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "for example in ds.take(1):\n",
        "  image, label = example[\"image\"], example[\"label\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "fc13db1debca4a688fe45181f942c6e1",
            "8049cdecd9c740acae12d7c3cbc8aade",
            "d8c77966a65c4b9fb8bd0d8d7c42eb56",
            "179ca67859414661b4ca2bde0939040e",
            "18c83471236a46a9a884065c39676639",
            "4835e10ee81748beb7a3456ff735770b",
            "6ac9d33280184bcbac6f991c0bd5564e",
            "9d03fe20257447cf9773ba50cb27e8fd",
            "ea0315a7220c4296a79c044765dea5be",
            "32e905bd4ed545678822f178b7fd5627",
            "7315d58ab3b64e49b3b7b67bba982ca8"
          ]
        },
        "id": "WXd50iFcH7Wq",
        "outputId": "258e0929-7d0c-4d1c-f87e-45458a12013c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ~/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc13db1debca4a688fe45181f942c6e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to ~/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm6xNNXeJQCZ",
        "outputId": "bfb08a4a-d7b8-439a-8250-8828923bc8cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FERpNPc1Ng3d",
        "outputId": "b2ab700a-abc0-4c92-872e-06c92f8494eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 498.0 MB 10 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 62.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 62.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYh-IaN4C7Z1"
      },
      "outputs": [],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "%tensorflow_version 2.x\n",
        "!pip install -q t5\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "import t5.models\n",
        "import seqio\n",
        "\n",
        "# Required to fix Colab flag parsing issue.\n",
        "sys.argv = sys.argv[:1]\n",
        "\n",
        "BASE_DIR = \"gs://\" #@param { type: \"string\" }\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  print(\"Setting up GCS access...\")\n",
        "  # Use legacy GCS authentication method.\n",
        "  os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"v2-8\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.enable_eager_execution()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEysVknTR1e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMoJ-G9mqDqa"
      },
      "source": [
        "# Creating new Tasks and Mixture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwoLPQhE6bef"
      },
      "source": [
        "T5 uses [`seqio`](https://goo.gle/seqio) for managing data pipelines and evaluaton metics.\n",
        "Two core components of the `seqio` are `Task` and `Mixture` objects.\n",
        "\n",
        "A `Task` is a dataset along with preprocessing functions and evaluation metrics. A `Mixture` is a collection of `Task` objects along with a mixing rate or a function defining how to compute a mixing rate based on the properties of the constituent `Tasks`.\n",
        "\n",
        "For this example, we will fine-tune the model to do closed-book question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "152zECujzPMk"
      },
      "source": [
        "### Natural Questions\n",
        "\n",
        "[Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions) is a challenging corpus for open-domain QA. Each example includes a question along with an entire Wikipedia article that may or may not contain its answer. The goal is to produce the correct answer given this context. In our case, we will be ignoring the provided context in hopes that the model will learn to find the answers from the world knowledge it has acquired during pre-training.\n",
        "\n",
        "Since the raw data splits are stored as JSONL files, we will first need to convert them to TSV format to make them parseable in TensorFlow. We will also take the opportunity to drop information we will not be using, remove questions with multiple answers, and to do a bit of cleaning of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 34
        },
        "id": "OjEonhK3zNRu",
        "outputId": "feb1e52f-0b86-4108-89b8-51d516499f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I1206 00:11:00.169766 248738 <ipython-input-3-45e03d923fbf>:51] Loading NQ from cache.\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "# Public directory of Natural Questions data on GCS.\n",
        "NQ_JSONL_DIR = \"gs://natural_questions/v1.0-simplified/\"\n",
        "NQ_SPLIT_FNAMES = {\n",
        "    \"train\": \"simplified-nq-train.jsonl.gz\",\n",
        "    \"validation\": \"nq-dev-all.jsonl.gz\"\n",
        "}\n",
        "nq_counts_path = os.path.join(DATA_DIR, \"nq-counts.json\")\n",
        "nq_tsv_path = {\n",
        "    \"train\": os.path.join(DATA_DIR, \"nq-train.tsv\"),\n",
        "    \"validation\": os.path.join(DATA_DIR, \"nq-validation.tsv\")\n",
        "}\n",
        "\n",
        "def nq_jsonl_to_tsv(in_fname, out_fname):\n",
        "\n",
        "  def extract_answer(tokens, span):\n",
        "    \"\"\"Reconstruct answer from token span and remove extra spaces.\"\"\"\n",
        "    start, end = span[\"start_token\"], span[\"end_token\"]\n",
        "    ans = \" \".join(tokens[start:end])\n",
        "    # Remove incorrect spacing around punctuation.\n",
        "    ans = ans.replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" %\", \"%\")\n",
        "    ans = ans.replace(\" - \", \"-\").replace(\" : \", \":\").replace(\" / \", \"/\")\n",
        "    ans = ans.replace(\"( \", \"(\").replace(\" )\", \")\")\n",
        "    ans = ans.replace(\"`` \", \"\\\"\").replace(\" ''\", \"\\\"\")\n",
        "    ans = ans.replace(\" 's\", \"'s\").replace(\"s ' \", \"s' \")\n",
        "    return ans\n",
        "\n",
        "  count = 0\n",
        "  with tf.io.gfile.GFile(in_fname, \"rb\") as infile,\\\n",
        "       tf.io.gfile.GFile(out_fname, \"w\") as outfile:\n",
        "    for line in gzip.open(infile):\n",
        "      ex = json.loads(line)\n",
        "      # Remove any examples with more than one answer.\n",
        "      if len(ex['annotations'][0]['short_answers']) != 1:\n",
        "        continue\n",
        "      # Questions in NQ do not include a question mark.\n",
        "      question = ex[\"question_text\"] + \"?\"\n",
        "      answer_span = ex['annotations'][0]['short_answers'][0]\n",
        "      # Handle the two document formats in NQ (tokens or text).\n",
        "      if \"document_tokens\" in ex:\n",
        "        tokens = [t[\"token\"] for t in ex[\"document_tokens\"]]\n",
        "      elif \"document_text\" in ex:\n",
        "        tokens = ex[\"document_text\"].split(\" \")\n",
        "      answer = extract_answer(tokens, answer_span)\n",
        "      # Write this line as <question>\\t<answer>\n",
        "      outfile.write(\"%s\\t%s\\n\" % (question, answer))\n",
        "      count += 1\n",
        "      tf.logging.log_every_n(\n",
        "          tf.logging.INFO,\n",
        "          \"Wrote %d examples to %s.\" % (count, out_fname),\n",
        "          1000)\n",
        "    return count\n",
        "\n",
        "if tf.io.gfile.exists(nq_counts_path):\n",
        "  # Used cached data and counts.\n",
        "  tf.logging.info(\"Loading NQ from cache.\")\n",
        "  num_nq_examples = json.load(tf.io.gfile.GFile(nq_counts_path))\n",
        "else:\n",
        "  # Create TSVs and get counts.\n",
        "  tf.logging.info(\"Generating NQ TSVs.\")\n",
        "  num_nq_examples = {}\n",
        "  for split, fname in NQ_SPLIT_FNAMES.items():\n",
        "    num_nq_examples[split] = nq_jsonl_to_tsv(\n",
        "        os.path.join(NQ_JSONL_DIR, fname), nq_tsv_path[split])\n",
        "  json.dump(num_nq_examples, tf.io.gfile.GFile(nq_counts_path, \"w\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Ja8akCX1dR"
      },
      "source": [
        "Next, we define a function to load the TSV data as a `tf.data.Dataset` in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 139
        },
        "id": "KPOteeqctpzw",
        "outputId": "ef61274d-170d-4c56-dadc-427a679521e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'question': b'what do the 3 dots mean in math?', 'answer': b'the therefore sign (\\xe2\\x88\\xb4) is generally used before a logical consequence, such as the conclusion of a syllogism'}\n",
            "{'question': b'who is playing the halftime show at super bowl 2016?', 'answer': b'Coldplay with special guest performers Beyonc\\xc3\\xa9 and Bruno Mars'}\n",
            "{'question': b'who won the 2017 sports personality of the year?', 'answer': b'Mo Farah'}\n",
            "{'question': b'where was the world economic forum held this year?', 'answer': b'Davos, a mountain resort in Graub\\xc3\\xbcnden, in the eastern Alps region of Switzerland'}\n",
            "{'question': b'who has made the most premier league appearances?', 'answer': b'Gareth Barry'}\n"
          ]
        }
      ],
      "source": [
        "def nq_dataset_fn(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  # Split each \"<question>\\t<answer>\" example into (question, answer) tuple.\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\", \"\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  # Map each tuple to a {\"question\": ... \"answer\": ...} dict.\n",
        "  ds = ds.map(lambda *ex: dict(zip([\"question\", \"answer\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_fn(\"validation\").take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCUYT7JmX9Tj"
      },
      "source": [
        "Now, we write a preprocess function to convert the examples in the `tf.data.Dataset` into a text-to-text format, with both `inputs` and `targets` fields. The preprocessor also normalizes the text by lowercasing it and removing quotes since the answers are sometimes formatted in odd ways. Finally, we prepend 'trivia question:' to the inputs so that the model knows what task it's trying to solve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8tNn6HMYLMb"
      },
      "outputs": [],
      "source": [
        "def trivia_preprocessor(ds):\n",
        "  def normalize_text(text):\n",
        "    \"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.regex_replace(text,\"'(.*)'\", r\"\\1\")\n",
        "    return text\n",
        "\n",
        "  def to_inputs_and_targets(ex):\n",
        "    \"\"\"Map {\"question\": ..., \"answer\": ...}->{\"inputs\": ..., \"targets\": ...}.\"\"\"\n",
        "    return {\n",
        "        \"inputs\":\n",
        "             tf.strings.join(\n",
        "                 [\"trivia question: \", normalize_text(ex[\"question\"])]),\n",
        "        \"targets\": normalize_text(ex[\"answer\"])\n",
        "    }\n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1Pm2aRZ9Ow"
      },
      "source": [
        "Finally, we put everything together to create a `Task`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJyRavOpZ7UW"
      },
      "outputs": [],
      "source": [
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\":\n",
        "        seqio.Feature(\n",
        "            vocabulary=t5.data.get_default_vocabulary(), add_eos=True),\n",
        "    \"targets\":\n",
        "        seqio.Feature(\n",
        "            vocabulary=t5.data.get_default_vocabulary(), add_eos=True)\n",
        "}\n",
        "\n",
        "seqio.TaskRegistry.add(\n",
        "    \"nq_context_free\",\n",
        "    # Specify the task source.\n",
        "    source=seqio.FunctionDataSource(\n",
        "        # Supply a function which returns a tf.data.Dataset.\n",
        "        dataset_fn=nq_dataset_fn,\n",
        "        splits=[\"train\", \"validation\"],\n",
        "        # Not required, but helps for mixing and auto-caching.\n",
        "        num_input_examples=num_nq_examples),\n",
        "    # Supply a list of functions that preprocess the input tf.data.Dataset.\n",
        "    preprocessors=[\n",
        "        trivia_preprocessor,\n",
        "        seqio.preprocessors.tokenize_and_append_eos,\n",
        "    ],\n",
        "    # Lowercase targets before computing metrics.\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    output_features=DEFAULT_OUTPUT_FEATURES,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe4o_0jFbP-p"
      },
      "source": [
        "Let's look at a few pre-processed examples from the validation set. Note they contain both the tokenized (integer) and plain-text inputs and targets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 275
        },
        "id": "I64TqHGxbOJ2",
        "outputId": "68df8ac5-9d34-4dd2-de40-1c6b65feca3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few preprocessed validation examples...\n",
            "{'inputs_pretokenized': b'trivia question: what is the average height of a chinese man?', 'inputs': array([22377,   822,    10,   125,    19,     8,  1348,  3902,    13,\n",
            "           3,     9,     3,  1436,  1496,    15,   388,    58,     1]), 'targets_pretokenized': b'167.1 cm (5 ft 6 in)', 'targets': array([  898, 25059,  2446,  9209,     3,    89,    17,   431,    16,\n",
            "          61,     1])}\n",
            "{'inputs_pretokenized': b'trivia question: what is the population of fayetteville north carolina?', 'inputs': array([22377,   822,    10,   125,    19,     8,  2074,    13,     3,\n",
            "          89,     9,    63,  1954,  1420,  3457,   443, 12057,     9,\n",
            "          58,     1]), 'targets_pretokenized': b'204,408 in 2013', 'targets': array([    3, 26363,     6,  2445,   927,    16,  2038,     1])}\n",
            "{'inputs_pretokenized': b'trivia question: capital of georgia the former soviet republic 7 letters?', 'inputs': array([22377,   822,    10,  1784,    13,   873,  1677,    23,     9,\n",
            "           8,  1798,    78,  5914,    17, 20237,   489,  5487,    58,\n",
            "           1]), 'targets_pretokenized': b'tbilisi', 'targets': array([   3,   17, 3727,  159,   23,    1])}\n",
            "{'inputs_pretokenized': b'trivia question: who plays jill bigelow in line of duty?', 'inputs': array([22377,   822,    10,   113,  4805,     3,   354,  1092,   600,\n",
            "          15,  3216,    16,   689,    13,  5461,    58,     1]), 'targets_pretokenized': b'polly walker', 'targets': array([ 5492,    63,     3, 24063,     1])}\n",
            "{'inputs_pretokenized': b'trivia question: when did we first put a rover on mars?', 'inputs': array([22377,   822,    10,   116,   410,    62,   166,   474,     3,\n",
            "           9,     3,    52,  1890,    30,  8113,    58,     1]), 'targets_pretokenized': b'january 2004', 'targets': array([   3, 7066,   76, 1208, 4406,    1])}\n"
          ]
        }
      ],
      "source": [
        "nq_task = seqio.TaskRegistry.get(\"nq_context_free\")\n",
        "ds = nq_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 32})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ktIEGePdBr"
      },
      "source": [
        "**Note**: Instead of defining `nq_dataset_fn` and above, we also could have used the `TextLineTask` class with the `parse_tsv` preprocessor for equivalent results as follows:\n",
        "\n",
        "```py\n",
        "seqio.TaskRegistry.add(\n",
        "    \"nq_context_free\",\n",
        "    source=seqio.TextLineDataSource(\n",
        "        split_to_filepattern=nq_tsv_path,\n",
        "        num_input_examples=num_nq_examples),\n",
        "    preprocessors=[\n",
        "      functools.partial(\n",
        "          t5.data.preprocessors.parse_tsv,\n",
        "          field_names=[\"question\", \"answer\"]),\n",
        "      trivia_preprocessor,\n",
        "      seqio.preprocessors.tokenize_and_append_eos,\n",
        "    ],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text, \n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    output_features=DEFAULT_OUTPUT_FEATURES,\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4_1gpcK9i3W"
      },
      "source": [
        "## TriviaQA\n",
        "\n",
        "A second dataset we will use is related to [TriviaQA](https://nlp.cs.washington.edu/triviaqa/). It is also intended for reading comprehension, but, once again, we will modify the task here by ignoring the provided context.\n",
        "\n",
        "Since the dataset has been imported into [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets/catalog/trivia_qa), we can let it handle the data parsing for us. It will take a few minutes to download and preprocess the first time, but we'll be able to access it instantly from our data directory afterward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 156
        },
        "id": "mQTQHS94Z0Tq",
        "outputId": "b0c0c90b-e4c3-418d-971f-bdfaa52d6b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'answer': {'aliases': array([b'Torquemada (disambiguation)', b'Torquemada'], dtype=object), 'matched_wiki_entity_name': b'', 'normalized_aliases': array([b'torquemada', b'torquemada disambiguation'], dtype=object), 'normalized_matched_wiki_entity_name': b'', 'normalized_value': b'torquemada', 'type': b'WikipediaEntity', 'value': b'Torquemada'}, 'entity_pages': {'doc_source': array([], dtype=object), 'filename': array([], dtype=object), 'title': array([], dtype=object), 'wiki_context': array([], dtype=object)}, 'question': b'In 1483, who was appointed the first grand inquisitor of the Spanish Inquisition?', 'question_id': b'qw_16011', 'question_source': b'http://www.quizwise.com/', 'search_results': {'description': array([], dtype=object), 'filename': array([], dtype=object), 'rank': array([], dtype=int32), 'search_context': array([], dtype=object), 'title': array([], dtype=object), 'url': array([], dtype=object)}}\n",
            "{'answer': {'aliases': array([b'Austerlitz (disambiguation)', b'Austerlitz', b'AUSTERLITZ'],\n",
            "      dtype=object), 'matched_wiki_entity_name': b'', 'normalized_aliases': array([b'austerlitz', b'austerlitz disambiguation'], dtype=object), 'normalized_matched_wiki_entity_name': b'', 'normalized_value': b'austerlitz', 'type': b'WikipediaEntity', 'value': b'AUSTERLITZ'}, 'entity_pages': {'doc_source': array([], dtype=object), 'filename': array([], dtype=object), 'title': array([], dtype=object), 'wiki_context': array([], dtype=object)}, 'question': b'Which celebrated battle was fought near Brno on 2nd December 1805?', 'question_id': b'dpql_4053', 'question_source': b'https://derbyshirepubquizleague.wordpress.com/', 'search_results': {'description': array([], dtype=object), 'filename': array([], dtype=object), 'rank': array([], dtype=int32), 'search_context': array([], dtype=object), 'title': array([], dtype=object), 'url': array([], dtype=object)}}\n"
          ]
        }
      ],
      "source": [
        "ds = tfds.load(\n",
        "    \"trivia_qa/unfiltered.nocontext\",\n",
        "    data_dir=DATA_DIR,\n",
        "    # Download data locally for preprocessing to avoid using GCS space.\n",
        "    download_and_prepare_kwargs={\"download_dir\": \"./downloads\"})\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(ds[\"validation\"].take(2)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq5U_rjDb1bn"
      },
      "source": [
        "As with Natural Questions, we need to preprocess the raw examples into `inputs` and `targets` features. We can reuse the `trivia_preprocessor` above, but first we need to convert the TriviaQA examples into the correct format, ignoring the fields we don't need for our task.\n",
        "\n",
        "We'll then define our `Task` and print out a few preprocessed examples from the validation set.\n",
        "\n",
        "Note that we do not need to specify the splits or number of examples since that information is provided by TFDS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 258
        },
        "id": "6rU32DjyeLuL",
        "outputId": "5f643cf8-c997-4201-d1da-a6c0beda473d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few preprocessed validation examples...\n",
            "{'inputs_pretokenized': b'trivia question: what does a farrier do?', 'inputs': array([22377,   822,    10,   125,   405,     3,     9,   623,  6711,\n",
            "         103,    58,     1]), 'targets_pretokenized': b'he shoes horses', 'targets': array([    3,    88,  4439, 10235,     1])}\n",
            "{'inputs_pretokenized': b'trivia question: what is the name of the wooden panelled lining applied to a room', 'inputs': array([22377,   822,    10,   125,    19,     8,   564,    13,     8,\n",
            "        5726,  2952,  1361,     3,  9424,  2930,    12,     3,     9,\n",
            "         562,     1]), 'targets_pretokenized': b'wainscotting', 'targets': array([    3,   210, 13676, 10405,    53,     1])}\n",
            "{'inputs_pretokenized': b'trivia question: how did gus grissom, ed white and roger b. chaffee die in 1967?', 'inputs': array([22377,   822,    10,   149,   410,     3,  1744,     7, 19116,\n",
            "       10348,     6,     3,    15,    26,   872,    11,     3,  3822,\n",
            "          49,     3,   115,     5,     3,  3441,  7398,    15,    67,\n",
            "          16, 18148,    58,     1]), 'targets_pretokenized': b'burned to death', 'targets': array([16644,    12,  1687,     1])}\n"
          ]
        }
      ],
      "source": [
        "def tiviaqa_extract_qa(ds):\n",
        "  def exract_qa(ex):\n",
        "    return {\n",
        "        \"question\": ex[\"question\"],\n",
        "        \"answer\": ex[\"answer\"][\"value\"]\n",
        "    }\n",
        "  return ds.map(exract_qa, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "seqio.TaskRegistry.add(\n",
        "    \"triviaqa_context_free\",\n",
        "    # A TfdsTask takes in a TFDS name instead of a tf.data.Dataset function.\n",
        "    source=seqio.TfdsDataSource(\n",
        "        tfds_name=\"trivia_qa/unfiltered.nocontext:1.1.0\",\n",
        "        tfds_data_dir=DATA_DIR),\n",
        "    preprocessors=[\n",
        "        tiviaqa_extract_qa,\n",
        "        trivia_preprocessor,\n",
        "        seqio.preprocessors.tokenize_and_append_eos,\n",
        "    ],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    output_features=DEFAULT_OUTPUT_FEATURES,\n",
        ")\n",
        "\n",
        "# Load and print a few examples.\n",
        "triviaqa_task = seqio.TaskRegistry.get(\"triviaqa_context_free\")\n",
        "ds = triviaqa_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 32})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlghm_3rAd-M"
      },
      "source": [
        "## Dataset Mixture\n",
        "\n",
        "We now create a `Mixture` from the above `Tasks`, which we will fine-tune on.\n",
        "\n",
        "There are different ways to automatically set the rate (for example, based on the number of examples using `rate_num_examples`), but we will just hardcode an equal mixture for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgs-s3eDAU37"
      },
      "outputs": [],
      "source": [
        "seqio.MixtureRegistry.remove(\"trivia_all\")\n",
        "seqio.MixtureRegistry.add(\n",
        "    \"trivia_all\",\n",
        "    [\"nq_context_free\", \"triviaqa_context_free\"],\n",
        "     default_rate=1.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_QS-Oh4SATs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGQ-zpgy3raf"
      },
      "outputs": [],
      "source": [
        "MODEL_SIZE = \"3B\" #@param[\"small\", \"base\", \"large\", \"3B\", \"11B\"]\n",
        "# Public GCS path for T5 pre-trained model checkpoints\n",
        "BASE_PRETRAINED_DIR = \"gs://t5-data/pretrained_models\"\n",
        "PRETRAINED_DIR = os.path.join(BASE_PRETRAINED_DIR, MODEL_SIZE)\n",
        "MODEL_DIR = os.path.join(MODELS_DIR, MODEL_SIZE)\n",
        "\n",
        "if ON_CLOUD and MODEL_SIZE == \"3B\":\n",
        "  tf.logging.warning(\n",
        "      \"The `3B` model is too large to use with the 5GB GCS free tier. \"\n",
        "      \"Make sure you have at least 25GB on GCS before continuing.\"\n",
        "  )\n",
        "elif ON_CLOUD and MODEL_SIZE == \"11B\":\n",
        "  raise ValueError(\n",
        "      \"The `11B` parameter is too large to fine-tune on the `v2-8` TPU \"\n",
        "      \"provided by Colab. Please comment out this Error if you're running \"\n",
        "      \"on a larger TPU.\"\n",
        "  )\n",
        "\n",
        "# Set parallelism and batch size to fit on v2-8 TPU (if possible).\n",
        "# Limit number of checkpoints to fit within 5GB (if possible).\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "# The models from our paper are based on the Mesh Tensorflow Transformer.\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 32},\n",
        "    learning_rate_schedule=0.003,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5mPyYATNsVT"
      },
      "outputs": [],
      "source": [
        "if ON_CLOUD:\n",
        "  %reload_ext tensorboard\n",
        "%tensorboard --logdir=\"$MODEL_DIR\" --port=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7t7a25LBTj9"
      },
      "outputs": [],
      "source": [
        "FINETUNE_STEPS = 25000 #@param {type: \"integer\"}\n",
        "\n",
        "model.finetune(\n",
        "    mixture_or_task_name=\"trivia_all\",\n",
        "    pretrained_model_dir=PRETRAINED_DIR,\n",
        "    finetune_steps=FINETUNE_STEPS\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPvO_ZZ-SJ8w"
      },
      "source": [
        "## Expected Results [SPOILER ALERT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_-7qYemnEHl"
      },
      "source": [
        "Below are the expected accuracies on the Natural Question (NQ) and TriviQA validation sets for various model sizes. The full 11B model produces the exact text of the answer 34.5% and 25.1% of the time on TriviaQA and NQ, respectively. The 3B parameter model, which is the largest that can be trained with a free Cloud TPU in Colab, achieves 29.7% and 23.7%, respectively.\n",
        "\n",
        "In reality, the model performs better than this since requiring exact match is too strict of a metric, as you’ll see in the examples below. This helps to explain why the model appears to perform better on TriviaQA than NQ, as the latter tends to include more long-form answers extracted from the context.\n",
        "\n",
        "Please see our [paper on closed-book QA](https://arxiv.org/abs/2002.08910) where achieved even better results.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/t5-data/assets/t5_trivia_expected.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYeciUZ_D7T2"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "We now evaluate on the validation sets of the tasks in our mixture. Accuracy results will be logged and added to the TensorBoard above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz6CJRHzNfd3"
      },
      "outputs": [],
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = train_batch_size * 4\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"trivia_all\",\n",
        "    checkpoint_steps=\"all\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 1000
        },
        "id": "-FuqHRuvxOct",
        "outputId": "e36475d1-a8e7-4f2f-b4fa-6a2a2dd0c607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<== Random predictions for triviaqa_context_free using checkpoint 1100000 ==>\n",
            "\n",
            "Input: trivia question: jackpot counter, ghost drop and drop zone are all terms used in which uk television game show?\n",
            "Target: tipping point\n",
            "Prediction: countdown\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: cursed to sail around the cape of good hope, which ghost ship is the theme of an 1841 opera by richard wagner?\n",
            "Target: the flying dutchman\n",
            "Prediction: baron von munchhausen\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: at what fret are found the same notes as the open strings, but an octave higher, on a standard guitar?\n",
            "Target: 12th\n",
            "Prediction: 12th\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: how many legs does a ladybird have?\n",
            "Target: six\n",
            "Prediction: six\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: in which city’s harbour was the ship queen elizabeth ravaged by fire in 1972?\n",
            "Target: hong kong\n",
            "Prediction: hong kong\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: what are the three largest islands in the world beginning with the letter n\n",
            "Target: new guinea, north island\n",
            "Prediction: new zealand; namibia and nova scotia\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: lenny bruce was in what field of entertainment in the 1960s?\n",
            "Target: standup comedy\n",
            "Prediction: comedy\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: in which sea are the cayman islands?\n",
            "Target: caribbean\n",
            "Prediction: caribbean\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: what is an astronomical event that occurs when one celestial object moves into the shadow of another?\n",
            "Target: eclipse\n",
            "Prediction: lunar eclipse\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: which tv cartoon series was about a meek janitor who led a double life as an unfortunate super-detective?\n",
            "Target: hong kong fuey\n",
            "Prediction: scooby-doo\n",
            "Counted as Correct? False\n",
            "\n",
            "<== Random predictions for nq_context_free using checkpoint 1100000 ==>\n",
            "\n",
            "Input: trivia question: who is known as the super fast boy in the series the icredible?\n",
            "Target: dashiell robert parr/dash\n",
            "Prediction: dash\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: who played santa in the santa clause movies?\n",
            "Target: tim allen\n",
            "Prediction: tim allen\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: who has sold more albums kelly or carrie?\n",
            "Target: carrie underwood\n",
            "Prediction: carrie underwood\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: when did sweet caroline start at red sox games?\n",
            "Target: at least 1997\n",
            "Prediction: 2004\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: who plays mr wilson in dennis the menace?\n",
            "Target: joseph sherrard kearns\n",
            "Prediction: joseph sherrard kearns\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: who had a baby at 100 in the bible?\n",
            "Target: abraham\n",
            "Prediction: sarah\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: who is doing 2018 super bowl half time show?\n",
            "Target: justin timberlake\n",
            "Prediction: justin timberlake\n",
            "Counted as Correct? True\n",
            "\n",
            "Input: trivia question: what is the official slogan for the 2018 winter olympics?\n",
            "Target: passion. connected.\n",
            "Prediction: every step counts\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: ray charles hit the road jack album name?\n",
            "Target: ray charles greatest hits\n",
            "Prediction: the road jack album\n",
            "Counted as Correct? False\n",
            "\n",
            "Input: trivia question: who sang the theme song to step by step?\n",
            "Target: jesse frederick james conaway\n",
            "Prediction: frederick and teresa james\n",
            "Counted as Correct? False\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def print_random_predictions(task_name, n=10):\n",
        "  \"\"\"Print n predictions from the validation split of a task.\"\"\"\n",
        "  # Grab the dataset for this task.\n",
        "  ds = seqio.TaskRegistry.get(task_name).get_dataset(\n",
        "      split=\"validation\",\n",
        "      sequence_length={\"inputs\": 128, \"targets\": 32},\n",
        "      shuffle=False)\n",
        "\n",
        "  def _prediction_file_to_ckpt(path):\n",
        "    \"\"\"Extract the global step from a prediction filename.\"\"\"\n",
        "    return int(path.split(\"_\")[-2])\n",
        "\n",
        "  # Grab the paths of all logged predictions.\n",
        "  prediction_files = tf.io.gfile.glob(\n",
        "      os.path.join(\n",
        "          MODEL_DIR,\n",
        "          \"validation_eval/%s_*_predictions\" % task_name))\n",
        "  # Get most recent prediction file by sorting by their step.\n",
        "  latest_prediction_file = sorted(\n",
        "      prediction_files, key=_prediction_file_to_ckpt)[-1]\n",
        "\n",
        "  # Collect (inputs, targets, prediction) from the dataset and predictions file\n",
        "  results = []\n",
        "  with tf.io.gfile.GFile(latest_prediction_file) as preds:\n",
        "    for ex, pred in zip(tfds.as_numpy(ds), preds):\n",
        "      results.append((tf.compat.as_text(ex[\"inputs_pretokenized\"]),\n",
        "                      tf.compat.as_text(ex[\"targets_pretokenized\"]),\n",
        "                      pred.strip()))\n",
        "\n",
        "  print(\"<== Random predictions for %s using checkpoint %s ==>\\n\" %\n",
        "        (task_name, \n",
        "         _prediction_file_to_ckpt(latest_prediction_file)))\n",
        "\n",
        "  for inp, tgt, pred in random.choices(results, k=10):\n",
        "    print(\"Input:\", inp)\n",
        "    print(\"Target:\", tgt)\n",
        "    print(\"Prediction:\", pred)\n",
        "    print(\"Counted as Correct?\", tgt == pred)\n",
        "    print()\n",
        "\n",
        "print_random_predictions(\"triviaqa_context_free\")\n",
        "print_random_predictions(\"nq_context_free\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbqiq2Ab4PJk"
      },
      "source": [
        "## Predict\n",
        "\n",
        "Now that we have fine-tuned the model, we can feed T5 arbitrary questions and have it predict the answers!\n",
        "\n",
        "There is a significant amount of overhead in initializing the model so this may take a few minutes to run each time even though the prediction itself is quite fast.\n",
        "\n",
        "\n",
        "To avoid this overhead, you might consider exporting a `SavedModel` and running it on [Cloud ML Engine](https://cloud.google.com/ml-engine/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 340
        },
        "id": "xatHPuCJsPns",
        "outputId": "18e6b677-cf57-4d45-b16d-ca015937dcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions using checkpoint 1100000:\n",
            "\n",
            "Q: Where is the Google headquarters located?\n",
            "A: mountain view, california\n",
            "\n",
            "\n",
            "Q: What is the most populous country in the world?\n",
            "A: china\n",
            "\n",
            "\n",
            "Q: Who are the 4 members of The Beatles?\n",
            "A: john lennon, paul mccartney, george harrison and ringo starr\n",
            "\n",
            "\n",
            "Q: How many teeth do humans have?\n",
            "A: 30\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# First import the t5 mixtures so we can load the training mixture's vocabulary.\n",
        "import t5.data.mixtures\n",
        "\n",
        "question_1 = \"Where is the Google headquarters located?\" #@param {type:\"string\"}\n",
        "question_2 = \"What is the most populous country in the world?\" #@param {type:\"string\"}\n",
        "question_3 = \"Who are the 4 members of The Beatles?\" #@param {type:\"string\"}\n",
        "question_4 = \"How many teeth do humans have?\" #@param {type:\"string\"}\n",
        "\n",
        "questions = [question_1, question_2, question_3, question_4]\n",
        "\n",
        "now = time.time()\n",
        "# Write out the supplied questions to text files.\n",
        "predict_inputs_path = os.path.join(MODEL_DIR, \"predict_inputs_%d.txt\" % now)\n",
        "predict_outputs_path = os.path.join(MODEL_DIR, \"predict_outputs_%d.txt\" % now)\n",
        "# Manually apply preprocessing by prepending \"triviaqa question:\".\n",
        "with tf.io.gfile.GFile(predict_inputs_path, \"w\") as f:\n",
        "  for q in questions:\n",
        "    f.write(\"trivia question: %s\\n\" % q.lower())\n",
        "\n",
        "# Ignore any logging so that we only see the model's answers to the questions.\n",
        "with tf_verbosity_level('ERROR'):\n",
        "  model.batch_size = 8  # Min size for small model on v2-8 with parallelism 1.\n",
        "  model.predict(\n",
        "      input_file=predict_inputs_path,\n",
        "      output_file=predict_outputs_path,\n",
        "      # Select the most probable output token at each step.\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "# The output filename will have the checkpoint appended so we glob to get \n",
        "# the latest.\n",
        "prediction_files = sorted(tf.io.gfile.glob(predict_outputs_path + \"*\"))\n",
        "print(\"\\nPredictions using checkpoint %s:\\n\" % prediction_files[-1].split(\"-\")[-1])\n",
        "with tf.io.gfile.GFile(prediction_files[-1]) as f:\n",
        "  for q, a in zip(questions, f):\n",
        "    if q:\n",
        "      print(\"Q: \" + q)\n",
        "      print(\"A: \" + a)\n",
        "      print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_YuEL9FZ-UR"
      },
      "source": [
        "## Export SavedModel\n",
        "\n",
        "We first export the SavedModel. We set a batch size of 1 for simplicity, but it may be more efficient to use a larger batch size if you want to handle multiple requests per call.\n",
        "\n",
        "For 3B and 11B models the export will take approximately 30-45 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWu8lbh3aHjc"
      },
      "outputs": [],
      "source": [
        "export_dir = os.path.join(MODEL_DIR, \"export\")\n",
        "\n",
        "model.batch_size = 1 # make one prediction per call\n",
        "saved_model_path = model.export(\n",
        "    export_dir,\n",
        "    checkpoint_step=-1,  # use most recent\n",
        "    beam_size=1,  # no beam search\n",
        "    temperature=1.0,  # sample according to predicted distribution\n",
        ")\n",
        "print(\"Model saved to:\", saved_model_path)"
      ]
    }
  ]
}